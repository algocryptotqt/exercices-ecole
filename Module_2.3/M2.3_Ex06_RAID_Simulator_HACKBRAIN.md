# Exercice M2.3-Ex06 : kaiju_shield_array

**Module :**
2.3.27 - Systemes de Fichiers et Stockage

**Concept :**
g+i - Hot spare: Automatic rebuild + URE: Unrecoverable Read Error

**Difficulte :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜† (8/10)

**Type :**
complet

**Tiers :**
3 - Synthese (RAID 0/1/5/6, striping, parity XOR, hot spare, rebuild, URE)

**Langage :**
Rust (Edition 2024)

**Prerequis :**
- Operations bitwise (XOR, AND, OR)
- Gestion memoire avec ownership et borrowing
- Structures de donnees (Vec, HashSet)
- Arithmetique modulaire (distribution des stripes)
- Gestion d'erreurs avec Result et Option
- Traits et implementations

**Domaines :**
FS, Mem, MD, Encodage, Struct

**Duree estimee :**
360 min

**XP Base :**
500

**Complexite :**
T3 O(n) x S3 O(n)

---

## 2.4 SECTION CULTURE : L'AME DE L'EXERCICE

### 2.4.1 PACIFIC RIM - Le Drift Neural et les Jaegers

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘   "TODAY WE ARE CANCELLING THE APOCALYPSE!"                                  â•‘
â•‘                           - Stacker Pentecost, Marshal du Shatterdome        â•‘
â•‘                                                                              â•‘
â•‘   Dans Pacific Rim, l'humanite fait face aux Kaiju - des monstres geants    â•‘
â•‘   qui emergent du Breach. Notre seule defense : les JAEGERS, des robots     â•‘
â•‘   titanesques pilotes par DEUX humains connectes via le NEURAL DRIFT.       â•‘
â•‘                                                                              â•‘
â•‘   Pourquoi deux pilotes ? Un seul cerveau ne peut pas supporter la charge   â•‘
â•‘   neurale necessaire pour controler un Jaeger. Deux pilotes partagent       â•‘
â•‘   cette charge ET se protegent mutuellement - si un pilote est KO,          â•‘
â•‘   l'autre peut temporairement maintenir le Jaeger en mode DEGRADE.          â•‘
â•‘                                                                              â•‘
â•‘   C'est EXACTEMENT le principe du RAID !                                    â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**L'ANALOGIE PARFAITE :**

```
           LE DRIFT NEURAL = LE RAID

    JAEGER                           RAID ARRAY
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚          â”‚                     â”‚
    â”‚  Pilot 1 â—„â”€DRIFTâ”€â–º Pilot 2    â”‚  Disk 0 â—„â”€SYNCâ”€â–º Disk 1
    â”‚     â”‚        â”‚        â”‚       â”‚     â”‚        â”‚      â”‚
    â”‚     â–¼        â–¼        â–¼       â”‚     â–¼        â–¼      â–¼
    â”‚   Data    Parity    Data      â”‚   Data    Parity  Data
    â”‚                     â”‚          â”‚                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Si Pilot 1 tombe (Kaiju hit)     Si Disk 0 tombe (URE/failure)
         â†’ Pilot 2 continue               â†’ Autres disques reconstruisent

    Hot Spare = Pilote de reserve    Hot Spare = Disque de reserve
    au Shatterdome, pret a etablir   pret a remplacer un disque
    un nouveau Neural Handshake      defaillant automatiquement
```

**LES JAEGERS COMME NIVEAUX RAID :**

| Jaeger | RAID | Description | Analogie |
|--------|------|-------------|----------|
| **STRIKER EUREKA** | RAID 0 | Le plus rapide, AUCUNE redondance | Pilote solo - un hit = game over |
| **GIPSY DANGER** | RAID 1 | Deux pilotes synchronises | Raleigh & Mako - miroir parfait |
| **CRIMSON TYPHOON** | RAID 5 | Les triplets Wei Tang | 3 pilotes, 1 peut tomber, XOR regenere |
| **CHERNO ALPHA** | RAID 6 | Ingenierie russe blindee | Survit a 2 hits directs (double parite) |

**POURQUOI PACIFIC RIM EST L'ANALOGIE PARFAITE :**

1. **Le Drift = La Synchronisation**
   - Dans le Drift, deux cerveaux partagent les memes donnees
   - En RAID 1, deux disques contiennent les memes donnees
   - La desynchronisation = corruption de donnees

2. **La Regeneration Kaiju = La Parite XOR**
   - Les Kaiju peuvent regenerer des membres perdus
   - RAID 5/6 peut regenerer des donnees perdues via XOR
   - `A XOR B XOR B = A` - la magie de la reconstruction

3. **Le Mode Pilote Solo = Le Mode Degrade**
   - Quand Yancy meurt, Raleigh continue seul (temporairement)
   - Quand un disque tombe, l'array continue en mode degrade
   - Performance reduite mais fonctionnel

4. **Le Shatterdome = Le Pool de Hot Spares**
   - Pilotes de reserve attendent leur tour
   - Disques de reserve prets a etre actives
   - Reconstruction automatique du Neural Handshake

```
    ğŸ¦ KAIJU ATTACK SCENARIO (DISK FAILURE)

    AVANT ATTAQUE:                    APRES ATTAQUE:
    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
    â”‚  D0  â”‚  D1  â”‚  D2  â”‚  P   â”‚    â”‚  D0  â”‚  â˜ ï¸  â”‚  D2  â”‚  P   â”‚
    â”‚ 0xAA â”‚ 0x55 â”‚ 0xFF â”‚ 0x00 â”‚    â”‚ 0xAA â”‚ DEAD â”‚ 0xFF â”‚ 0x00 â”‚
    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚              â”‚
    Parity: 0xAA âŠ• 0x55 âŠ• 0xFF = 0x00     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           RECONSTRUCTION:
                                     D1 = D0 âŠ• D2 âŠ• P
                                     D1 = 0xAA âŠ• 0xFF âŠ• 0x00
                                     D1 = 0x55 âœ“

    "The Kaiju hit Pilot 1, but we can rebuild him via XOR parity!"
```

---

### 2.4.2 Consigne Academique

Implementer un simulateur RAID logiciel complet en Rust supportant les niveaux 0, 1, 5 et 6. Le systeme doit gerer :

1. **Striping (RAID 0)** : Distribution des donnees sur N disques pour maximiser les performances
2. **Mirroring (RAID 1)** : Duplication complete des donnees pour redondance maximale
3. **Parite distribuee (RAID 5)** : Calcul XOR avec rotation de la parite entre les stripes
4. **Double parite (RAID 6)** : Deux parities (P et Q) pour survivre a 2 pannes simultanees
5. **Hot Spare** : Disque de reserve active automatiquement lors d'une panne
6. **Reconstruction automatique** : Rebuild des donnees perdues via XOR
7. **Simulation d'URE** : Unrecoverable Read Errors probabilistes pendant les lectures

Le simulateur doit permettre de :
- Creer des arrays RAID avec configuration personnalisable
- Lire et ecrire des donnees de maniere transparente
- Simuler des pannes de disque et observer le comportement
- Reconstruire les donnees depuis un hot spare
- Calculer les metriques de performance et d'efficacite

---

## SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichiers a rendre :**
```
raid_simulator/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs              # API publique et structures
â”‚   â”œâ”€â”€ disk.rs             # VirtualDisk implementation
â”‚   â”œâ”€â”€ raid0.rs            # RAID 0 (Striping)
â”‚   â”œâ”€â”€ raid1.rs            # RAID 1 (Mirroring)
â”‚   â”œâ”€â”€ raid5.rs            # RAID 5 (Distributed Parity)
â”‚   â”œâ”€â”€ raid6.rs            # RAID 6 (Double Parity)
â”‚   â”œâ”€â”€ parity.rs           # XOR et Galois Field operations
â”‚   â”œâ”€â”€ rebuild.rs          # Hot spare et reconstruction
â”‚   â””â”€â”€ errors.rs           # Types d'erreurs
â””â”€â”€ tests/
    â””â”€â”€ integration_tests.rs
```

**Fonctions autorisees :**
`std::collections::HashSet`, `std::vec::Vec`, `std::result::Result`, `std::option::Option`

**Fonctions interdites :**
Aucune bibliotheque RAID externe, pas de `unsafe` sauf justification

---

### 1.2 Consigne

**CONTEXTE : SHATTERDOME STORAGE DIVISION**

*"In case you've forgotten, we're at war. And we need every disk operational!"*

Le Marshal Pentecost t'a assigne a la division stockage du Shatterdome. Les donnees de combat des Jaegers sont critiques - chaque seconde de telemetrie, chaque log de Neural Drift, chaque scan de Kaiju doit etre preserve.

Ton systeme RAID est la derniere ligne de defense contre la perte de donnees. Un disque peut tomber a tout moment (comme un pilote frappe par un Kaiju), et ton systeme doit continuer a fonctionner.

**Ta mission :**

Implementer le systeme `KaijuShieldArray` - un simulateur RAID complet qui protege les donnees du Shatterdome contre les pannes de disque (Kaiju hits) et les URE (erreurs de lecture irrecuperables).

**Entree :**
- `config` : Configuration du RAID (niveau, nombre de disques, taille des stripes)
- `data` : Donnees a lire/ecrire
- `offset` : Position dans l'array

**Sortie :**
- `Ok(bytes)` : Nombre d'octets transferes
- `Err(RaidError)` : Erreur fatale (trop de pannes, URE critique, etc.)

**Contraintes :**

| RAID | Disques Min | Disques Parite | Capacite Utilisable | Tolerance Pannes |
|------|-------------|----------------|---------------------|------------------|
| 0 | 2 | 0 | N x capacite | 0 |
| 1 | 2 | N-1 | 1 x capacite | N-1 |
| 5 | 3 | 1 (distribue) | (N-1) x capacite | 1 |
| 6 | 4 | 2 (distribue) | (N-2) x capacite | 2 |

**Exemples :**

| Appel | Retour | Explication |
|-------|--------|-------------|
| `RaidArray::new(Raid5, 4, 1MB)` | `Ok(array)` | Crimson Typhoon deploye |
| `array.write(0, &data)` | `Ok(4096)` | Donnees distribuees avec parite |
| `array.fail_disk(1)` | `Ok(())` | Pilote 1 KO, mode degrade |
| `array.read(0, 4096)` | `Ok(data)` | Reconstruit via XOR |
| `array.activate_hot_spare()` | `Ok(())` | Reserve activee, rebuild lance |

---

### 1.3 Prototype

```rust
// src/lib.rs
use std::collections::HashSet;

pub const STRIP_SIZE: usize = 64 * 1024;  // 64 KB par strip

/// Niveaux RAID supportes - Les differents types de Jaegers
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RaidLevel {
    /// RAID 0 - Striker Eureka: Pure vitesse, zero protection
    Raid0,
    /// RAID 1 - Gipsy Danger: Deux pilotes synchronises, miroir parfait
    Raid1,
    /// RAID 5 - Crimson Typhoon: Triplets Wei, parite distribuee
    Raid5,
    /// RAID 6 - Cherno Alpha: Double blindage russe
    Raid6,
}

/// Statut d'un disque virtuel - Etat d'un pilote
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum DiskStatus {
    /// Disque operationnel - Pilote en pleine forme
    Online,
    /// Disque defaillant - Pilote KO par Kaiju
    Failed,
    /// Disque en reconstruction - Neural Handshake en cours
    Rebuilding,
    /// Disque de reserve - Pilote au Shatterdome
    HotSpare,
}

/// Erreur de disque individuel
#[derive(Debug, Clone)]
pub enum DiskError {
    /// Disque hors ligne - Pilote inconscient
    Failed,
    /// Erreur de lecture irrecuperable - Corruption neurale
    URE,
    /// Acces hors limites - Memoire non mappee
    OutOfBounds,
}

/// Erreur au niveau RAID
#[derive(Debug, Clone)]
pub enum RaidError {
    /// Erreur sur un disque specifique
    DiskError(usize, DiskError),
    /// Trop de pannes pour le niveau RAID
    TooManyFailures,
    /// Aucun hot spare disponible
    NoHotSpare,
    /// Donnees corrompues irreparables
    DataCorrupted,
    /// Echec de reconstruction
    RebuildFailed,
    /// Configuration invalide
    InvalidConfig(String),
}

/// Disque virtuel - Un pilote de Jaeger
#[derive(Debug)]
pub struct VirtualDisk {
    /// Identifiant unique du disque
    pub id: usize,
    /// Statut actuel
    pub status: DiskStatus,
    /// Donnees stockees
    data: Vec<u8>,
    /// Capacite totale
    pub capacity: usize,
    /// Probabilite d'URE par lecture (0.0 - 1.0)
    pub ure_probability: f64,
    /// Compteur de lectures
    pub read_count: u64,
    /// Compteur d'ecritures
    pub write_count: u64,
}

impl VirtualDisk {
    /// Creer un nouveau disque virtuel
    pub fn new(id: usize, capacity: usize) -> Self {
        VirtualDisk {
            id,
            status: DiskStatus::Online,
            data: vec![0u8; capacity],
            capacity,
            ure_probability: 0.0,
            read_count: 0,
            write_count: 0,
        }
    }

    /// Lire des donnees avec simulation d'URE
    pub fn read(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, DiskError> {
        todo!("Implementer lecture avec simulation URE probabiliste")
    }

    /// Ecrire des donnees
    pub fn write(&mut self, offset: usize, data: &[u8]) -> Result<(), DiskError> {
        todo!("Implementer ecriture avec verification de statut")
    }

    /// Simuler une panne - Kaiju hit!
    pub fn fail(&mut self) {
        self.status = DiskStatus::Failed;
    }

    /// Verifier si le disque est operationnel
    pub fn is_operational(&self) -> bool {
        self.status == DiskStatus::Online || self.status == DiskStatus::Rebuilding
    }
}

/// Array RAID - Le Jaeger complet
pub struct RaidArray {
    /// Niveau RAID (type de Jaeger)
    level: RaidLevel,
    /// Disques de l'array (pilotes actifs)
    disks: Vec<VirtualDisk>,
    /// Disques de reserve (pilotes au Shatterdome)
    hot_spares: Vec<VirtualDisk>,
    /// Taille d'un stripe
    stripe_size: usize,
    /// Nombre de stripes
    stripe_count: usize,
    /// Set des disques en panne
    failed_disks: HashSet<usize>,
    /// Progression du rebuild (disk_id, progress_bytes)
    rebuild_progress: Option<(usize, usize)>,
}

impl RaidArray {
    /// Deployer un nouveau Jaeger (creer l'array RAID)
    pub fn new(level: RaidLevel, disk_count: usize, disk_capacity: usize) -> Result<Self, RaidError> {
        todo!("Creer le RAID avec validation du niveau vs nombre de disques")
    }

    /// Ajouter un pilote de reserve au Shatterdome
    pub fn add_hot_spare(&mut self, disk: VirtualDisk) {
        todo!("Ajouter un hot spare")
    }

    /// Capacite utilisable du RAID apres redondance
    pub fn usable_capacity(&self) -> usize {
        todo!("Calculer selon le niveau RAID")
    }

    /// Ecrire des donnees - Neural Drift Write
    pub fn write(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        match self.level {
            RaidLevel::Raid0 => self.write_raid0(offset, data),
            RaidLevel::Raid1 => self.write_raid1(offset, data),
            RaidLevel::Raid5 => self.write_raid5(offset, data),
            RaidLevel::Raid6 => self.write_raid6(offset, data),
        }
    }

    /// Lire des donnees - Neural Drift Read
    pub fn read(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        match self.level {
            RaidLevel::Raid0 => self.read_raid0(offset, length),
            RaidLevel::Raid1 => self.read_raid1(offset, length),
            RaidLevel::Raid5 => self.read_raid5(offset, length),
            RaidLevel::Raid6 => self.read_raid6(offset, length),
        }
    }

    // ============ RAID 0 - STRIKER EUREKA ============

    /// Ecriture RAID 0 - Striping pur, vitesse maximale
    fn write_raid0(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        todo!("Distribuer les donnees sur tous les disques")
    }

    /// Lecture RAID 0 - Aucune reconstruction possible
    fn read_raid0(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        todo!("Lire depuis les stripes, echouer si un disque est KO")
    }

    // ============ RAID 1 - GIPSY DANGER ============

    /// Ecriture RAID 1 - Miroir sur tous les disques
    fn write_raid1(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        todo!("Ecrire sur tous les miroirs operationnels")
    }

    /// Lecture RAID 1 - Lire depuis n'importe quel miroir valide
    fn read_raid1(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        todo!("Lire depuis le premier miroir disponible")
    }

    // ============ RAID 5 - CRIMSON TYPHOON ============

    /// Ecriture RAID 5 - Donnees + parite distribuee
    fn write_raid5(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        todo!("Ecrire avec calcul et distribution de parite XOR")
    }

    /// Lecture RAID 5 - Reconstruction si necessaire
    fn read_raid5(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        todo!("Lire avec reconstruction via XOR si un disque est KO")
    }

    /// Calculer la parite XOR d'un ensemble de strips
    fn calculate_parity(&self, strips: &[Vec<u8>]) -> Vec<u8> {
        todo!("XOR de tous les strips")
    }

    /// Determiner quel disque contient la parite pour un stripe donne
    fn parity_disk_for_stripe(&self, stripe_num: usize) -> usize {
        todo!("Rotation de la parite: (n_disks - 1 - stripe % n_disks)")
    }

    /// Reconstruire un strip manquant via XOR des autres
    fn reconstruct_strip(&mut self, stripe_num: usize, missing_disk: usize) -> Result<Vec<u8>, RaidError> {
        todo!("D_missing = D0 XOR D1 XOR ... XOR P (excluant missing)")
    }

    // ============ RAID 6 - CHERNO ALPHA ============

    /// Ecriture RAID 6 - Double parite (P + Q)
    fn write_raid6(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        todo!("Ecrire avec P (XOR) et Q (Reed-Solomon simplifie)")
    }

    /// Lecture RAID 6 - Reconstruction meme avec 2 pannes
    fn read_raid6(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        todo!("Reconstruire via P et/ou Q selon les pannes")
    }

    /// Calculer la parite Q (Reed-Solomon simplifie)
    fn calculate_q_parity(&self, strips: &[Vec<u8>]) -> Vec<u8> {
        todo!("Q = g^0*D0 XOR g^1*D1 XOR ... avec g=0x02 dans GF(2^8)")
    }

    // ============ GESTION DES PANNES ============

    /// Simuler une panne de disque - Kaiju hit!
    pub fn fail_disk(&mut self, disk_id: usize) -> Result<(), RaidError> {
        todo!("Marquer le disque comme failed, verifier tolerance")
    }

    /// Verifier si l'array est en mode degrade
    pub fn is_degraded(&self) -> bool {
        !self.failed_disks.is_empty()
    }

    /// Obtenir le nombre de pannes tolerables restantes
    pub fn remaining_fault_tolerance(&self) -> usize {
        todo!("Calculer selon niveau RAID et pannes actuelles")
    }

    // ============ HOT SPARE & REBUILD ============

    /// Activer un hot spare pour remplacer un disque KO
    pub fn activate_hot_spare(&mut self) -> Result<(), RaidError> {
        todo!("Prendre un spare, remplacer le disque KO, lancer rebuild")
    }

    /// Demarrer la reconstruction sur un disque cible
    pub fn start_rebuild(&mut self, target_disk: usize) -> Result<(), RaidError> {
        todo!("Initialiser le processus de rebuild")
    }

    /// Executer une etape de reconstruction
    /// Retourne true si la reconstruction est terminee
    pub fn rebuild_step(&mut self) -> Result<bool, RaidError> {
        todo!("Reconstruire un chunk, mettre a jour progress")
    }

    /// Obtenir le pourcentage de completion du rebuild
    pub fn get_rebuild_progress(&self) -> Option<f64> {
        todo!("progress_bytes / capacity * 100")
    }

    // ============ STATISTIQUES ============

    /// Obtenir le statut complet de l'array
    pub fn status(&self) -> RaidStatus {
        RaidStatus {
            level: self.level,
            total_disks: self.disks.len(),
            failed_disks: self.failed_disks.len(),
            hot_spares: self.hot_spares.len(),
            capacity_bytes: self.usable_capacity(),
            is_degraded: self.is_degraded(),
            is_rebuilding: self.rebuild_progress.is_some(),
        }
    }
}

/// Statut complet d'un array RAID
#[derive(Debug, Clone)]
pub struct RaidStatus {
    pub level: RaidLevel,
    pub total_disks: usize,
    pub failed_disks: usize,
    pub hot_spares: usize,
    pub capacity_bytes: usize,
    pub is_degraded: bool,
    pub is_rebuilding: bool,
}

/// Simuler une charge de travail avec pannes aleatoires
pub fn simulate_workload(
    raid: &mut RaidArray,
    operations: &[(bool, usize, usize)],  // (is_write, offset, length)
    failure_probability: f64,
) -> SimulationResult {
    todo!("Executer les operations avec pannes simulees aleatoires")
}

/// Resultat d'une simulation de charge
#[derive(Debug, Clone)]
pub struct SimulationResult {
    pub successful_ops: usize,
    pub failed_ops: usize,
    pub disk_failures: usize,
    pub ure_count: usize,
    pub data_loss: bool,
}
```

---

## SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 L'Histoire du RAID

RAID (Redundant Array of Independent Disks) a ete invente en 1988 a l'Universite de Berkeley par Patterson, Gibson et Katz. L'idee etait simple mais revolutionnaire : combiner plusieurs disques bon marche pour obtenir les performances ET la fiabilite d'un disque haut de gamme couteux.

Le terme original etait "Redundant Array of **Inexpensive** Disks" - l'industrie l'a change en "Independent" pour des raisons marketing!

### 2.2 La Magie du XOR

```
    POURQUOI XOR EST MAGIQUE POUR LA PARITE

    Propriete fondamentale: A âŠ• B âŠ• B = A

    Exemple concret:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Disk 0 (D0):  1 0 1 1 0 1 0 0  = 0xB4    â”‚
    â”‚  Disk 1 (D1):  0 1 1 0 1 0 1 1  = 0x6B    â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚  Parity (P):   1 1 0 1 1 1 1 1  = 0xDF    â”‚
    â”‚                                            â”‚
    â”‚  Verification: D0 âŠ• D1 = 0xB4 âŠ• 0x6B     â”‚
    â”‚                       = 0xDF âœ“            â”‚
    â”‚                                            â”‚
    â”‚  Si D1 tombe:                              â”‚
    â”‚  D1 = D0 âŠ• P = 0xB4 âŠ• 0xDF = 0x6B âœ“      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 URE - Le Tueur Silencieux

Un URE (Unrecoverable Read Error) est une erreur de lecture que le disque ne peut pas corriger. Avec les disques modernes de grande capacite, la probabilite d'URE pendant un rebuild est significative :

- Disque entreprise : 1 URE pour 10^15 bits lus
- Disque desktop : 1 URE pour 10^14 bits lus
- Sur un rebuild de 4TB : ~3% de chance d'URE!

C'est pourquoi RAID 6 devient essentiel pour les grandes capacites.

---

### 2.5 DANS LA VRAIE VIE

| Metier | Usage RAID | Niveau Typique | Pourquoi |
|--------|-----------|----------------|----------|
| **SysAdmin Linux** | Serveurs web/mail | RAID 5/6 | Bon compromis capacite/securite |
| **DBA PostgreSQL** | Bases de donnees critiques | RAID 10 | Performance I/O + redondance |
| **DevOps Cloud** | Kubernetes storage | RAID 6 + erasure coding | Haute disponibilite |
| **Data Engineer** | Data lakes | RAID 0 + replication | Throughput massif |
| **Monteur Video** | Scratch disks | RAID 0 | Vitesse pure, donnees temporaires |
| **NAS Personnel** | Synology/QNAP | RAID 1 ou SHR | Simplicite + protection |
| **Datacenter** | Enterprise storage | RAID 6 + Hot Spare | Zero data loss policy |

---

## SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ ls
Cargo.toml  src/  tests/

$ cargo build --release
   Compiling raid_simulator v0.1.0
    Finished release [optimized] target(s) in 2.34s

$ cargo test
running 12 tests
test test_raid0_striping ... ok
test test_raid0_no_redundancy ... ok
test test_raid1_mirroring ... ok
test test_raid1_degraded ... ok
test test_raid5_parity ... ok
test test_raid5_reconstruction ... ok
test test_raid5_two_failures ... ok
test test_raid6_double_parity ... ok
test test_hot_spare_activation ... ok
test test_rebuild_progress ... ok
test test_ure_simulation ... ok
test test_usable_capacity ... ok

test result: ok. 12 passed; 0 failed; 0 ignored

$ cargo run --example demo
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           SHATTERDOME - KAIJU SHIELD ARRAY DEMO              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  "Today we are cancelling the data loss!"                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[DEPLOY] Crimson Typhoon (RAID 5) - 4 disks x 1MB
  â†’ Total capacity: 4 MB
  â†’ Usable capacity: 3 MB (75% efficiency)
  â†’ Fault tolerance: 1 disk

[WRITE] 4096 bytes at offset 0
  â†’ Stripe 0: D0â†’Disk0, D1â†’Disk1, D2â†’Disk2, Pâ†’Disk3
  â†’ Parity calculated: 0xA7

[KAIJU ATTACK] Disk 1 failed! Entering degraded mode...
  â†’ Array still operational (1 failure tolerated)

[READ] 4096 bytes at offset 0 (degraded)
  â†’ Reconstructing Disk1 data via XOR
  â†’ D1 = D0 âŠ• D2 âŠ• P
  â†’ Data integrity: VERIFIED

[HOT SPARE] Activating reserve disk...
[REBUILD] Starting reconstruction...
  â†’ Progress: 25%... 50%... 75%... 100%
[REBUILD] Complete! Array fully operational.

All tests passed! The data apocalypse has been cancelled.
```

---

### 3.1 BONUS EXPERT : GALOIS FIELD RAID 6 (OPTIONNEL)

**Difficulte Bonus :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜† (9/10)

**Recompense :**
XP x4

**Time Complexity attendue :**
O(n) pour P, O(n) pour Q avec multiplication Galois Field

**Space Complexity attendue :**
O(1) auxiliaire (tables pre-calculees OK)

**Domaines Bonus :**
`MD, Crypto, Encodage`

#### 3.1.1 Consigne Bonus

**NIVEAU KAIJU CATEGORIE 5 : VRAI REED-SOLOMON**

*"Cherno Alpha wasn't built with double shields by accident."*

RAID 6 standard utilise une parite Q simplifiee. Le vrai Reed-Solomon utilise l'arithmetique dans un corps de Galois GF(2^8) :

- **P** = D0 XOR D1 XOR D2 XOR ... (classique)
- **Q** = g^0*D0 XOR g^1*D1 XOR g^2*D2 XOR ... (Galois)

Avec `g = 0x02` (generateur) et le polynome irreductible `x^8 + x^4 + x^3 + x^2 + 1` (0x11D).

**Ta mission :**

Implementer les operations GF(2^8) et la reconstruction dual-failure :

```rust
/// Operations dans le corps de Galois GF(2^8)
pub mod galois {
    /// Multiplication dans GF(2^8)
    pub fn gf_mult(a: u8, b: u8) -> u8 {
        todo!("Multiplication avec reduction polynomiale")
    }

    /// Division dans GF(2^8)
    pub fn gf_div(a: u8, b: u8) -> u8 {
        todo!("a * inverse(b)")
    }

    /// Inverse multiplicatif dans GF(2^8)
    pub fn gf_inv(a: u8) -> u8 {
        todo!("Utiliser table pre-calculee ou extended Euclidean")
    }

    /// Puissance dans GF(2^8)
    pub fn gf_pow(base: u8, exp: u8) -> u8 {
        todo!("Exponentiation rapide")
    }
}

/// Reconstruction avec 2 disques manquants
pub fn reconstruct_dual_failure(
    raid: &mut RaidArray,
    missing1: usize,
    missing2: usize,
    stripe: usize,
) -> Result<(Vec<u8>, Vec<u8>), RaidError> {
    todo!("Resoudre systeme lineaire 2x2 dans GF(2^8)")
}
```

**Contraintes :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GF(2^8) multiplication : O(1) via LUT  â”‚
â”‚  Reconstruction : systeme 2x2           â”‚
â”‚  Tables pre-calculees : autorisees      â”‚
â”‚  No unsafe : bonus style points         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.1.2 Ce qui change par rapport a l'exercice de base

| Aspect | Base | Bonus |
|--------|------|-------|
| Q Parity | Simple ponderation | GF(2^8) multiplication |
| Dual reconstruction | Non supporte | Resolution systeme lineaire |
| Tables | Aucune | gf_log[], gf_exp[] pre-calculees |
| Math | XOR simple | Corps finis, algebre lineaire |

---

## SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette

| Test | Input | Expected | Points | Concept |
|------|-------|----------|--------|---------|
| `test_raid_new` | Valid config | Ok(RaidArray) | 5 | Core |
| `test_raid0_striping` | R0 + data | Data intact | 10 | Striping |
| `test_raid0_failure` | R0 + fail 1 | Err(TooManyFailures) | 5 | Zero redundancy |
| `test_raid1_mirror` | R1 + data | Identical copies | 10 | Mirroring |
| `test_raid1_degraded` | R1 + fail 1 | Ok(data) | 5 | Degraded read |
| `test_raid5_parity` | R5 + stripe | XOR correct | 10 | Parity calc |
| `test_raid5_parity_rotation` | R5 + 4 stripes | Parity rotates | 5 | Distribution |
| `test_raid5_reconstruct` | R5 + fail 1 | Reconstructed data | 10 | XOR rebuild |
| `test_raid5_two_failures` | R5 + fail 2 | Err(TooManyFailures) | 5 | Tolerance |
| `test_raid6_dual_parity` | R6 + P + Q | Both correct | 10 | Double parity |
| `test_raid6_single_fail` | R6 + fail 1 | Ok(data) | 5 | Single reconstruct |
| `test_raid6_double_fail` | R6 + fail 2 | Ok(data) | 10 | Dual reconstruct |
| `test_hot_spare_add` | Add spare | spare_count++ | 3 | Hot spare |
| `test_hot_spare_activate` | Fail + activate | Seamless replace | 7 | Activation |
| `test_rebuild_progress` | Start rebuild | 0.0 â†’ 1.0 | 5 | Progress tracking |
| `test_rebuild_complete` | Full rebuild | is_degraded = false | 5 | Completion |
| `test_ure_simulation` | URE probability | Some errors | 5 | URE |
| `test_usable_capacity` | All levels | Correct values | 5 | Capacity calc |
| **TOTAL** | | | **100** | |
| **BONUS** | GF(2^8) dual | Works | **20** | Reed-Solomon |

---

### 4.2 main.rs de test

```rust
// tests/integration_tests.rs
use raid_simulator::*;

const MB: usize = 1024 * 1024;

#[test]
fn test_raid0_striping() {
    let mut raid = RaidArray::new(RaidLevel::Raid0, 4, MB).unwrap();

    let data = vec![0x42u8; STRIP_SIZE * 8];
    raid.write(0, &data).unwrap();

    let read_data = raid.read(0, data.len()).unwrap();
    assert_eq!(data, read_data, "Data mismatch after read");
}

#[test]
fn test_raid0_no_redundancy() {
    let mut raid = RaidArray::new(RaidLevel::Raid0, 4, MB).unwrap();

    raid.write(0, &[0x42; STRIP_SIZE * 4]).unwrap();
    raid.fail_disk(0).unwrap();

    // Must fail - no redundancy in RAID 0
    assert!(raid.read(0, STRIP_SIZE).is_err());
}

#[test]
fn test_raid1_mirroring() {
    let mut raid = RaidArray::new(RaidLevel::Raid1, 2, MB).unwrap();

    let data = vec![0x42u8; 1024];
    raid.write(0, &data).unwrap();

    // Fail one disk
    raid.fail_disk(0).unwrap();

    // Should read from mirror
    let read_data = raid.read(0, 1024).unwrap();
    assert_eq!(data, read_data);
}

#[test]
fn test_raid5_parity() {
    let mut raid = RaidArray::new(RaidLevel::Raid5, 4, MB).unwrap();

    let data = vec![0x42u8; STRIP_SIZE * 3];
    raid.write(0, &data).unwrap();

    // Fail one disk
    raid.fail_disk(1).unwrap();

    // Should reconstruct via parity
    let read_data = raid.read(0, data.len()).unwrap();
    assert_eq!(data, read_data, "Reconstruction failed");
}

#[test]
fn test_raid5_two_failures() {
    let mut raid = RaidArray::new(RaidLevel::Raid5, 4, MB).unwrap();

    raid.write(0, &[0x42; STRIP_SIZE * 3]).unwrap();

    raid.fail_disk(0).unwrap();
    raid.fail_disk(1).unwrap();

    // Must fail with 2 failures in RAID 5
    assert!(raid.read(0, STRIP_SIZE).is_err());
}

#[test]
fn test_raid6_double_parity() {
    let mut raid = RaidArray::new(RaidLevel::Raid6, 5, MB).unwrap();

    let data = vec![0x42u8; STRIP_SIZE * 3];
    raid.write(0, &data).unwrap();

    // Fail TWO disks
    raid.fail_disk(0).unwrap();
    raid.fail_disk(2).unwrap();

    // Should reconstruct via double parity
    let read_data = raid.read(0, data.len()).unwrap();
    assert_eq!(data, read_data);
}

#[test]
fn test_hot_spare_activation() {
    let mut raid = RaidArray::new(RaidLevel::Raid5, 4, MB).unwrap();
    raid.add_hot_spare(VirtualDisk::new(99, MB));

    raid.write(0, &[0x42; STRIP_SIZE * 3]).unwrap();

    // Fail disk to trigger hot spare
    raid.fail_disk(1).unwrap();

    // Activate and rebuild
    raid.activate_hot_spare().unwrap();
    while !raid.rebuild_step().unwrap() {}

    assert!(!raid.is_degraded(), "Should not be degraded after rebuild");
    assert_eq!(raid.status().hot_spares, 0, "Hot spare should be used");
}

#[test]
fn test_rebuild_progress() {
    let mut raid = RaidArray::new(RaidLevel::Raid5, 4, MB).unwrap();
    raid.add_hot_spare(VirtualDisk::new(99, MB));

    raid.write(0, &[0x42; STRIP_SIZE * 100]).unwrap();
    raid.fail_disk(1).unwrap();
    raid.activate_hot_spare().unwrap();

    let mut progress = raid.get_rebuild_progress().unwrap();
    assert!(progress < 1.0);

    while !raid.rebuild_step().unwrap() {
        let new_progress = raid.get_rebuild_progress().unwrap();
        assert!(new_progress >= progress, "Progress should increase");
        progress = new_progress;
    }

    assert!(raid.get_rebuild_progress().is_none(), "No progress after complete");
}

#[test]
fn test_ure_simulation() {
    let mut raid = RaidArray::new(RaidLevel::Raid5, 4, MB).unwrap();

    // Set 10% URE probability on disk 0
    // raid.disks[0].ure_probability = 0.1;

    raid.write(0, &[0x42; STRIP_SIZE * 100]).unwrap();

    // Fail a different disk
    raid.fail_disk(1).unwrap();

    // Some reads may fail due to URE during reconstruction
    let mut ure_count = 0;
    for i in 0..100 {
        if raid.read(i * STRIP_SIZE, STRIP_SIZE).is_err() {
            ure_count += 1;
        }
    }

    println!("URE count: {}", ure_count);
    // With 10% URE, expect ~10 failures
}

#[test]
fn test_usable_capacity() {
    // RAID 0: full capacity
    let raid0 = RaidArray::new(RaidLevel::Raid0, 4, MB).unwrap();
    assert_eq!(raid0.usable_capacity(), 4 * MB);

    // RAID 1: half capacity
    let raid1 = RaidArray::new(RaidLevel::Raid1, 2, MB).unwrap();
    assert_eq!(raid1.usable_capacity(), MB);

    // RAID 5: N-1
    let raid5 = RaidArray::new(RaidLevel::Raid5, 4, MB).unwrap();
    assert_eq!(raid5.usable_capacity(), 3 * MB);

    // RAID 6: N-2
    let raid6 = RaidArray::new(RaidLevel::Raid6, 5, MB).unwrap();
    assert_eq!(raid6.usable_capacity(), 3 * MB);
}
```

---

### 4.3 Solution de reference

```rust
// src/lib.rs - Reference Implementation (extrait)
use std::collections::HashSet;

pub const STRIP_SIZE: usize = 64 * 1024;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum RaidLevel { Raid0, Raid1, Raid5, Raid6 }

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum DiskStatus { Online, Failed, Rebuilding, HotSpare }

#[derive(Debug, Clone)]
pub enum DiskError { Failed, URE, OutOfBounds }

#[derive(Debug, Clone)]
pub enum RaidError {
    DiskError(usize, DiskError),
    TooManyFailures,
    NoHotSpare,
    DataCorrupted,
    RebuildFailed,
    InvalidConfig(String),
}

#[derive(Debug)]
pub struct VirtualDisk {
    pub id: usize,
    pub status: DiskStatus,
    data: Vec<u8>,
    pub capacity: usize,
    pub ure_probability: f64,
    pub read_count: u64,
    pub write_count: u64,
}

impl VirtualDisk {
    pub fn new(id: usize, capacity: usize) -> Self {
        VirtualDisk {
            id,
            status: DiskStatus::Online,
            data: vec![0u8; capacity],
            capacity,
            ure_probability: 0.0,
            read_count: 0,
            write_count: 0,
        }
    }

    pub fn read(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, DiskError> {
        if self.status == DiskStatus::Failed {
            return Err(DiskError::Failed);
        }
        if offset + length > self.capacity {
            return Err(DiskError::OutOfBounds);
        }

        // Simulate URE
        if self.ure_probability > 0.0 {
            let random: f64 = (self.read_count as f64 * 0.1234).fract();
            if random < self.ure_probability {
                return Err(DiskError::URE);
            }
        }

        self.read_count += 1;
        Ok(self.data[offset..offset + length].to_vec())
    }

    pub fn write(&mut self, offset: usize, data: &[u8]) -> Result<(), DiskError> {
        if self.status == DiskStatus::Failed {
            return Err(DiskError::Failed);
        }
        if offset + data.len() > self.capacity {
            return Err(DiskError::OutOfBounds);
        }

        self.data[offset..offset + data.len()].copy_from_slice(data);
        self.write_count += 1;
        Ok(())
    }

    pub fn fail(&mut self) {
        self.status = DiskStatus::Failed;
    }

    pub fn is_operational(&self) -> bool {
        self.status == DiskStatus::Online || self.status == DiskStatus::Rebuilding
    }
}

pub struct RaidArray {
    level: RaidLevel,
    disks: Vec<VirtualDisk>,
    hot_spares: Vec<VirtualDisk>,
    stripe_size: usize,
    failed_disks: HashSet<usize>,
    rebuild_progress: Option<(usize, usize)>,
}

impl RaidArray {
    pub fn new(level: RaidLevel, disk_count: usize, disk_capacity: usize) -> Result<Self, RaidError> {
        // Validate configuration
        match level {
            RaidLevel::Raid0 if disk_count < 2 => {
                return Err(RaidError::InvalidConfig("RAID 0 needs at least 2 disks".into()));
            }
            RaidLevel::Raid1 if disk_count < 2 => {
                return Err(RaidError::InvalidConfig("RAID 1 needs at least 2 disks".into()));
            }
            RaidLevel::Raid5 if disk_count < 3 => {
                return Err(RaidError::InvalidConfig("RAID 5 needs at least 3 disks".into()));
            }
            RaidLevel::Raid6 if disk_count < 4 => {
                return Err(RaidError::InvalidConfig("RAID 6 needs at least 4 disks".into()));
            }
            _ => {}
        }

        let disks: Vec<VirtualDisk> = (0..disk_count)
            .map(|id| VirtualDisk::new(id, disk_capacity))
            .collect();

        Ok(RaidArray {
            level,
            disks,
            hot_spares: Vec::new(),
            stripe_size: STRIP_SIZE,
            failed_disks: HashSet::new(),
            rebuild_progress: None,
        })
    }

    pub fn add_hot_spare(&mut self, mut disk: VirtualDisk) {
        disk.status = DiskStatus::HotSpare;
        self.hot_spares.push(disk);
    }

    pub fn usable_capacity(&self) -> usize {
        let disk_cap = self.disks.first().map_or(0, |d| d.capacity);
        let n = self.disks.len();

        match self.level {
            RaidLevel::Raid0 => n * disk_cap,
            RaidLevel::Raid1 => disk_cap,
            RaidLevel::Raid5 => (n - 1) * disk_cap,
            RaidLevel::Raid6 => (n - 2) * disk_cap,
        }
    }

    pub fn write(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        match self.level {
            RaidLevel::Raid0 => self.write_raid0(offset, data),
            RaidLevel::Raid1 => self.write_raid1(offset, data),
            RaidLevel::Raid5 => self.write_raid5(offset, data),
            RaidLevel::Raid6 => self.write_raid6(offset, data),
        }
    }

    pub fn read(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        match self.level {
            RaidLevel::Raid0 => self.read_raid0(offset, length),
            RaidLevel::Raid1 => self.read_raid1(offset, length),
            RaidLevel::Raid5 => self.read_raid5(offset, length),
            RaidLevel::Raid6 => self.read_raid6(offset, length),
        }
    }

    // RAID 0 - Striping
    fn write_raid0(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        let mut written = 0;
        while written < data.len() {
            let stripe = (offset + written) / self.stripe_size;
            let disk_idx = stripe % self.disks.len();
            let disk_offset = (stripe / self.disks.len()) * self.stripe_size
                + ((offset + written) % self.stripe_size);

            let chunk_size = (self.stripe_size - ((offset + written) % self.stripe_size))
                .min(data.len() - written);

            self.disks[disk_idx]
                .write(disk_offset, &data[written..written + chunk_size])
                .map_err(|e| RaidError::DiskError(disk_idx, e))?;

            written += chunk_size;
        }
        Ok(written)
    }

    fn read_raid0(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        if !self.failed_disks.is_empty() {
            return Err(RaidError::TooManyFailures);
        }

        let mut result = vec![0u8; length];
        let mut read_bytes = 0;

        while read_bytes < length {
            let stripe = (offset + read_bytes) / self.stripe_size;
            let disk_idx = stripe % self.disks.len();
            let disk_offset = (stripe / self.disks.len()) * self.stripe_size
                + ((offset + read_bytes) % self.stripe_size);

            let chunk_size = (self.stripe_size - ((offset + read_bytes) % self.stripe_size))
                .min(length - read_bytes);

            let data = self.disks[disk_idx]
                .read(disk_offset, chunk_size)
                .map_err(|e| RaidError::DiskError(disk_idx, e))?;

            result[read_bytes..read_bytes + chunk_size].copy_from_slice(&data);
            read_bytes += chunk_size;
        }

        Ok(result)
    }

    // RAID 1 - Mirroring
    fn write_raid1(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        for (idx, disk) in self.disks.iter_mut().enumerate() {
            if disk.is_operational() {
                disk.write(offset, data)
                    .map_err(|e| RaidError::DiskError(idx, e))?;
            }
        }
        Ok(data.len())
    }

    fn read_raid1(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        for (idx, disk) in self.disks.iter_mut().enumerate() {
            if disk.is_operational() {
                if let Ok(data) = disk.read(offset, length) {
                    return Ok(data);
                }
            }
        }
        Err(RaidError::TooManyFailures)
    }

    // RAID 5 - Distributed Parity
    fn parity_disk_for_stripe(&self, stripe_num: usize) -> usize {
        self.disks.len() - 1 - (stripe_num % self.disks.len())
    }

    fn calculate_parity(&self, strips: &[Vec<u8>]) -> Vec<u8> {
        let len = strips.first().map_or(0, |s| s.len());
        let mut parity = vec![0u8; len];

        for strip in strips {
            for (i, byte) in strip.iter().enumerate() {
                parity[i] ^= byte;
            }
        }

        parity
    }

    fn write_raid5(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        let data_disks = self.disks.len() - 1;
        let mut written = 0;

        while written < data.len() {
            let logical_offset = offset + written;
            let stripe = logical_offset / (self.stripe_size * data_disks);
            let parity_disk = self.parity_disk_for_stripe(stripe);

            let stripe_offset = logical_offset % (self.stripe_size * data_disks);
            let data_disk_idx = stripe_offset / self.stripe_size;

            let actual_disk = if data_disk_idx >= parity_disk {
                data_disk_idx + 1
            } else {
                data_disk_idx
            };

            let disk_offset = stripe * self.stripe_size + (stripe_offset % self.stripe_size);
            let chunk_size = (self.stripe_size - (stripe_offset % self.stripe_size))
                .min(data.len() - written);

            // Write data
            self.disks[actual_disk]
                .write(disk_offset, &data[written..written + chunk_size])
                .map_err(|e| RaidError::DiskError(actual_disk, e))?;

            // Update parity (simplified - full implementation would read-modify-write)
            let old_data = self.disks[parity_disk]
                .read(disk_offset, chunk_size)
                .unwrap_or(vec![0u8; chunk_size]);

            let mut new_parity = old_data;
            for (i, byte) in data[written..written + chunk_size].iter().enumerate() {
                new_parity[i] ^= byte;
            }

            self.disks[parity_disk]
                .write(disk_offset, &new_parity)
                .map_err(|e| RaidError::DiskError(parity_disk, e))?;

            written += chunk_size;
        }

        Ok(written)
    }

    fn read_raid5(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        if self.failed_disks.len() > 1 {
            return Err(RaidError::TooManyFailures);
        }

        let data_disks = self.disks.len() - 1;
        let mut result = vec![0u8; length];
        let mut read_bytes = 0;

        while read_bytes < length {
            let logical_offset = offset + read_bytes;
            let stripe = logical_offset / (self.stripe_size * data_disks);
            let parity_disk = self.parity_disk_for_stripe(stripe);

            let stripe_offset = logical_offset % (self.stripe_size * data_disks);
            let data_disk_idx = stripe_offset / self.stripe_size;

            let actual_disk = if data_disk_idx >= parity_disk {
                data_disk_idx + 1
            } else {
                data_disk_idx
            };

            let disk_offset = stripe * self.stripe_size + (stripe_offset % self.stripe_size);
            let chunk_size = (self.stripe_size - (stripe_offset % self.stripe_size))
                .min(length - read_bytes);

            let data = if self.failed_disks.contains(&actual_disk) {
                // Reconstruct via XOR
                self.reconstruct_chunk(stripe, actual_disk, disk_offset, chunk_size)?
            } else {
                self.disks[actual_disk]
                    .read(disk_offset, chunk_size)
                    .map_err(|e| RaidError::DiskError(actual_disk, e))?
            };

            result[read_bytes..read_bytes + chunk_size].copy_from_slice(&data);
            read_bytes += chunk_size;
        }

        Ok(result)
    }

    fn reconstruct_chunk(&mut self, _stripe: usize, missing: usize, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        let mut reconstructed = vec![0u8; length];

        for (idx, disk) in self.disks.iter_mut().enumerate() {
            if idx != missing && disk.is_operational() {
                let data = disk.read(offset, length)
                    .map_err(|e| RaidError::DiskError(idx, e))?;
                for (i, byte) in data.iter().enumerate() {
                    reconstructed[i] ^= byte;
                }
            }
        }

        Ok(reconstructed)
    }

    // RAID 6 (simplified)
    fn write_raid6(&mut self, offset: usize, data: &[u8]) -> Result<usize, RaidError> {
        // Simplified: treat like RAID 5 with extra parity
        self.write_raid5(offset, data)
    }

    fn read_raid6(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
        if self.failed_disks.len() > 2 {
            return Err(RaidError::TooManyFailures);
        }
        // Simplified: same as RAID 5 for single failure
        self.read_raid5(offset, length)
    }

    pub fn fail_disk(&mut self, disk_id: usize) -> Result<(), RaidError> {
        if disk_id >= self.disks.len() {
            return Err(RaidError::InvalidConfig("Invalid disk ID".into()));
        }

        self.disks[disk_id].fail();
        self.failed_disks.insert(disk_id);

        let tolerance = match self.level {
            RaidLevel::Raid0 => 0,
            RaidLevel::Raid1 => self.disks.len() - 1,
            RaidLevel::Raid5 => 1,
            RaidLevel::Raid6 => 2,
        };

        if self.failed_disks.len() > tolerance {
            return Err(RaidError::TooManyFailures);
        }

        Ok(())
    }

    pub fn is_degraded(&self) -> bool {
        !self.failed_disks.is_empty()
    }

    pub fn activate_hot_spare(&mut self) -> Result<(), RaidError> {
        if self.hot_spares.is_empty() {
            return Err(RaidError::NoHotSpare);
        }

        let failed_id = *self.failed_disks.iter().next()
            .ok_or(RaidError::InvalidConfig("No failed disk".into()))?;

        let mut spare = self.hot_spares.remove(0);
        spare.status = DiskStatus::Rebuilding;
        spare.id = failed_id;

        self.disks[failed_id] = spare;
        self.rebuild_progress = Some((failed_id, 0));

        Ok(())
    }

    pub fn rebuild_step(&mut self) -> Result<bool, RaidError> {
        let (disk_id, progress) = self.rebuild_progress
            .ok_or(RaidError::RebuildFailed)?;

        let capacity = self.disks[disk_id].capacity;
        let chunk = self.stripe_size.min(capacity - progress);

        if progress >= capacity {
            self.disks[disk_id].status = DiskStatus::Online;
            self.failed_disks.remove(&disk_id);
            self.rebuild_progress = None;
            return Ok(true);
        }

        // Reconstruct chunk
        let reconstructed = self.reconstruct_chunk(0, disk_id, progress, chunk)?;
        self.disks[disk_id].write(progress, &reconstructed)
            .map_err(|e| RaidError::DiskError(disk_id, e))?;

        self.rebuild_progress = Some((disk_id, progress + chunk));
        Ok(false)
    }

    pub fn get_rebuild_progress(&self) -> Option<f64> {
        self.rebuild_progress.map(|(disk_id, progress)| {
            progress as f64 / self.disks[disk_id].capacity as f64
        })
    }

    pub fn status(&self) -> RaidStatus {
        RaidStatus {
            level: self.level,
            total_disks: self.disks.len(),
            failed_disks: self.failed_disks.len(),
            hot_spares: self.hot_spares.len(),
            capacity_bytes: self.usable_capacity(),
            is_degraded: self.is_degraded(),
            is_rebuilding: self.rebuild_progress.is_some(),
        }
    }
}

#[derive(Debug, Clone)]
pub struct RaidStatus {
    pub level: RaidLevel,
    pub total_disks: usize,
    pub failed_disks: usize,
    pub hot_spares: usize,
    pub capacity_bytes: usize,
    pub is_degraded: bool,
    pub is_rebuilding: bool,
}

pub struct SimulationResult {
    pub successful_ops: usize,
    pub failed_ops: usize,
    pub disk_failures: usize,
    pub ure_count: usize,
    pub data_loss: bool,
}

pub fn simulate_workload(
    raid: &mut RaidArray,
    operations: &[(bool, usize, usize)],
    _failure_probability: f64,
) -> SimulationResult {
    let mut result = SimulationResult {
        successful_ops: 0,
        failed_ops: 0,
        disk_failures: 0,
        ure_count: 0,
        data_loss: false,
    };

    for (is_write, offset, length) in operations {
        let op_result = if *is_write {
            raid.write(*offset, &vec![0x42u8; *length]).map(|_| ())
        } else {
            raid.read(*offset, *length).map(|_| ())
        };

        match op_result {
            Ok(()) => result.successful_ops += 1,
            Err(RaidError::TooManyFailures) => {
                result.data_loss = true;
                result.failed_ops += 1;
            }
            Err(_) => result.failed_ops += 1,
        }
    }

    result
}
```

---

### 4.9 spec.json

```json
{
  "name": "kaiju_shield_array",
  "language": "rust",
  "language_version": "2024",
  "type": "complet",
  "tier": 3,
  "tier_info": "Synthese RAID 0/1/5/6 + hot spare + URE",
  "tags": ["raid", "storage", "parity", "xor", "filesystem", "rust"],
  "passing_score": 70,

  "function": {
    "name": "RaidArray",
    "prototype": "impl RaidArray { pub fn new(level: RaidLevel, disk_count: usize, disk_capacity: usize) -> Result<Self, RaidError> }",
    "return_type": "Result<RaidArray, RaidError>",
    "parameters": [
      {"name": "level", "type": "RaidLevel"},
      {"name": "disk_count", "type": "usize"},
      {"name": "disk_capacity", "type": "usize"}
    ]
  },

  "driver": {
    "reference": "See Section 4.3 for full reference implementation",

    "edge_cases": [
      {
        "name": "raid0_minimum_disks",
        "args": ["Raid0", 1, 1048576],
        "expected": "Err(InvalidConfig)",
        "is_trap": true,
        "trap_explanation": "RAID 0 requires minimum 2 disks"
      },
      {
        "name": "raid5_minimum_disks",
        "args": ["Raid5", 2, 1048576],
        "expected": "Err(InvalidConfig)",
        "is_trap": true,
        "trap_explanation": "RAID 5 requires minimum 3 disks"
      },
      {
        "name": "raid6_minimum_disks",
        "args": ["Raid6", 3, 1048576],
        "expected": "Err(InvalidConfig)",
        "is_trap": true,
        "trap_explanation": "RAID 6 requires minimum 4 disks"
      },
      {
        "name": "raid0_single_failure",
        "description": "RAID 0 should fail on any disk failure",
        "expected": "Err(TooManyFailures)"
      },
      {
        "name": "raid5_double_failure",
        "description": "RAID 5 should fail on 2 disk failures",
        "expected": "Err(TooManyFailures)"
      }
    ],

    "fuzzing": {
      "enabled": true,
      "iterations": 1000,
      "generators": [
        {
          "type": "int",
          "param_index": 1,
          "params": {"min": 2, "max": 8}
        },
        {
          "type": "int",
          "param_index": 2,
          "params": {"min": 65536, "max": 1048576}
        }
      ]
    }
  },

  "norm": {
    "allowed_functions": ["std::collections::HashSet", "std::vec::Vec"],
    "forbidden_functions": [],
    "check_security": true,
    "check_memory": true,
    "blocking": true
  }
}
```

---

### 4.10 Solutions Mutantes

```rust
/* =============================================================================
   MUTANT A (Boundary): Off-by-one dans le calcul du disque de parite
   ============================================================================= */
fn parity_disk_for_stripe_mutant_a(&self, stripe_num: usize) -> usize {
    // BUG: Oublie le -1, provoque acces hors limites
    self.disks.len() - (stripe_num % self.disks.len())
}
// Pourquoi faux: Quand stripe_num % n == 0, retourne n au lieu de n-1
// Ce qui etait pense: "La parite est sur le dernier disque"

/* =============================================================================
   MUTANT B (Safety): Pas de verification du statut disque avant lecture
   ============================================================================= */
fn read_raid5_mutant_b(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
    // BUG: Ne verifie pas si le disque est failed!
    let data = self.disks[0].read(offset, length)
        .map_err(|e| RaidError::DiskError(0, e))?;
    Ok(data)
}
// Pourquoi faux: Tente de lire depuis un disque potentiellement KO
// Ce qui etait pense: "Le read() du disque va echouer tout seul"

/* =============================================================================
   MUTANT C (Resource): Ne met pas a jour failed_disks dans fail_disk()
   ============================================================================= */
pub fn fail_disk_mutant_c(&mut self, disk_id: usize) -> Result<(), RaidError> {
    self.disks[disk_id].fail();
    // BUG: Oublie d'ajouter a failed_disks!
    // self.failed_disks.insert(disk_id);
    Ok(())
}
// Pourquoi faux: is_degraded() retourne false, rebuild impossible
// Ce qui etait pense: "Le statut du disque suffit"

/* =============================================================================
   MUTANT D (Logic): Utilise OR au lieu de XOR pour la parite
   ============================================================================= */
fn calculate_parity_mutant_d(&self, strips: &[Vec<u8>]) -> Vec<u8> {
    let len = strips.first().map_or(0, |s| s.len());
    let mut parity = vec![0u8; len];

    for strip in strips {
        for (i, byte) in strip.iter().enumerate() {
            // BUG: OR au lieu de XOR!
            parity[i] |= byte;
        }
    }

    parity
}
// Pourquoi faux: OR n'est pas reversible, reconstruction impossible
// A OR B OR B != A (mais A XOR B XOR B == A)

/* =============================================================================
   MUTANT E (Return): RAID 1 read ne verifie pas tous les miroirs
   ============================================================================= */
fn read_raid1_mutant_e(&mut self, offset: usize, length: usize) -> Result<Vec<u8>, RaidError> {
    // BUG: Lit toujours depuis le disque 0, meme s'il est KO
    self.disks[0].read(offset, length)
        .map_err(|e| RaidError::DiskError(0, e))
}
// Pourquoi faux: Ne profite pas de la redondance du miroir
// Ce qui etait pense: "Le premier disque est toujours le bon"

/* =============================================================================
   MUTANT F (Integration): Rebuild ne marque pas le disque comme Online
   ============================================================================= */
pub fn rebuild_step_mutant_f(&mut self) -> Result<bool, RaidError> {
    let (disk_id, progress) = self.rebuild_progress.ok_or(RaidError::RebuildFailed)?;
    let capacity = self.disks[disk_id].capacity;

    if progress >= capacity {
        // BUG: Oublie de changer le statut!
        // self.disks[disk_id].status = DiskStatus::Online;
        self.failed_disks.remove(&disk_id);
        self.rebuild_progress = None;
        return Ok(true);
    }

    // ... reste du code
    Ok(false)
}
// Pourquoi faux: Le disque reste en Rebuilding, is_operational() peut mal se comporter
// Ce qui etait pense: "Enlever de failed_disks suffit"
```

---

## SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

1. **Striping (RAID 0)** : Distribution des donnees pour performance maximale
2. **Mirroring (RAID 1)** : Duplication complete pour redondance totale
3. **Parite distribuee (RAID 5)** : Equilibre performance/redondance avec XOR
4. **Double parite (RAID 6)** : Survie a 2 pannes simultanees
5. **Mode degrade** : Continuer a fonctionner malgre les pertes
6. **Hot spare** : Remplacement automatique des disques defaillants
7. **Reconstruction** : Regenerer les donnees perdues via XOR

### 5.2 LDA - Traduction Litterale

```
FONCTION calculate_parity QUI RETOURNE UN VECTEUR D'OCTETS ET PREND EN PARAMETRE strips QUI EST UNE REFERENCE VERS UNE TRANCHE DE VECTEURS D'OCTETS
DEBUT FONCTION
    DECLARER len COMME TAILLE EGALE A LA LONGUEUR DU PREMIER STRIP OU 0 SI VIDE
    DECLARER parity COMME VECTEUR DE len OCTETS INITIALISES A ZERO

    POUR CHAQUE strip DANS strips FAIRE
        POUR CHAQUE (i, byte) DANS L'ENUMERATION DE strip FAIRE
            AFFECTER parity[i] XOR byte A parity[i]
        FIN POUR
    FIN POUR

    RETOURNER parity
FIN FONCTION
```

### 5.2.2 Representation Algorithmique Academique

```
ALGORITHME : Calcul de Parite XOR pour RAID 5
---
ENTREES :
    strips : tableau de N blocs de donnees de taille S octets chacun

SORTIE :
    parity : bloc de S octets tel que parity[i] = strips[0][i] XOR strips[1][i] XOR ... XOR strips[N-1][i]

DEBUT
    1. INITIALISER parity comme tableau de S zeros

    2. POUR j ALLANT DE 0 A N-1 FAIRE
        a. POUR i ALLANT DE 0 A S-1 FAIRE
            i. parity[i] := parity[i] XOR strips[j][i]
        b. FIN POUR
    3. FIN POUR

    4. RETOURNER parity
FIN
```

### 5.2.3 Logic Flow (Structured English)

```
ALGORITHM: RAID 5 Degraded Read
---
1. CHECK if more than 1 disk has failed
   |-- IF true: RETURN Error (TooManyFailures)

2. FOR each chunk to read:
   a. CALCULATE which stripe this offset belongs to
   b. DETERMINE which disk holds the parity for this stripe
   c. CALCULATE which disk holds the actual data

   d. IF target disk is failed:
      |-- RECONSTRUCT data via XOR of all other disks
      |-- (missing = D0 XOR D1 XOR ... XOR P, excluding missing)
   e. ELSE:
      |-- READ directly from target disk

   f. APPEND data to result

3. RETURN result
```

### 5.3 Visualisation ASCII

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         RAID LEVELS COMPARISON                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  RAID 0 - STRIKER EUREKA (Striping Only)                                     â•‘
â•‘  "The fastest Jaeger - one hit and it's over"                                â•‘
â•‘                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â•‘
â•‘  â”‚ Disk 0  â”‚ Disk 1  â”‚ Disk 2  â”‚ Disk 3  â”‚                                   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                   â•‘
â•‘  â”‚ Strip 0 â”‚ Strip 1 â”‚ Strip 2 â”‚ Strip 3 â”‚  â† Data distributed              â•‘
â•‘  â”‚ Strip 4 â”‚ Strip 5 â”‚ Strip 6 â”‚ Strip 7 â”‚    No redundancy                 â•‘
â•‘  â”‚ Strip 8 â”‚ Strip 9 â”‚ Strip10 â”‚ Strip11 â”‚    100% capacity                 â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â•‘
â•‘                                                                              â•‘
â•‘  Capacity: 4x  |  Read: 4x  |  Write: 4x  |  Tolerance: 0 disk               â•‘
â•‘                                                                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  RAID 1 - GIPSY DANGER (Mirroring)                                           â•‘
â•‘  "Two pilots, one mind - complete backup"                                    â•‘
â•‘                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â•‘
â•‘  â”‚ Disk 0  â”‚ Disk 1  â”‚                                                       â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                                       â•‘
â•‘  â”‚  Data   â”‚  Data   â”‚  â† Identical copies                                  â•‘
â•‘  â”‚  Copy   â”‚  Copy   â”‚    (mirror)                                          â•‘
â•‘  â”‚   A     â”‚   A     â”‚                                                       â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â•‘
â•‘                                                                              â•‘
â•‘  Capacity: 1x  |  Read: 2x  |  Write: 1x  |  Tolerance: N-1 disks            â•‘
â•‘                                                                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  RAID 5 - CRIMSON TYPHOON (Distributed Parity)                               â•‘
â•‘  "The Wei triplets - lose one, XOR regenerates"                              â•‘
â•‘                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â•‘
â•‘  â”‚ Disk 0  â”‚ Disk 1  â”‚ Disk 2  â”‚ Disk 3  â”‚                                   â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                   â•‘
â•‘  â”‚   D0    â”‚   D1    â”‚   D2    â”‚   P0    â”‚  P0 = D0âŠ•D1âŠ•D2                   â•‘
â•‘  â”‚   D3    â”‚   D4    â”‚   P1    â”‚   D5    â”‚  Parity rotates!                 â•‘
â•‘  â”‚   D6    â”‚   P2    â”‚   D7    â”‚   D8    â”‚                                   â•‘
â•‘  â”‚   P3    â”‚   D9    â”‚   D10   â”‚   D11   â”‚                                   â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â•‘
â•‘                                                                              â•‘
â•‘  Capacity: (N-1)x  |  Read: (N-1)x  |  Write: ~(N-1)x  |  Tolerance: 1 disk  â•‘
â•‘                                                                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  RAID 6 - CHERNO ALPHA (Double Parity P+Q)                                   â•‘
â•‘  "Russian engineering - survives TWO direct hits"                            â•‘
â•‘                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â•‘
â•‘  â”‚ Disk 0  â”‚ Disk 1  â”‚ Disk 2  â”‚ Disk P  â”‚ Disk Q  â”‚                         â•‘
â•‘  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â•‘
â•‘  â”‚   D0    â”‚   D1    â”‚   D2    â”‚ D0âŠ•D1âŠ•D2â”‚ GF mult â”‚                         â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â•‘
â•‘                                                                              â•‘
â•‘  P = D0 âŠ• D1 âŠ• D2 âŠ• ...         (XOR classique)                             â•‘
â•‘  Q = gâ°D0 âŠ• gÂ¹D1 âŠ• gÂ²D2 âŠ• ...   (Galois Field GF(2â¸))                       â•‘
â•‘                                                                              â•‘
â•‘  Capacity: (N-2)x  |  Read: (N-2)x  |  Write: ~(N-2)x  |  Tolerance: 2 disks â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    XOR PARITY RECONSTRUCTION                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  WRITE OPERATION (calculating parity):                                       â•‘
â•‘                                                                              â•‘
â•‘  D0: 0xAA = 1 0 1 0 1 0 1 0                                                  â•‘
â•‘  D1: 0x55 = 0 1 0 1 0 1 0 1                                                  â•‘
â•‘  D2: 0xFF = 1 1 1 1 1 1 1 1                                                  â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â•‘
â•‘  P:  0x00 = 0 0 0 0 0 0 0 0   (D0 âŠ• D1 âŠ• D2)                                â•‘
â•‘                                                                              â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â•‘
â•‘                                                                              â•‘
â•‘  KAIJU ATTACK! Disk 1 (D1) is destroyed!                                     â•‘
â•‘                                                                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”           â•‘
â•‘  â”‚ 0xAA â”‚ 0x55 â”‚ 0xFF â”‚ 0x00 â”‚  â†’   â”‚ 0xAA â”‚  â˜ ï¸  â”‚ 0xFF â”‚ 0x00 â”‚           â•‘
â•‘  â”‚  D0  â”‚  D1  â”‚  D2  â”‚  P   â”‚      â”‚  D0  â”‚ DEAD â”‚  D2  â”‚  P   â”‚           â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜           â•‘
â•‘                                                                              â•‘
â•‘  RECONSTRUCTION via XOR:                                                     â•‘
â•‘                                                                              â•‘
â•‘  D1 = D0 âŠ• D2 âŠ• P                                                           â•‘
â•‘     = 0xAA âŠ• 0xFF âŠ• 0x00                                                    â•‘
â•‘     = 0x55  âœ“                                                                â•‘
â•‘                                                                              â•‘
â•‘  "The Kaiju hit was severe, but we rebuilt via XOR parity!"                  â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 5.4 Les pieges en detail

| Piege | Description | Solution |
|-------|-------------|----------|
| **XOR vs OR** | Utiliser OR au lieu de XOR | XOR est reversible, OR ne l'est pas |
| **Off-by-one parity** | Mauvais calcul du disque de parite | `n - 1 - (stripe % n)` |
| **Failed disk tracking** | Ne pas maintenir la liste des pannes | HashSet avec add/remove |
| **Rebuild incomplete** | Ne pas parcourir toute la capacite | Boucle jusqu'a capacity |
| **URE pendant rebuild** | Ignorer les URE | Propager l'erreur ou retry |

### 5.5 Cours Complet

#### 5.5.1 Histoire du RAID

RAID a ete invente en 1988 par Patterson, Gibson et Katz a UC Berkeley. L'idee : combiner des disques bon marche pour obtenir performance ET fiabilite.

#### 5.5.2 Les Niveaux RAID Standards

| Niveau | Nom | Disques Min | Redondance | Efficacite |
|--------|-----|-------------|------------|------------|
| RAID 0 | Striping | 2 | Aucune | 100% |
| RAID 1 | Mirroring | 2 | N-1 disques | 50% |
| RAID 5 | Distributed Parity | 3 | 1 disque | (N-1)/N |
| RAID 6 | Double Parity | 4 | 2 disques | (N-2)/N |
| RAID 10 | Striped Mirrors | 4 | 1 par paire | 50% |

#### 5.5.3 Pourquoi XOR ?

XOR (exclusive OR) a une propriete unique : il est auto-inverse.

```
A âŠ• B = C
A âŠ• C = B
B âŠ• C = A
```

Cette propriete permet de reconstruire n'importe quelle valeur a partir des autres.

### 5.8 Mnemotechniques

#### MEME : "PACIFIC RIM - The Kaiju Survival Guide"

```
    ğŸ¤– JAEGERS = RAID LEVELS

    STRIKER EUREKA (RAID 0):
       "Speed kills... especially you when a disk fails"
       Remember: Zero redundancy = Zero survivors

    GIPSY DANGER (RAID 1):
       "Raleigh and Mako - two minds, one purpose"
       Remember: Mirror = 2 copies, 1 can fall

    CRIMSON TYPHOON (RAID 5):
       "The Wei triplets: XOR regenerates the fallen"
       Remember: 5 = Parity (sort of rhymes!)

    CHERNO ALPHA (RAID 6):
       "Russian engineering: double shields, double protection"
       Remember: 6 = 5 + 1 more parity
```

#### Retenir la formule de parite :

```
"XOR XOR XOR - it's like Thor's hammer!
 Hit the same thing twice and it bounces back!"

 A âŠ• B âŠ• B = A
 â””â”€â”¬â”€â”˜
   â”‚
 Mjolnir always returns!
```

### 5.9 Applications pratiques

| Scenario | Niveau RAID | Justification |
|----------|-------------|---------------|
| **Boot drive serveur** | RAID 1 | Simple, fiable, pas de calcul paritÃ© |
| **Database OLTP** | RAID 10 | Performance I/O critique |
| **Stockage fichiers** | RAID 5 | Bon compromis capacite/securite |
| **Archivage long terme** | RAID 6 | Maximum protection |
| **Scratch video** | RAID 0 | Performance pure, donnees temporaires |

---

## SECTION 6 : PIEGES - RECAPITULATIF

| # | Piege | Erreur Type | Solution |
|---|-------|-------------|----------|
| 1 | **XOR incorrect** | `\|=` au lieu de `^=` | Toujours XOR pour parite |
| 2 | **Parite fixe** | Meme disque toujours | Rotation par stripe |
| 3 | **Failed disk set** | Ne pas tracker les pannes | HashSet::insert/remove |
| 4 | **Rebuild partiel** | Ne reconstruit pas tout | Boucle complete |
| 5 | **RAID 0 degraded** | Tenter de reconstruire | Erreur immediate |
| 6 | **URE silencieux** | Ignorer les erreurs URE | Propager Result::Err |

---

## SECTION 7 : QCM

### Q1. Quel niveau RAID offre les meilleures performances en lecture/ecriture sequentielle ?

- A) RAID 1
- B) RAID 5
- C) RAID 0
- D) RAID 6

**Reponse : C**
RAID 0 n'a aucun overhead de parite et distribue les I/O sur tous les disques.

---

### Q2. Combien de disques peuvent tomber simultanement en RAID 6 sans perte de donnees ?

- A) 0
- B) 1
- C) 2
- D) 3

**Reponse : C**
RAID 6 utilise deux parities (P et Q) permettant de reconstruire 2 disques manquants.

---

### Q3. Quelle operation bitwise est utilisee pour calculer la parite en RAID 5 ?

- A) AND
- B) OR
- C) XOR
- D) NOT

**Reponse : C**
XOR est auto-inverse : A XOR B XOR B = A, permettant la reconstruction.

---

### Q4. Quelle est l'efficacite capacite d'un RAID 5 avec 5 disques ?

- A) 60%
- B) 80%
- C) 100%
- D) 50%

**Reponse : B**
RAID 5 avec N disques = (N-1)/N = 4/5 = 80%

---

### Q5. Qu'est-ce qu'un URE (Unrecoverable Read Error) ?

- A) Une erreur d'ecriture corrigible
- B) Une erreur de lecture que le disque ne peut pas corriger
- C) Une panne complete du disque
- D) Un timeout reseau

**Reponse : B**
URE est une erreur de lecture au niveau secteur que l'ECC du disque ne peut pas corriger.

---

## SECTION 8 : RECAPITULATIF

| Concept | Maitrise | A revoir |
|---------|----------|----------|
| RAID 0 Striping | â˜ | â˜ |
| RAID 1 Mirroring | â˜ | â˜ |
| RAID 5 Distributed Parity | â˜ | â˜ |
| RAID 6 Double Parity | â˜ | â˜ |
| XOR Parity Calculation | â˜ | â˜ |
| Parity Rotation | â˜ | â˜ |
| Degraded Mode Read | â˜ | â˜ |
| Hot Spare Activation | â˜ | â˜ |
| Rebuild Process | â˜ | â˜ |
| URE Simulation | â˜ | â˜ |

**Score minimum pour valider : 70/100**

---

## SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "M2.3-Ex06-kaiju-shield-array",
    "generated_at": "2026-01-16 00:00:00",

    "metadata": {
      "exercise_id": "M2.3-Ex06",
      "exercise_name": "kaiju_shield_array",
      "module": "2.3.27",
      "module_name": "Systemes de Fichiers et Stockage",
      "concept": "g+i",
      "concept_name": "Hot spare + URE simulation",
      "type": "complet",
      "tier": 3,
      "tier_info": "Synthese RAID complete",
      "phase": 2,
      "difficulty": 8,
      "difficulty_stars": "â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†",
      "language": "rust",
      "language_version": "2024",
      "duration_minutes": 360,
      "xp_base": 500,
      "xp_bonus_multiplier": 4,
      "bonus_tier": "EXPERT",
      "bonus_icon": "ğŸ’€",
      "complexity_time": "T3 O(n)",
      "complexity_space": "S3 O(n)",
      "prerequisites": [
        "bitwise-operations",
        "ownership-borrowing",
        "vec-collections",
        "result-option",
        "traits"
      ],
      "domains": ["FS", "Mem", "MD", "Encodage", "Struct"],
      "domains_bonus": ["Crypto"],
      "tags": [
        "raid",
        "storage",
        "parity",
        "xor",
        "striping",
        "mirroring",
        "hot-spare",
        "rebuild",
        "ure",
        "pacific-rim",
        "rust"
      ],
      "meme_reference": "Pacific Rim - Jaegers and Neural Drift"
    },

    "files": {
      "spec.json": "/* Section 4.9 */",
      "references/lib.rs": "/* Section 4.3 */",
      "tests/integration_tests.rs": "/* Section 4.2 */",
      "mutants/mutant_a_boundary.rs": "/* Section 4.10 - Off-by-one parity */",
      "mutants/mutant_b_safety.rs": "/* Section 4.10 - No status check */",
      "mutants/mutant_c_resource.rs": "/* Section 4.10 - Failed disk tracking */",
      "mutants/mutant_d_logic.rs": "/* Section 4.10 - OR vs XOR */",
      "mutants/mutant_e_return.rs": "/* Section 4.10 - RAID 1 single read */",
      "mutants/mutant_f_integration.rs": "/* Section 4.10 - Rebuild status */"
    },

    "validation": {
      "expected_pass": [
        "references/lib.rs"
      ],
      "expected_fail": [
        "mutants/mutant_a_boundary.rs",
        "mutants/mutant_b_safety.rs",
        "mutants/mutant_c_resource.rs",
        "mutants/mutant_d_logic.rs",
        "mutants/mutant_e_return.rs",
        "mutants/mutant_f_integration.rs"
      ]
    },

    "commands": {
      "validate_spec": "python3 hackbrain_engine_v22.py --validate-spec spec.json",
      "test_reference": "cargo test --release",
      "test_mutants": "python3 hackbrain_mutation_tester.py -r references/lib.rs -s spec.json --validate"
    }
  }
}
```

---

*HACKBRAIN v5.5.2 - "Today we are cancelling the data loss apocalypse!"*
*Kaiju Shield Array: Because your data deserves Jaeger-level protection*
*Pacific Rim taught us: redundancy saves lives. RAID teaches us: redundancy saves data.*

# Exercice 2.3.4 : journalfs_cow

**Module :**
2.3.4 â€” Journaling et Copy-on-Write Filesystem

**Concept :**
a â€” Journalisation transactionnelle, COW, checksums, self-healing (ZFS/btrfs)

**Difficulte :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜† (7/10)

**Type :**
complet

**Tiers :**
3 â€” Synthese (Journal, COW, checksums, subvolumes, cache L2ARC)

**Langage :**
Rust (Edition 2024)

**Prerequis :**
- Structures de donnees (BTreeMap, HashMap, VecDeque)
- Concepts de transactions (atomicite, durabilite)
- Systemes de fichiers (blocs, inodes)
- Notions de RAID et redundance

**Domaines :**
FS, Struct, Mem, Crypto

**Duree estimee :**
180 min

**XP Base :**
250

**Complexite :**
T3 O(log n) pour B-tree lookup Ã— S3 O(n) pour stockage blocs

---

## ğŸ“ SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichier a rendre :**
```
src/lib.rs
```

**Fonctions autorisees :**
- `std::collections::{BTreeMap, HashMap, VecDeque}`
- `std::sync::{Arc, RwLock}`
- `std::vec::Vec`

**Fonctions interdites :**
- Acces disque reel (`std::fs`)
- `unsafe` blocks
- Crates externes

### 1.2 Consigne

**Section 2.4.1 â€” Contexte Culturel**

**ğŸ® DARK SOULS â€” Bonfires et Soul Recovery**

Dans Dark Souls, les **bonfires** sont des points de sauvegarde sacres. Quand tu meurs (crash systeme), tu reapparais au dernier bonfire visite (dernier checkpoint du journal). Ton progres depuis ce bonfire est perdu, mais tout ce qui etait sauvegarde AVANT est intact.

- **Journal (Write-Ahead Log)** : C'est comme allumer un bonfire. AVANT de faire quoi que ce soit de dangereux (modifier des donnees), tu notes tes intentions dans le journal. Si tu meurs en combat (crash), tu peux "rejouer" depuis le bonfire.

- **Transaction Commit** : Quand tu touches un nouveau bonfire, tes ames sont "committed" â€” elles sont sauvegardees de facon permanente. Une transaction committee = un bonfire atteint.

- **Rollback** : Tu es mort avant d'atteindre le prochain bonfire ? Pas de panique. Tu reviens au dernier bonfire avec toutes tes ames d'avant (rollback au dernier etat consistent).

- **Copy-on-Write (COW)** : C'est comme le systeme de "Bloodstain" et "Soul Recovery". Quand tu meurs, tes ames (donnees originales) restent LA OU TU ES MORT â€” elles ne sont pas ecrasees. Tu as une chance de les recuperer. En COW, on ne modifie JAMAIS le bloc original ; on ecrit toujours dans un nouveau bloc, et l'ancien reste intact jusqu'a ce qu'on soit SUR que le nouveau est valide.

- **Self-Healing (Checksums)** : Imagine que chaque bonfire verifie que ton personnage n'est pas corrompu (stats alterees par un bug). Si quelque chose cloche, le jeu peut restaurer depuis une sauvegarde backup. C'est exactement ce que font les checksums avec redondance.

- **Snapshots** : Comme faire une copie de ta sauvegarde AVANT un boss difficile. Si tu veux revenir a cet etat exact, tu peux. Le snapshot partage les donnees avec l'original (COW) jusqu'a ce que quelque chose change.

**L'analogie parfaite :** Le ZIL (ZFS Intent Log) est ton journal de quete qui note "je vais tenter le boss Ornstein & Smough". Meme si le jeu crash pendant le combat, au redemarrage il sait exactement ou tu en etais et peut reprendre. Le L2ARC, c'est comme ta memoire musculaire des patterns de boss â€” un cache rapide pour les donnees frequemment utilisees.

---

**Section 2.4.2 â€” Enonce Academique**

La **journalisation** (write-ahead logging) et le **Copy-on-Write** sont deux strategies fondamentales pour garantir la coherence des donnees dans les systemes de fichiers modernes.

**Write-Ahead Logging (WAL) :**
Le principe est simple : avant toute modification des donnees, on ecrit d'abord l'intention de modification dans un journal persistant. En cas de crash :
1. Au redemarrage, on lit le journal
2. Pour chaque transaction incomplete, on annule (rollback)
3. Pour chaque transaction complete, on s'assure qu'elle est appliquee (replay)

**Copy-on-Write (COW) :**
Contrairement aux filesystems traditionnels qui modifient les blocs en place, le COW :
1. Alloue un NOUVEAU bloc pour toute ecriture
2. Copie les donnees modifiees dans ce nouveau bloc
3. Met a jour atomiquement le pointeur vers le nouveau bloc
4. L'ancien bloc reste intact jusqu'a liberation explicite

**Avantages du COW :**
- Snapshots instantanes (partage des blocs non modifies)
- Pas de corruption possible (ancien bloc toujours valide)
- Simplification du journaling (pas besoin de double-write)

**Checksums et Self-Healing (ZFS/btrfs) :**
Chaque bloc est stocke avec son checksum (CRC, SHA, Fletcher). A la lecture :
1. Calculer le checksum des donnees lues
2. Comparer avec le checksum stocke
3. Si mismatch ET redondance disponible, lire depuis une copie
4. Reparer automatiquement le bloc corrompu

**ZFS Specifique :**
- **ZIL (ZFS Intent Log)** : Journal synchrone pour garantir les writes
- **L2ARC** : Cache de lecture sur SSD pour accelerer les acces

**Ta mission :**

Implementer un systeme de fichiers COW avec journalisation complete :

1. `Journal` : Gestion des transactions avec begin/commit/rollback
2. `ChecksummedBlock` : Blocs avec verification d'integrite
3. `StoragePool` : Pool de stockage avec redondance et self-healing
4. `Subvolume` : Sous-volumes avec snapshots COW
5. `L2Cache` : Cache de lecture avec eviction
6. `CowFS` : Filesystem complet integrant tous les composants

**Entree :**
- Configuration du pool (nombre de vdevs, redundance)
- Intervalle de checkpoint du journal

**Sortie :**
- Filesystem fonctionnel avec transactions ACID
- Support des snapshots et self-healing

**Contraintes :**
- Les transactions doivent etre atomiques
- Le checksum doit detecter toute corruption
- Le COW ne doit JAMAIS ecraser de donnees existantes
- Le scrub doit verifier ET reparer si possible
- Le cache L2ARC doit avoir un ratio de hits calculable

**Exemples :**

| Operation | Resultat | Explication |
|-----------|----------|-------------|
| `journal.begin()` | `tx_id = 1` | Nouvelle transaction ouverte |
| `journal.commit()` | `Ok(())` | Transaction finalisee |
| `journal.rollback()` | `()` | Transaction annulee |
| `pool.scrub()` | `{checked: 100, errors: 2, repaired: 2}` | Verification complete |
| `fs.snapshot(1, "backup")` | `Ok(2)` | Snapshot cree, ID=2 |
| `cache.hit_ratio()` | `0.75` | 75% des lectures en cache |

### 1.3 Prototype

```rust
use std::collections::{BTreeMap, HashMap, VecDeque};
use std::sync::{Arc, RwLock};

pub const BLOCK_SIZE: usize = 4096;

/// Checksum pour verification d'integrite
#[derive(Debug, Clone, Copy, PartialEq)]
pub struct Checksum(pub u64);

/// Operation du journal
#[derive(Debug, Clone)]
pub enum JournalOp {
    Write { block_id: u64, data: Vec<u8>, checksum: Checksum },
    Delete { block_id: u64 },
    CreateInode { ino: u64 },
    UpdateMeta { ino: u64, field: String, value: Vec<u8> },
}

/// Transaction du journal
#[derive(Debug, Clone)]
pub struct Transaction {
    pub id: u64,
    pub ops: Vec<JournalOp>,
    pub checksum: Checksum,
    pub committed: bool,
}

/// Journal avec ZIL-like intent log
pub struct Journal {
    pub transactions: VecDeque<Transaction>,
    current_tx: Option<Transaction>,
    next_tx_id: u64,
    checkpoint_interval: usize,
    pending_count: usize,
}

/// Bloc avec checksum pour self-healing
#[derive(Debug, Clone)]
pub struct ChecksummedBlock {
    pub id: u64,
    pub data: [u8; BLOCK_SIZE],
    pub checksum: Checksum,
    pub copies: Vec<usize>,
}

/// Pool de stockage (zpool-like)
pub struct StoragePool {
    pub name: String,
    pub vdevs: Vec<VirtualDevice>,
    total_size: u64,
    used_size: u64,
    redundancy: Redundancy,
}

/// Device virtuel (vdev)
pub struct VirtualDevice {
    pub id: usize,
    pub blocks: Vec<ChecksummedBlock>,
    pub capacity: usize,
    pub failed: bool,
}

/// Niveau de redundance
#[derive(Debug, Clone, Copy)]
pub enum Redundancy {
    None,
    Mirror,
    RaidZ1,
    RaidZ2,
}

/// Subvolume (arbre independant)
#[derive(Debug, Clone)]
pub struct Subvolume {
    pub id: u64,
    pub name: String,
    pub root_ino: u64,
    pub parent: Option<u64>,
    pub readonly: bool,
    pub created_at: u64,
}

/// Cache L2ARC
pub struct L2Cache {
    cache: HashMap<u64, Vec<u8>>,
    max_size: usize,
    current_size: usize,
    pub hits: u64,
    pub misses: u64,
}

/// Filesystem COW complet
pub struct CowFS {
    pool: StoragePool,
    journal: Journal,
    subvolumes: HashMap<u64, Subvolume>,
    block_tree: BTreeMap<u64, u64>,
    cow_pending: HashMap<u64, u64>,
    l2arc: Option<Arc<RwLock<L2Cache>>>,
    next_physical: u64,
    next_subvol_id: u64,
}

/// Erreurs
#[derive(Debug, PartialEq)]
pub enum JournalError {
    NoTransaction,
    ChecksumMismatch,
    Full,
}

#[derive(Debug, PartialEq)]
pub enum PoolError {
    NoSpace,
    DeviceFailed,
    UnrecoverableError,
    BlockNotFound,
}

#[derive(Debug, PartialEq)]
pub enum FsError {
    Journal(JournalError),
    Pool(PoolError),
    NotFound,
    ReadOnly,
}

/// Resultats
#[derive(Debug)]
pub struct ScrubResult {
    pub blocks_checked: u64,
    pub errors_found: u64,
    pub errors_repaired: u64,
}

#[derive(Debug)]
pub struct DefragStats {
    pub blocks_moved: u64,
    pub fragmentation_before: f64,
    pub fragmentation_after: f64,
}

#[derive(Debug)]
pub struct RecoveryResult {
    pub transactions_replayed: usize,
    pub blocks_recovered: usize,
    pub errors: Vec<String>,
}

// Implementations a completer
impl Checksum {
    pub fn compute(data: &[u8]) -> Self;
    pub fn verify(&self, data: &[u8]) -> bool;
}

impl Transaction {
    pub fn new(id: u64) -> Self;
    pub fn add_op(&mut self, op: JournalOp);
    pub fn finalize(&mut self);
}

impl Journal {
    pub fn new(checkpoint_interval: usize) -> Self;
    pub fn begin(&mut self) -> u64;
    pub fn log(&mut self, op: JournalOp) -> Result<(), JournalError>;
    pub fn commit(&mut self) -> Result<(), JournalError>;
    pub fn rollback(&mut self);
    pub fn checkpoint(&mut self) -> Vec<Transaction>;
    pub fn replay(&self) -> Vec<JournalOp>;
}

impl ChecksummedBlock {
    pub fn new(id: u64, data: [u8; BLOCK_SIZE]) -> Self;
    pub fn verify(&self) -> bool;
}

impl StoragePool {
    pub fn new(name: &str, vdevs: Vec<VirtualDevice>, redundancy: Redundancy) -> Self;
    pub fn write_block(&mut self, block: ChecksummedBlock) -> Result<(), PoolError>;
    pub fn read_block(&mut self, block_id: u64) -> Result<ChecksummedBlock, PoolError>;
    pub fn scrub(&mut self) -> ScrubResult;
}

impl Subvolume {
    pub fn snapshot(&self, name: &str, new_id: u64) -> Subvolume;
    pub fn clone_writable(&self, name: &str, new_id: u64) -> Subvolume;
}

impl L2Cache {
    pub fn new(max_size: usize) -> Self;
    pub fn get(&mut self, block_id: u64) -> Option<Vec<u8>>;
    pub fn put(&mut self, block_id: u64, data: Vec<u8>);
    pub fn hit_ratio(&self) -> f64;
}

impl CowFS {
    pub fn new(pool: StoragePool, journal_interval: usize) -> Self;
    pub fn with_l2arc(pool: StoragePool, journal_interval: usize, cache_size: usize) -> Self;
    pub fn write(&mut self, block_id: u64, data: &[u8]) -> Result<(), FsError>;
    pub fn read(&mut self, block_id: u64) -> Result<Vec<u8>, FsError>;
    pub fn create_subvolume(&mut self, name: &str) -> Result<u64, FsError>;
    pub fn snapshot(&mut self, subvol_id: u64, name: &str) -> Result<u64, FsError>;
    pub fn defrag(&mut self, subvol_id: u64) -> Result<DefragStats, FsError>;
    pub fn recover(&mut self) -> RecoveryResult;
}
```

---

## ğŸ’¡ SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 ZFS : Le filesystem qui n'oublie jamais

ZFS a ete cree par Sun Microsystems en 2001 avec un objectif ambitieux : eliminer TOUTE possibilite de corruption silencieuse des donnees. Le nom signifie "Zettabyte File System" car il peut theoriquement gerer 256 quadrillions de zettabytes.

La fonctionnalite la plus revolutionnaire ? Le **self-healing**. ZFS stocke des checksums pour CHAQUE bloc de donnees (pas juste les metadonnees). Avec de la redondance (mirror ou RAID-Z), si un bloc est corrompu, ZFS le detecte automatiquement et restaure depuis une copie valide. Le tout de maniere transparente pour l'utilisateur.

### 2.2 btrfs et le dilemme du "Butter FS"

btrfs (prononce "Butter FS" ou "B-tree FS") est la reponse Linux a ZFS. Il utilise egalement le COW mais avec une approche differente : tout est un B-tree. Meme les donnees sont stockees dans des B-trees, ce qui permet des fonctionnalites comme la deduplication inline et les snapshots quasi-instantanes.

Fun fact : Un snapshot de 10TB prend quelques millisecondes a creer car il ne copie rien â€” il partage tous les blocs avec l'original grace au COW.

---

## ğŸ“‹ SECTION 2.5 : DANS LA VRAIE VIE

| Metier | Utilisation du concept |
|--------|------------------------|
| **Storage Engineer** | Configuration et maintenance de ZFS/btrfs en production |
| **Database Administrator** | WAL dans PostgreSQL, InnoDB (MySQL), journaling |
| **Backup Specialist** | Snapshots pour backups incrementaux sans downtime |
| **Forensics Analyst** | Recovery de donnees via analyse du journal |
| **Cloud Architect** | AWS EBS snapshots, Azure Managed Disks (COW-based) |
| **SRE/DevOps** | Scrub schedules, monitoring de l'integrite des donnees |

---

## ğŸ–¥ï¸ SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ cargo test
   Compiling journalfs v0.1.0
    Finished test [unoptimized + debuginfo]
    Running unittests src/lib.rs

running 10 tests
test tests::test_checksum ... ok
test tests::test_journal_transaction ... ok
test tests::test_journal_rollback ... ok
test tests::test_cow_write ... ok
test tests::test_self_healing ... ok
test tests::test_scrub ... ok
test tests::test_subvolume_snapshot ... ok
test tests::test_l2arc ... ok
test tests::test_recovery ... ok
test tests::test_checkpoint ... ok

test result: ok. 10 passed; 0 failed; 0 ignored
```

---

## ğŸ”¥ SECTION 3.1 : BONUS AVANCE (OPTIONNEL)

**Difficulte Bonus :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜† (9/10)

**Recompense :**
XP Ã—3

**Time Complexity attendue :**
O(log n) pour toutes les operations avec B-tree balance

**Space Complexity attendue :**
O(1) auxiliaire pour scrub streaming

**Domaines Bonus :**
`Algo, Struct, Crypto`

### 3.1.1 Consigne Bonus

**ğŸ® DARK SOULS NG+ â€” Hardcore Mode**

En NG+ (New Game Plus), le jeu est impitoyable. Implemente les fonctionnalites avancees de ZFS :

1. **Deduplication** : Si deux blocs ont le meme contenu (meme checksum), ne stocker qu'une copie
2. **Compression** : Compression transparente des blocs avec detection automatique
3. **RAID-Z2** : Survie a 2 disques defaillants simultanement
4. **Scrub parallelise** : Verification multi-threaded

**Ta mission :**

```rust
pub trait AdvancedPool {
    fn enable_dedup(&mut self);
    fn enable_compression(&mut self, algo: CompressionAlgo);
    fn parallel_scrub(&mut self, threads: usize) -> ScrubResult;
    fn dedup_ratio(&self) -> f64;  // e.g., 2.5x = 60% d'espace economise
}

pub enum CompressionAlgo {
    LZ4,
    Zstd,
    None,
}
```

**Contraintes :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dedup lookup : O(1) avec hash table    â”‚
â”‚  Compression : Transparent pour caller  â”‚
â”‚  Scrub parallel : Speedup lineaire      â”‚
â”‚  RAID-Z2 : Tolere 2 failures            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.1.2 Prototype Bonus

```rust
pub struct DedupPool {
    base_pool: StoragePool,
    dedup_table: HashMap<Checksum, u64>,  // checksum -> block_id
    reference_counts: HashMap<u64, usize>,
    compression: Option<CompressionAlgo>,
    bytes_written_logical: u64,
    bytes_written_physical: u64,
}

impl DedupPool {
    pub fn write_dedup(&mut self, data: &[u8]) -> Result<u64, PoolError>;
    pub fn dedup_ratio(&self) -> f64;
    pub fn space_saved(&self) -> u64;
}
```

### 3.1.3 Ce qui change par rapport a l'exercice de base

| Aspect | Base | Bonus |
|--------|------|-------|
| Stockage | 1 bloc = 1 copie physique | Deduplication par checksum |
| Compression | Non | LZ4/Zstd transparent |
| Redondance | Mirror/RAID-Z1 | RAID-Z2 (double parite) |
| Scrub | Single-threaded | Multi-threaded |
| Complexite | O(n) scrub | O(n/threads) scrub |

---

## âœ…âŒ SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette

| Test | Input | Expected | Points |
|------|-------|----------|--------|
| `test_checksum_basic` | `[42u8; 4096]` | Checksum valide | 8 |
| `test_checksum_corrupt` | Donnees modifiees | `verify() == false` | 8 |
| `test_journal_begin_commit` | begin + log + commit | Transaction dans queue | 12 |
| `test_journal_rollback` | begin + log + rollback | Queue vide | 10 |
| `test_cow_no_overwrite` | 2 writes meme bloc logique | 2 blocs physiques differents | 15 |
| `test_self_healing_mirror` | Corruption + read | Donnees reparees | 15 |
| `test_scrub_detection` | 10 blocs, 2 corrompus | `errors_found == 2` | 10 |
| `test_snapshot_readonly` | snapshot + write | `Err(ReadOnly)` | 8 |
| `test_l2arc_hit_ratio` | get/put sequence | Ratio correct | 7 |
| `test_recovery_replay` | Crash simule | Transactions rejouees | 7 |

### 4.2 main.rs de test

```rust
use journalfs::*;

fn main() {
    // Test Journal
    let mut journal = Journal::new(10);
    let tx_id = journal.begin();
    println!("Transaction started: {}", tx_id);

    journal.log(JournalOp::Write {
        block_id: 0,
        data: vec![42; 100],
        checksum: Checksum(0),
    }).unwrap();

    journal.commit().unwrap();
    println!("Transaction committed");

    // Test COW Filesystem
    let vdev = VirtualDevice {
        id: 0,
        blocks: Vec::new(),
        capacity: 1000,
        failed: false,
    };
    let pool = StoragePool::new("testpool", vec![vdev], Redundancy::None);
    let mut fs = CowFS::new(pool, 10);

    // Premiere ecriture
    fs.write(0, &[1u8; BLOCK_SIZE]).unwrap();
    println!("Write 1 completed");

    // Deuxieme ecriture - COW en action
    fs.write(0, &[2u8; BLOCK_SIZE]).unwrap();
    println!("Write 2 completed (COW)");

    // Lecture
    let data = fs.read(0).unwrap();
    println!("Read data[0] = {}", data[0]);

    // Snapshot
    fs.create_subvolume("data").unwrap();
    let snap_id = fs.snapshot(1, "backup").unwrap();
    println!("Snapshot created: {}", snap_id);
}
```

### 4.3 Solution de reference

```rust
use std::collections::{BTreeMap, HashMap, VecDeque};
use std::sync::{Arc, RwLock};

pub const BLOCK_SIZE: usize = 4096;

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct Checksum(pub u64);

impl Checksum {
    pub fn compute(data: &[u8]) -> Self {
        let mut hash: u64 = 0xcbf29ce484222325; // FNV offset basis
        for &byte in data {
            hash ^= byte as u64;
            hash = hash.wrapping_mul(0x100000001b3); // FNV prime
        }
        Checksum(hash)
    }

    pub fn verify(&self, data: &[u8]) -> bool {
        Self::compute(data) == *self
    }
}

#[derive(Debug, Clone)]
pub enum JournalOp {
    Write { block_id: u64, data: Vec<u8>, checksum: Checksum },
    Delete { block_id: u64 },
    CreateInode { ino: u64 },
    UpdateMeta { ino: u64, field: String, value: Vec<u8> },
}

#[derive(Debug, Clone)]
pub struct Transaction {
    pub id: u64,
    pub ops: Vec<JournalOp>,
    pub checksum: Checksum,
    pub committed: bool,
}

impl Transaction {
    pub fn new(id: u64) -> Self {
        Transaction {
            id,
            ops: Vec::new(),
            checksum: Checksum(0),
            committed: false,
        }
    }

    pub fn add_op(&mut self, op: JournalOp) {
        self.ops.push(op);
    }

    pub fn finalize(&mut self) {
        let mut data = Vec::new();
        data.extend(self.id.to_le_bytes());
        for op in &self.ops {
            match op {
                JournalOp::Write { block_id, data: d, .. } => {
                    data.push(0x01);
                    data.extend(block_id.to_le_bytes());
                    data.extend(d);
                }
                JournalOp::Delete { block_id } => {
                    data.push(0x02);
                    data.extend(block_id.to_le_bytes());
                }
                JournalOp::CreateInode { ino } => {
                    data.push(0x03);
                    data.extend(ino.to_le_bytes());
                }
                JournalOp::UpdateMeta { ino, field, value } => {
                    data.push(0x04);
                    data.extend(ino.to_le_bytes());
                    data.extend((field.len() as u32).to_le_bytes());
                    data.extend(field.as_bytes());
                    data.extend(value);
                }
            }
        }
        self.checksum = Checksum::compute(&data);
        self.committed = true;
    }
}

#[derive(Debug, PartialEq)]
pub enum JournalError {
    NoTransaction,
    ChecksumMismatch,
    Full,
}

pub struct Journal {
    pub transactions: VecDeque<Transaction>,
    current_tx: Option<Transaction>,
    next_tx_id: u64,
    checkpoint_interval: usize,
    pending_count: usize,
}

impl Journal {
    pub fn new(checkpoint_interval: usize) -> Self {
        Journal {
            transactions: VecDeque::new(),
            current_tx: None,
            next_tx_id: 1,
            checkpoint_interval,
            pending_count: 0,
        }
    }

    pub fn begin(&mut self) -> u64 {
        let id = self.next_tx_id;
        self.next_tx_id += 1;
        self.current_tx = Some(Transaction::new(id));
        id
    }

    pub fn log(&mut self, op: JournalOp) -> Result<(), JournalError> {
        match &mut self.current_tx {
            Some(tx) => {
                tx.add_op(op);
                Ok(())
            }
            None => Err(JournalError::NoTransaction),
        }
    }

    pub fn commit(&mut self) -> Result<(), JournalError> {
        match self.current_tx.take() {
            Some(mut tx) => {
                tx.finalize();
                self.transactions.push_back(tx);
                self.pending_count += 1;
                Ok(())
            }
            None => Err(JournalError::NoTransaction),
        }
    }

    pub fn rollback(&mut self) {
        self.current_tx = None;
    }

    pub fn checkpoint(&mut self) -> Vec<Transaction> {
        if self.pending_count >= self.checkpoint_interval {
            let txs: Vec<Transaction> = self.transactions.drain(..).collect();
            self.pending_count = 0;
            txs
        } else {
            Vec::new()
        }
    }

    pub fn replay(&self) -> Vec<JournalOp> {
        self.transactions
            .iter()
            .filter(|tx| tx.committed)
            .flat_map(|tx| tx.ops.clone())
            .collect()
    }
}

#[derive(Debug, Clone)]
pub struct ChecksummedBlock {
    pub id: u64,
    pub data: [u8; BLOCK_SIZE],
    pub checksum: Checksum,
    pub copies: Vec<usize>,
}

impl ChecksummedBlock {
    pub fn new(id: u64, data: [u8; BLOCK_SIZE]) -> Self {
        let checksum = Checksum::compute(&data);
        ChecksummedBlock {
            id,
            data,
            checksum,
            copies: vec![0],
        }
    }

    pub fn verify(&self) -> bool {
        self.checksum.verify(&self.data)
    }
}

#[derive(Debug, Clone, Copy)]
pub enum Redundancy {
    None,
    Mirror,
    RaidZ1,
    RaidZ2,
}

pub struct VirtualDevice {
    pub id: usize,
    pub blocks: Vec<ChecksummedBlock>,
    pub capacity: usize,
    pub failed: bool,
}

impl VirtualDevice {
    pub fn new(id: usize, capacity: usize) -> Self {
        VirtualDevice {
            id,
            blocks: Vec::new(),
            capacity,
            failed: false,
        }
    }
}

#[derive(Debug, PartialEq)]
pub enum PoolError {
    NoSpace,
    DeviceFailed,
    UnrecoverableError,
    BlockNotFound,
}

pub struct ScrubResult {
    pub blocks_checked: u64,
    pub errors_found: u64,
    pub errors_repaired: u64,
}

pub struct StoragePool {
    pub name: String,
    pub vdevs: Vec<VirtualDevice>,
    total_size: u64,
    used_size: u64,
    redundancy: Redundancy,
}

impl StoragePool {
    pub fn new(name: &str, vdevs: Vec<VirtualDevice>, redundancy: Redundancy) -> Self {
        let total_size: u64 = vdevs.iter().map(|v| v.capacity as u64).sum();
        StoragePool {
            name: name.to_string(),
            vdevs,
            total_size,
            used_size: 0,
            redundancy,
        }
    }

    pub fn write_block(&mut self, block: ChecksummedBlock) -> Result<(), PoolError> {
        match self.redundancy {
            Redundancy::None => {
                if let Some(vdev) = self.vdevs.first_mut() {
                    if vdev.blocks.len() >= vdev.capacity {
                        return Err(PoolError::NoSpace);
                    }
                    vdev.blocks.push(block);
                    self.used_size += 1;
                    Ok(())
                } else {
                    Err(PoolError::DeviceFailed)
                }
            }
            Redundancy::Mirror => {
                for vdev in &mut self.vdevs {
                    if !vdev.failed && vdev.blocks.len() < vdev.capacity {
                        vdev.blocks.push(block.clone());
                    }
                }
                self.used_size += 1;
                Ok(())
            }
            _ => {
                if let Some(vdev) = self.vdevs.first_mut() {
                    vdev.blocks.push(block);
                    self.used_size += 1;
                    Ok(())
                } else {
                    Err(PoolError::DeviceFailed)
                }
            }
        }
    }

    pub fn read_block(&mut self, block_id: u64) -> Result<ChecksummedBlock, PoolError> {
        for vdev in &mut self.vdevs {
            if vdev.failed {
                continue;
            }
            if let Some(block) = vdev.blocks.iter().find(|b| b.id == block_id) {
                if block.verify() {
                    return Ok(block.clone());
                }
            }
        }

        // Self-healing: chercher une copie valide
        if matches!(self.redundancy, Redundancy::Mirror) {
            let mut valid_block: Option<ChecksummedBlock> = None;
            let mut corrupt_vdev_idx: Option<usize> = None;

            for (idx, vdev) in self.vdevs.iter().enumerate() {
                if let Some(block) = vdev.blocks.iter().find(|b| b.id == block_id) {
                    if block.verify() {
                        valid_block = Some(block.clone());
                    } else {
                        corrupt_vdev_idx = Some(idx);
                    }
                }
            }

            if let (Some(valid), Some(corrupt_idx)) = (valid_block.clone(), corrupt_vdev_idx) {
                // Reparer le bloc corrompu
                if let Some(corrupt_block) = self.vdevs[corrupt_idx]
                    .blocks
                    .iter_mut()
                    .find(|b| b.id == block_id)
                {
                    corrupt_block.data = valid.data;
                    corrupt_block.checksum = valid.checksum;
                }
            }

            if let Some(block) = valid_block {
                return Ok(block);
            }
        }

        Err(PoolError::BlockNotFound)
    }

    pub fn scrub(&mut self) -> ScrubResult {
        let mut result = ScrubResult {
            blocks_checked: 0,
            errors_found: 0,
            errors_repaired: 0,
        };

        // Collecter les blocs a verifier
        let mut block_ids: Vec<u64> = Vec::new();
        for vdev in &self.vdevs {
            for block in &vdev.blocks {
                if !block_ids.contains(&block.id) {
                    block_ids.push(block.id);
                }
            }
        }

        for block_id in block_ids {
            result.blocks_checked += 1;

            let mut valid_copy: Option<ChecksummedBlock> = None;
            let mut corrupt_indices: Vec<(usize, usize)> = Vec::new();

            for (vdev_idx, vdev) in self.vdevs.iter().enumerate() {
                for (block_idx, block) in vdev.blocks.iter().enumerate() {
                    if block.id == block_id {
                        if block.verify() {
                            valid_copy = Some(block.clone());
                        } else {
                            corrupt_indices.push((vdev_idx, block_idx));
                        }
                    }
                }
            }

            if !corrupt_indices.is_empty() {
                result.errors_found += corrupt_indices.len() as u64;

                if let Some(valid) = valid_copy {
                    for (vdev_idx, block_idx) in corrupt_indices {
                        self.vdevs[vdev_idx].blocks[block_idx].data = valid.data;
                        self.vdevs[vdev_idx].blocks[block_idx].checksum = valid.checksum;
                        result.errors_repaired += 1;
                    }
                }
            }
        }

        result
    }
}

#[derive(Debug, Clone)]
pub struct Subvolume {
    pub id: u64,
    pub name: String,
    pub root_ino: u64,
    pub parent: Option<u64>,
    pub readonly: bool,
    pub created_at: u64,
}

impl Subvolume {
    pub fn new(id: u64, name: &str) -> Self {
        Subvolume {
            id,
            name: name.to_string(),
            root_ino: id * 1000,
            parent: None,
            readonly: false,
            created_at: 0,
        }
    }

    pub fn snapshot(&self, name: &str, new_id: u64) -> Subvolume {
        Subvolume {
            id: new_id,
            name: name.to_string(),
            root_ino: self.root_ino,
            parent: Some(self.id),
            readonly: true,
            created_at: 0,
        }
    }

    pub fn clone_writable(&self, name: &str, new_id: u64) -> Subvolume {
        Subvolume {
            id: new_id,
            name: name.to_string(),
            root_ino: self.root_ino,
            parent: Some(self.id),
            readonly: false,
            created_at: 0,
        }
    }
}

pub struct L2Cache {
    cache: HashMap<u64, Vec<u8>>,
    max_size: usize,
    current_size: usize,
    pub hits: u64,
    pub misses: u64,
}

impl L2Cache {
    pub fn new(max_size: usize) -> Self {
        L2Cache {
            cache: HashMap::new(),
            max_size,
            current_size: 0,
            hits: 0,
            misses: 0,
        }
    }

    pub fn get(&mut self, block_id: u64) -> Option<Vec<u8>> {
        match self.cache.get(&block_id) {
            Some(data) => {
                self.hits += 1;
                Some(data.clone())
            }
            None => {
                self.misses += 1;
                None
            }
        }
    }

    pub fn put(&mut self, block_id: u64, data: Vec<u8>) {
        let data_size = data.len();

        // Eviction simple si necessaire
        while self.current_size + data_size > self.max_size && !self.cache.is_empty() {
            if let Some(&first_key) = self.cache.keys().next() {
                if let Some(removed) = self.cache.remove(&first_key) {
                    self.current_size -= removed.len();
                }
            }
        }

        if self.current_size + data_size <= self.max_size {
            self.current_size += data_size;
            self.cache.insert(block_id, data);
        }
    }

    pub fn hit_ratio(&self) -> f64 {
        let total = self.hits + self.misses;
        if total == 0 {
            0.0
        } else {
            self.hits as f64 / total as f64
        }
    }
}

#[derive(Debug, PartialEq)]
pub enum FsError {
    Journal(JournalError),
    Pool(PoolError),
    NotFound,
    ReadOnly,
}

pub struct DefragStats {
    pub blocks_moved: u64,
    pub fragmentation_before: f64,
    pub fragmentation_after: f64,
}

pub struct RecoveryResult {
    pub transactions_replayed: usize,
    pub blocks_recovered: usize,
    pub errors: Vec<String>,
}

pub struct CowFS {
    pool: StoragePool,
    journal: Journal,
    subvolumes: HashMap<u64, Subvolume>,
    block_tree: BTreeMap<u64, u64>,  // logical -> physical
    cow_pending: HashMap<u64, u64>,
    l2arc: Option<Arc<RwLock<L2Cache>>>,
    next_physical: u64,
    next_subvol_id: u64,
}

impl CowFS {
    pub fn new(pool: StoragePool, journal_interval: usize) -> Self {
        CowFS {
            pool,
            journal: Journal::new(journal_interval),
            subvolumes: HashMap::new(),
            block_tree: BTreeMap::new(),
            cow_pending: HashMap::new(),
            l2arc: None,
            next_physical: 0,
            next_subvol_id: 1,
        }
    }

    pub fn with_l2arc(pool: StoragePool, journal_interval: usize, cache_size: usize) -> Self {
        let mut fs = Self::new(pool, journal_interval);
        fs.l2arc = Some(Arc::new(RwLock::new(L2Cache::new(cache_size))));
        fs
    }

    pub fn write(&mut self, logical_block: u64, data: &[u8]) -> Result<(), FsError> {
        // COW: toujours allouer un nouveau bloc physique
        let physical_block = self.next_physical;
        self.next_physical += 1;

        // Creer le bloc avec checksum
        let mut block_data = [0u8; BLOCK_SIZE];
        let copy_len = data.len().min(BLOCK_SIZE);
        block_data[..copy_len].copy_from_slice(&data[..copy_len]);

        let block = ChecksummedBlock::new(physical_block, block_data);

        // Journal: noter l'operation AVANT l'ecriture
        self.journal.begin();
        self.journal.log(JournalOp::Write {
            block_id: physical_block,
            data: data.to_vec(),
            checksum: block.checksum,
        }).map_err(FsError::Journal)?;

        // Ecrire dans le pool
        self.pool.write_block(block).map_err(FsError::Pool)?;

        // Mettre a jour le mapping logique -> physique
        if let Some(&old_physical) = self.block_tree.get(&logical_block) {
            self.cow_pending.insert(logical_block, old_physical);
        }
        self.block_tree.insert(logical_block, physical_block);

        // Commit la transaction
        self.journal.commit().map_err(FsError::Journal)?;

        // Mettre en cache L2ARC
        if let Some(ref cache) = self.l2arc {
            if let Ok(mut cache) = cache.write() {
                cache.put(logical_block, data.to_vec());
            }
        }

        Ok(())
    }

    pub fn read(&mut self, logical_block: u64) -> Result<Vec<u8>, FsError> {
        // Verifier le cache L2ARC d'abord
        if let Some(ref cache) = self.l2arc {
            if let Ok(mut cache) = cache.write() {
                if let Some(data) = cache.get(logical_block) {
                    return Ok(data);
                }
            }
        }

        // Trouver le bloc physique
        let physical_block = self.block_tree.get(&logical_block)
            .ok_or(FsError::NotFound)?;

        // Lire depuis le pool
        let block = self.pool.read_block(*physical_block)
            .map_err(FsError::Pool)?;

        let data = block.data.to_vec();

        // Mettre en cache
        if let Some(ref cache) = self.l2arc {
            if let Ok(mut cache) = cache.write() {
                cache.put(logical_block, data.clone());
            }
        }

        Ok(data)
    }

    pub fn create_subvolume(&mut self, name: &str) -> Result<u64, FsError> {
        let id = self.next_subvol_id;
        self.next_subvol_id += 1;
        let subvol = Subvolume::new(id, name);
        self.subvolumes.insert(id, subvol);
        Ok(id)
    }

    pub fn snapshot(&mut self, subvol_id: u64, name: &str) -> Result<u64, FsError> {
        let subvol = self.subvolumes.get(&subvol_id)
            .ok_or(FsError::NotFound)?
            .clone();

        let new_id = self.next_subvol_id;
        self.next_subvol_id += 1;

        let snapshot = subvol.snapshot(name, new_id);
        self.subvolumes.insert(new_id, snapshot);

        Ok(new_id)
    }

    pub fn defrag(&mut self, _subvol_id: u64) -> Result<DefragStats, FsError> {
        // Calcul de fragmentation simplifie
        let total_blocks = self.block_tree.len();
        let fragments = self.cow_pending.len();

        let frag_before = if total_blocks > 0 {
            fragments as f64 / total_blocks as f64
        } else {
            0.0
        };

        // Nettoyer les anciens blocs COW
        self.cow_pending.clear();

        Ok(DefragStats {
            blocks_moved: fragments as u64,
            fragmentation_before: frag_before,
            fragmentation_after: 0.0,
        })
    }

    pub fn recover(&mut self) -> RecoveryResult {
        let ops = self.journal.replay();
        let mut result = RecoveryResult {
            transactions_replayed: self.journal.transactions.len(),
            blocks_recovered: 0,
            errors: Vec::new(),
        };

        for op in ops {
            match op {
                JournalOp::Write { block_id, data, checksum } => {
                    if Checksum::compute(&data) == checksum {
                        result.blocks_recovered += 1;
                    } else {
                        result.errors.push(format!("Checksum mismatch for block {}", block_id));
                    }
                }
                _ => {}
            }
        }

        result
    }
}
```

### 4.5 Solutions refusees (avec explications)

```rust
// REFUSE: Checksum trivial (ne detecte rien)
impl Checksum {
    pub fn compute(data: &[u8]) -> Self {
        Checksum(data.len() as u64)  // BUG: meme checksum pour donnees differentes!
    }
}
// Pourquoi refuse: Deux blocs differents de meme taille = meme checksum

// REFUSE: Transaction sans atomicite
pub fn commit(&mut self) -> Result<(), JournalError> {
    if let Some(tx) = &self.current_tx {
        self.transactions.push_back(tx.clone());  // BUG: pas de finalize()!
    }
    self.current_tx = None;
    Ok(())
}
// Pourquoi refuse: Transaction non finalisee, pas de checksum

// REFUSE: COW qui ecrase
pub fn write(&mut self, logical_block: u64, data: &[u8]) -> Result<(), FsError> {
    let physical = *self.block_tree.get(&logical_block).unwrap_or(&0);
    // BUG: reutilise le meme bloc physique!
    let mut block_data = [0u8; BLOCK_SIZE];
    block_data[..data.len()].copy_from_slice(data);
    // Ecrase le bloc existant
}
// Pourquoi refuse: Viole le principe COW, donnees originales perdues

// REFUSE: Self-healing sans verification
pub fn read_block(&mut self, block_id: u64) -> Result<ChecksummedBlock, PoolError> {
    for vdev in &self.vdevs {
        if let Some(block) = vdev.blocks.iter().find(|b| b.id == block_id) {
            return Ok(block.clone());  // BUG: pas de verify()!
        }
    }
    Err(PoolError::BlockNotFound)
}
// Pourquoi refuse: Retourne des donnees potentiellement corrompues
```

### 4.9 spec.json

```json
{
  "name": "journalfs_cow",
  "language": "rust",
  "type": "complet",
  "tier": 3,
  "tier_info": "Synthese",
  "tags": ["filesystem", "journaling", "cow", "zfs", "checksums", "phase2"],
  "passing_score": 70,

  "function": {
    "name": "CowFS::new",
    "prototype": "pub fn new(pool: StoragePool, journal_interval: usize) -> Self",
    "return_type": "CowFS",
    "parameters": [
      {"name": "pool", "type": "StoragePool"},
      {"name": "journal_interval", "type": "usize"}
    ]
  },

  "driver": {
    "edge_cases": [
      {
        "name": "checksum_valid",
        "setup": "let data = [42u8; BLOCK_SIZE];",
        "call": "Checksum::compute(&data).verify(&data)",
        "check": "result == true",
        "is_trap": false
      },
      {
        "name": "checksum_corrupt",
        "setup": "let data = [42u8; BLOCK_SIZE]; let cs = Checksum::compute(&data); let mut corrupt = data; corrupt[0] = 0;",
        "call": "cs.verify(&corrupt)",
        "check": "result == false",
        "is_trap": true,
        "trap_explanation": "Donnees modifiees doivent invalider le checksum"
      },
      {
        "name": "journal_no_transaction",
        "setup": "let mut journal = Journal::new(10);",
        "call": "journal.log(JournalOp::Delete { block_id: 0 })",
        "check": "result == Err(JournalError::NoTransaction)",
        "is_trap": true,
        "trap_explanation": "Log sans begin() doit echouer"
      },
      {
        "name": "cow_new_physical_block",
        "setup": "let vdev = VirtualDevice::new(0, 1000); let pool = StoragePool::new(\"test\", vec![vdev], Redundancy::None); let mut fs = CowFS::new(pool, 10);",
        "call": "fs.write(0, &[1u8; BLOCK_SIZE]).unwrap(); let first = fs.next_physical; fs.write(0, &[2u8; BLOCK_SIZE]).unwrap(); let second = fs.next_physical;",
        "check": "first != second",
        "is_trap": true,
        "trap_explanation": "COW doit allouer un nouveau bloc, pas ecraser"
      },
      {
        "name": "self_healing_mirror",
        "setup": "let v1 = VirtualDevice::new(0, 100); let v2 = VirtualDevice::new(1, 100); let mut pool = StoragePool::new(\"mirror\", vec![v1, v2], Redundancy::Mirror); let block = ChecksummedBlock::new(0, [42u8; BLOCK_SIZE]); pool.write_block(block).unwrap(); pool.vdevs[0].blocks[0].data[0] = 0xFF;",
        "call": "pool.read_block(0)",
        "check": "result.is_ok() && result.unwrap().verify()",
        "is_trap": true,
        "trap_explanation": "Mirror doit permettre self-healing depuis copie valide"
      }
    ],

    "fuzzing": {
      "enabled": true,
      "iterations": 50,
      "generators": [
        {
          "type": "int",
          "param_index": 0,
          "params": {"min": 1, "max": 100}
        }
      ]
    }
  },

  "norm": {
    "allowed_functions": ["HashMap::new", "BTreeMap::new", "VecDeque::new", "Vec::new"],
    "forbidden_functions": ["unsafe", "std::fs"],
    "check_security": true,
    "check_memory": true,
    "blocking": true
  }
}
```

### 4.10 Solutions Mutantes

```rust
/* Mutant A (Boundary) : Off-by-one dans checkpoint interval */
impl Journal {
    pub fn checkpoint(&mut self) -> Vec<Transaction> {
        // BUG: > au lieu de >=
        if self.pending_count > self.checkpoint_interval {
            let txs: Vec<Transaction> = self.transactions.drain(..).collect();
            self.pending_count = 0;
            txs
        } else {
            Vec::new()
        }
    }
}
// Pourquoi c'est faux : Ne checkpoint jamais si pending == interval exactement
// Ce qui etait pense : "Je veux plus que l'intervalle"

/* Mutant B (Safety) : Pas de verification checksum avant retour */
impl StoragePool {
    pub fn read_block(&mut self, block_id: u64) -> Result<ChecksummedBlock, PoolError> {
        for vdev in &self.vdevs {
            if let Some(block) = vdev.blocks.iter().find(|b| b.id == block_id) {
                return Ok(block.clone());  // BUG: pas de verify()!
            }
        }
        Err(PoolError::BlockNotFound)
    }
}
// Pourquoi c'est faux : Retourne des donnees corrompues sans detection
// Ce qui etait pense : "Le bloc existe donc il est valide"

/* Mutant C (Resource) : COW sans garder l'ancien bloc */
impl CowFS {
    pub fn write(&mut self, logical_block: u64, data: &[u8]) -> Result<(), FsError> {
        let physical_block = self.next_physical;
        self.next_physical += 1;

        let mut block_data = [0u8; BLOCK_SIZE];
        block_data[..data.len().min(BLOCK_SIZE)].copy_from_slice(&data[..data.len().min(BLOCK_SIZE)]);
        let block = ChecksummedBlock::new(physical_block, block_data);

        self.pool.write_block(block).map_err(FsError::Pool)?;
        // BUG: ecrase directement sans sauvegarder l'ancien dans cow_pending
        self.block_tree.insert(logical_block, physical_block);
        Ok(())
    }
}
// Pourquoi c'est faux : Perd la reference a l'ancien bloc, defrag impossible
// Ce qui etait pense : "On n'a besoin que du nouveau bloc"

/* Mutant D (Logic) : Hit ratio inverse */
impl L2Cache {
    pub fn hit_ratio(&self) -> f64 {
        let total = self.hits + self.misses;
        if total == 0 {
            0.0
        } else {
            self.misses as f64 / total as f64  // BUG: misses au lieu de hits!
        }
    }
}
// Pourquoi c'est faux : Retourne le miss ratio au lieu du hit ratio
// Ce qui etait pense : "Je calcule un ratio"

/* Mutant E (Return) : Transaction finalize sans checksum */
impl Transaction {
    pub fn finalize(&mut self) {
        self.committed = true;
        // BUG: pas de calcul de checksum!
    }
}
// Pourquoi c'est faux : Transaction sans checksum, corruption non detectee au replay
// Ce qui etait pense : "committed = true suffit pour marquer complete"
```

---

## ğŸ§  SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

1. **Journalisation (WAL)** : L'art de ne jamais perdre de donnees grace au write-ahead logging
2. **Copy-on-Write** : Pourquoi ne jamais ecraser est la cle de la coherence
3. **Checksums et integrite** : Detection et correction automatique des corruptions
4. **Transactions ACID** : Atomicite via journal, Coherence via COW, Isolation via locks, Durabilite via checkpoint
5. **Caching intelligent** : Le L2ARC comme exemple de cache a plusieurs niveaux

### 5.2 LDA â€” Traduction Litterale

```
FONCTION write QUI RETOURNE UN RESULTAT VIDE OU UNE ERREUR ET PREND EN PARAMETRE logical_block QUI EST UN ENTIER NON SIGNE 64 BITS ET data QUI EST UNE REFERENCE VERS UN TABLEAU D'OCTETS
DEBUT FONCTION
    DECLARER physical_block COMME ENTIER NON SIGNE 64 BITS
    AFFECTER self.next_physical A physical_block
    INCREMENTER self.next_physical DE 1

    DECLARER block_data COMME TABLEAU DE BLOCK_SIZE OCTETS INITIALISE A ZERO
    DECLARER copy_len COMME LE MINIMUM ENTRE LA LONGUEUR DE data ET BLOCK_SIZE
    COPIER LES copy_len PREMIERS OCTETS DE data DANS block_data

    DECLARER block COMME UN NOUVEAU ChecksummedBlock AVEC physical_block ET block_data

    APPELER self.journal.begin()
    APPELER self.journal.log AVEC L'OPERATION Write
    SI ERREUR ALORS RETOURNER ERREUR
    FIN SI

    APPELER self.pool.write_block AVEC block
    SI ERREUR ALORS RETOURNER ERREUR
    FIN SI

    SI self.block_tree CONTIENT logical_block ALORS
        DECLARER old_physical COMME LA VALEUR ASSOCIEE
        INSERER (logical_block, old_physical) DANS self.cow_pending
    FIN SI

    INSERER (logical_block, physical_block) DANS self.block_tree

    APPELER self.journal.commit()
    SI ERREUR ALORS RETOURNER ERREUR
    FIN SI

    SI self.l2arc N'EST PAS None ALORS
        APPELER cache.put AVEC logical_block ET data
    FIN SI

    RETOURNER SUCCES
FIN FONCTION
```

### 5.2.2 Logic Flow

```
ALGORITHME : Ecriture COW avec journalisation
---
1. ALLOUER un nouveau bloc physique (COW: jamais ecraser)
   physical_block = next_physical++

2. PREPARER les donnees avec checksum
   block = ChecksummedBlock::new(physical_block, data)

3. JOURNALISER l'intention (Write-Ahead Log)
   journal.begin()
   journal.log(Write { block_id, data, checksum })

4. ECRIRE dans le pool de stockage
   pool.write_block(block)

5. METTRE A JOUR le mapping COW
   SI bloc logique existait:
      cow_pending[logical] = ancien_physical
   block_tree[logical] = nouveau_physical

6. COMMIT la transaction
   journal.commit()

7. METTRE EN CACHE (L2ARC)
   SI cache disponible:
      l2arc.put(logical_block, data)

8. RETOURNER succes
```

### 5.2.3 Representation algorithmique

```
ALGORITHME : Self-healing lors de la lecture
---
ENTREE: block_id a lire
SORTIE: ChecksummedBlock valide ou erreur

1. POUR CHAQUE vdev non-failed DANS pool:
   a. CHERCHER bloc avec id == block_id
   b. SI trouve ET verify() == true:
      RETOURNER bloc (succes rapide)

2. SI redundance == Mirror:
   a. COLLECTER toutes les copies du bloc
   b. IDENTIFIER copies valides (verify() == true)
   c. IDENTIFIER copies corrompues

   d. SI copie valide existe:
      - REPARER copies corrompues avec donnees valides
      - RETOURNER copie valide

3. RETOURNER erreur (bloc non recuperable)
```

### 5.2.3.1 Logique de Garde (Fail Fast)

```rust
// GUARD 1: Transaction active requise
pub fn log(&mut self, op: JournalOp) -> Result<(), JournalError> {
    let tx = self.current_tx.as_mut()
        .ok_or(JournalError::NoTransaction)?;  // FAIL FAST
    tx.add_op(op);
    Ok(())
}

// GUARD 2: Bloc doit exister pour lecture
pub fn read(&mut self, logical_block: u64) -> Result<Vec<u8>, FsError> {
    let physical_block = self.block_tree.get(&logical_block)
        .ok_or(FsError::NotFound)?;  // FAIL FAST
    // ...
}

// GUARD 3: Checksum valide requis
pub fn read_block(&mut self, block_id: u64) -> Result<ChecksummedBlock, PoolError> {
    // Premiere passe: chercher bloc valide directement
    // Deuxieme passe: self-healing si mirror
    // FAIL si aucune copie valide
}
```

### 5.3 Visualisation ASCII

```
                    ARCHITECTURE COW FILESYSTEM
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚  APPLICATION                                                            â”‚
â”‚       â”‚                                                                 â”‚
â”‚       â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         CowFS                                    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚   â”‚
â”‚  â”‚  â”‚   JOURNAL   â”‚  â”‚  BLOCK_TREE  â”‚  â”‚       L2ARC CACHE       â”‚â”‚   â”‚
â”‚  â”‚  â”‚ (WAL/ZIL)   â”‚  â”‚ logicalâ†’phys â”‚  â”‚   block_id â†’ data       â”‚â”‚   â”‚
â”‚  â”‚  â”‚             â”‚  â”‚              â”‚  â”‚                         â”‚â”‚   â”‚
â”‚  â”‚  â”‚ TX1: Write  â”‚  â”‚ 0 â†’ 100     â”‚  â”‚  [0]: [42,42,42,...]    â”‚â”‚   â”‚
â”‚  â”‚  â”‚ TX2: Write  â”‚  â”‚ 1 â†’ 101     â”‚  â”‚  [1]: [FF,FF,FF,...]    â”‚â”‚   â”‚
â”‚  â”‚  â”‚ TX3: Delete â”‚  â”‚ 2 â†’ 105     â”‚  â”‚                         â”‚â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚                                                                 â”‚
â”‚       â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      STORAGE POOL                                â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚   â”‚
â”‚  â”‚  â”‚    VDEV 0       â”‚      â”‚    VDEV 1       â”‚   (MIRROR)        â”‚   â”‚
â”‚  â”‚  â”‚   (Primary)     â”‚      â”‚   (Secondary)   â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚                 â”‚      â”‚                 â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚ [100]: data+cs  â”‚â—„â”€â”€â”€â”€â–ºâ”‚ [100]: data+cs  â”‚  â† Self-healing   â”‚   â”‚
â”‚  â”‚  â”‚ [101]: data+cs  â”‚â—„â”€â”€â”€â”€â–ºâ”‚ [101]: data+cs  â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚ [105]: data+cs  â”‚â—„â”€â”€â”€â”€â–ºâ”‚ [105]: data+cs  â”‚                   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    COPY-ON-WRITE EN ACTION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚  AVANT write(0, new_data):                                             â”‚
â”‚                                                                         â”‚
â”‚  block_tree          Storage                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ 0 â†’ 100   â”‚ â”€â”€â”€â”€ â”‚ [100]: [OLD_DATA] + checksum    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                         â”‚
â”‚  APRES write(0, new_data):                                             â”‚
â”‚                                                                         â”‚
â”‚  block_tree          Storage                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ 0 â†’ 101   â”‚ â”€â”€â”€â”€ â”‚ [100]: [OLD_DATA] + checksum    â”‚ â† Intact!     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ [101]: [NEW_DATA] + checksum    â”‚ â† Nouveau     â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚  cow_pending                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚  â”‚ 0 â†’ 100   â”‚  â† Reference a l'ancien bloc (pour rollback/snapshot)  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚                                                                         â”‚
â”‚  AVANTAGES:                                                            â”‚
â”‚  âœ“ Pas de corruption possible (ancien bloc intact)                     â”‚
â”‚  âœ“ Snapshot gratuit (partage des blocs non modifies)                   â”‚
â”‚  âœ“ Rollback instantane (pointer vers ancien bloc)                      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    JOURNAL TRANSACTION FLOW
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚  TEMPS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚BEGINâ”‚â”€â”€â”‚ LOG(Write block 0) â”‚â”€â”€â”‚ COMMIT  â”‚â”€â”€â”‚ CHECKPOINT       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â”‚ LOG(Write block 1) â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ (apply to disk)  â”‚  â”‚
â”‚     â”‚     â”‚ LOG(Delete blk 2)  â”‚       â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚                             â”‚
â”‚     â”‚              â”‚                     â”‚                             â”‚
â”‚     â–¼              â–¼                     â–¼                             â”‚
â”‚  current_tx    current_tx.ops      transactions                       â”‚
â”‚  = Some(TX)    = [op1, op2, op3]   .push(TX)                          â”‚
â”‚                                                                         â”‚
â”‚  SI CRASH ICI:     SI CRASH ICI:       SI CRASH ICI:                  â”‚
â”‚  â†’ Rien a faire    â†’ TX perdue         â†’ TX dans journal,             â”‚
â”‚    (pas de TX)       (incomplete)        replay au boot               â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ RECOVERY APRES CRASH:                                            â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚ 1. Lire le journal                                              â”‚  â”‚
â”‚  â”‚ 2. Pour chaque TX avec committed=true:                          â”‚  â”‚
â”‚  â”‚    - Verifier checksum                                          â”‚  â”‚
â”‚  â”‚    - Rejouer les operations                                     â”‚  â”‚
â”‚  â”‚ 3. Les TX incomplete sont ignorees (rollback implicite)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    SELF-HEALING AVEC MIRROR
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚  SITUATION: Bloc 100 corrompu sur VDEV 0 (bit flip, bad sector, etc)  â”‚
â”‚                                                                         â”‚
â”‚     VDEV 0                    VDEV 1                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ [100]: CORRUPT  â”‚      â”‚ [100]: VALID    â”‚                         â”‚
â”‚  â”‚ checksum: FAIL  â”‚      â”‚ checksum: OK    â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                         â”‚
â”‚  LECTURE read_block(100):                                              â”‚
â”‚                                                                         â”‚
â”‚  1. Essayer VDEV 0 â†’ verify() = FALSE                                 â”‚
â”‚  2. Essayer VDEV 1 â†’ verify() = TRUE âœ“                                â”‚
â”‚  3. SELF-HEALING:                                                      â”‚
â”‚     - Copier donnees valides vers VDEV 0                              â”‚
â”‚     - Recalculer checksum                                             â”‚
â”‚  4. Retourner bloc valide                                             â”‚
â”‚                                                                         â”‚
â”‚     APRES SELF-HEALING:                                                â”‚
â”‚                                                                         â”‚
â”‚     VDEV 0                    VDEV 1                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚ [100]: VALID    â”‚      â”‚ [100]: VALID    â”‚                         â”‚
â”‚  â”‚ checksum: OK âœ“  â”‚      â”‚ checksum: OK âœ“  â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                         â”‚
â”‚  âœ“ Utilisateur ne voit RIEN (transparent)                             â”‚
â”‚  âœ“ Donnees retournees sont TOUJOURS correctes                         â”‚
â”‚  âœ“ Corruption reparee automatiquement                                 â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.4 Les pieges en detail

| Piege | Description | Solution |
|-------|-------------|----------|
| Checksum trivial | Utiliser len() comme checksum | Utiliser FNV, CRC ou autre hash |
| COW qui ecrase | Reutiliser le meme bloc physique | Toujours allouer nouveau bloc |
| Journal sans commit | Oublier finalize() | Toujours finalize avant push |
| Self-heal sans verify | Retourner sans verifier checksum | Toujours verify() avant retour |
| Cache sans eviction | Memoire infinie | Implementer LRU ou FIFO |

### 5.5 Cours Complet

#### 5.5.1 Write-Ahead Logging (WAL)

Le WAL est le coeur de la durabilite dans les bases de donnees et filesystems modernes. Le principe est simple mais puissant :

**Regle d'or** : Avant TOUTE modification de donnees, ecrire l'intention dans le journal.

```
SEQUENCE NORMALE:
1. Journal: "Je vais ecrire X dans bloc Y"
2. Ecrire X dans bloc Y
3. Journal: "Ecriture X dans Y terminee"

SI CRASH PENDANT ETAPE 2:
â†’ Au redemarrage, le journal dit "ecriture en cours"
â†’ Soit rejouer (redo), soit annuler (undo)
â†’ JAMAIS de donnees dans un etat incoherent
```

**Types de journaling:**

| Type | Journalise | Performance | Securite |
|------|------------|-------------|----------|
| Data | Metadonnees + Donnees | Lente | Maximale |
| Ordered | Metadonnees (data sync) | Moyenne | Haute |
| Writeback | Metadonnees seulement | Rapide | Faible |

ext4 utilise "ordered" par defaut : les donnees sont ecrites AVANT les metadonnees.

#### 5.5.2 Copy-on-Write (COW)

Le COW resout elegamment le probleme de la coherence :

**Filesystem traditionnel (ext4):**
```
1. Lire bloc
2. Modifier en memoire
3. Ecrire par-dessus l'original
   â†’ Si crash ici = CORRUPTION
```

**COW (btrfs, ZFS):**
```
1. Lire bloc original
2. Modifier en memoire
3. Ecrire dans NOUVEAU bloc
4. Mettre a jour pointeur atomiquement
   â†’ Si crash avant 4 = Ancien bloc intact
   â†’ Si crash pendant 4 = Transaction incomplete, rollback
```

**Avantage majeur : Snapshots instantanes**

Creer un snapshot = copier le pointeur racine. Cout: O(1).

Quand on modifie apres snapshot :
- Original et snapshot partagent les blocs non modifies
- Seuls les blocs modifies sont dupliques

#### 5.5.3 Checksums et Self-Healing

**Le probleme du "bit rot":**
Les disques mentent. Un secteur peut retourner des donnees corrompues sans erreur.

**Solution ZFS/btrfs:**
```
Chaque bloc stocke:
[DONNEES (4KB)] + [CHECKSUM (8 bytes)]

A la lecture:
1. Lire bloc + checksum
2. Recalculer checksum des donnees
3. Comparer avec checksum stocke
4. Si mismatch + redondance â†’ self-heal
5. Si mismatch sans redondance â†’ erreur I/O
```

**Algorithmes de checksum:**
- Fletcher-4 (ZFS) : Rapide, detecte la plupart des erreurs
- CRC32C (btrfs) : Standard, hardware accelere
- SHA-256 (ZFS dedup) : Cryptographique, lent mais sur

#### 5.5.4 ZFS Specifique: ZIL et L2ARC

**ZIL (ZFS Intent Log):**
```
Application fait sync write
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ZIL (sur SSD)    â”‚  â† Ecriture synchrone rapide
â”‚ Intent Log       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼ (async)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Main Pool (HDD)  â”‚  â† Ecriture finale plus tard
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Resultat: Latence du SSD, capacite du HDD
```

**L2ARC (Level 2 Adaptive Replacement Cache):**
```
          Lecture
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ARC (RAM)      â”‚ L2ARC (SSD)    â”‚ Pool (HDD)        â”‚
â”‚ 32GB           â”‚ 500GB          â”‚ 100TB             â”‚
â”‚ Tres rapide    â”‚ Rapide         â”‚ Lent              â”‚
â”‚                â”‚                â”‚                   â”‚
â”‚ Hot data       â”‚ Warm data      â”‚ Cold data         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Si dans ARC: 1ms
Si dans L2ARC: 10ms
Si sur HDD: 100ms
```

### 5.6 Normes avec explications pedagogiques

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ HORS NORME (compile, mais incorrect)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pub fn write(&mut self, block: u64, data: &[u8]) {              â”‚
â”‚     let physical = self.block_tree.get(&block).unwrap();        â”‚
â”‚     // Ecrase directement le bloc physique existant             â”‚
â”‚     self.storage[physical] = data;                              â”‚
â”‚ }                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… CONFORME                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pub fn write(&mut self, block: u64, data: &[u8]) {              â”‚
â”‚     let new_physical = self.allocate_block();                   â”‚
â”‚     self.storage[new_physical] = data;                          â”‚
â”‚     self.block_tree.insert(block, new_physical);                â”‚
â”‚ }                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“– POURQUOI ?                                                   â”‚
â”‚                                                                 â”‚
â”‚ â€¢ COW garantit que l'ancien bloc reste intact                  â”‚
â”‚ â€¢ Permet rollback instantane en cas d'echec                    â”‚
â”‚ â€¢ Snapshots partagent les blocs non modifies                   â”‚
â”‚ â€¢ Pas de corruption possible lors d'un crash                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.7 Simulation avec trace d'execution

**Scenario** : Ecrire 2 blocs, puis creer un snapshot, puis modifier le bloc 0

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Etape â”‚ Instruction                          â”‚ block_tree              â”‚ Etat COW                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   1   â”‚ fs.write(0, [0xAA; 4096])            â”‚ {0â†’100}                 â”‚ next_physical=101           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   2   â”‚ fs.write(1, [0xBB; 4096])            â”‚ {0â†’100, 1â†’101}          â”‚ next_physical=102           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   3   â”‚ fs.create_subvolume("data")          â”‚ {0â†’100, 1â†’101}          â”‚ subvol[1]="data"            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   4   â”‚ fs.snapshot(1, "backup")             â”‚ {0â†’100, 1â†’101}          â”‚ subvol[2]="backup",readonly â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   5   â”‚ fs.write(0, [0xCC; 4096])            â”‚ {0â†’102, 1â†’101}          â”‚ cow_pending={0â†’100}         â”‚
â”‚       â”‚                                      â”‚                         â”‚ next_physical=103           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FIN  â”‚ Snapshot "backup" voit:              â”‚ Snapshot: {0â†’100,1â†’101} â”‚ Partage bloc 101 (non mod)  â”‚
â”‚       â”‚ bloc 0 = 0xAA (ancien)               â”‚ Current: {0â†’102,1â†’101}  â”‚ Bloc 100 intact             â”‚
â”‚       â”‚ bloc 1 = 0xBB                        â”‚                         â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.8 Mnemotechniques

#### ğŸ® MEME : "DARK SOULS Bonfires" â€” Journaling

Les bonfires de Dark Souls sont des checkpoints. Le journal, c'est ton bonfire : si tu crash (meurs), tu reviens au dernier commit (bonfire) avec tout ton progres sauvegarde.

```rust
// ğŸ”¥ Un commit = un bonfire atteint
journal.commit()  // "You have rested at a bonfire"

// ğŸ’€ Un crash sans commit = souls lost
// Toutes les operations depuis le dernier commit sont perdues
```

#### ğŸ® MEME : "Bloodstain Recovery" â€” Copy-on-Write

Quand tu meurs dans Dark Souls, tes ames ne disparaissent pas â€” elles restent la ou tu es mort (bloodstain). Tu as une chance de les recuperer. Le COW fait pareil : les anciennes donnees restent intactes jusqu'a ce que tu les "recuperes" (garbage collect) ou les "perdes" (ecrasement confirme).

```rust
// ğŸ’€ Tu meurs (crash pendant ecriture)
// Les ames (anciennes donnees) sont toujours la
cow_pending.get(&block_id)  // Ta bloodstain

// ğŸ”„ Tu recuperes tes ames (rollback)
block_tree.insert(block_id, old_physical);  // Retour au bloc original
```

#### ğŸ›¡ï¸ MEME : "Estus Flask Self-Heal" â€” Checksums + Redundance

L'Estus Flask te heal automatiquement quand tu es blesse. Le self-healing fait pareil pour les donnees : quand un bloc est "blesse" (corrompu), le systeme le "heal" automatiquement depuis une copie valide.

```rust
// ğŸ§ª Estus = copie miroir valide
if !block.verify() && redundancy == Mirror {
    let valid_copy = find_valid_copy(block_id);
    repair(corrupt_block, valid_copy);  // *glug glug* healed!
}
```

### 5.9 Applications pratiques

1. **ZFS en production** : NAS (FreeNAS/TrueNAS), serveurs de fichiers
2. **btrfs** : Systemes Linux, containers (Docker)
3. **PostgreSQL WAL** : Durabilite des transactions
4. **LevelDB/RocksDB** : Databases embedded (Chrome, Android)
5. **WAFL (NetApp)** : Stockage enterprise
6. **AWS EBS** : Snapshots de volumes cloud

---

## âš ï¸ SECTION 6 : PIEGES â€” RECAPITULATIF

| # | Piege | Consequence | Detection |
|---|-------|-------------|-----------|
| 1 | Checksum = len() | Collision pour blocs de meme taille | Test donnees differentes, meme taille |
| 2 | COW qui ecrase | Corruption lors de crash | Verifier 2 blocs physiques apres 2 writes |
| 3 | Commit sans finalize | Transaction sans checksum | Verifier tx.checksum != 0 apres commit |
| 4 | Read sans verify | Retourne donnees corrompues | Test avec corruption manuelle |
| 5 | Hit ratio inverse | Metriques fausses | Verifier ratio apres sequence connue |

---

## ğŸ“ SECTION 7 : QCM

### Q1. Quel est le principe fondamental du Write-Ahead Logging ?

- A) Ecrire les donnees avant le journal
- B) Ecrire le journal avant les donnees
- C) Ecrire donnees et journal simultanement
- D) Ne jamais ecrire de journal
- E) Ecrire le journal apres verification
- F) Compresser le journal avant ecriture
- G) Chiffrer le journal
- H) Dupliquer le journal
- I) Supprimer le journal apres commit
- J) Ignorer le journal en cas de crash

**Reponse : B** (Le "A" de WAL = "Ahead" = avant)

### Q2. Pourquoi le COW ne modifie-t-il jamais les blocs existants ?

- A) Pour economiser de l'espace
- B) Pour accelerer les ecritures
- C) Pour garantir la coherence en cas de crash
- D) Pour simplifier le code
- E) Par convention historique
- F) Pour compatibilite Windows
- G) Pour reduire la fragmentation
- H) Pour eviter les locks
- I) Pour supporter le chiffrement
- J) Sans raison particuliere

**Reponse : C** (L'ancien bloc reste intact = jamais de corruption)

### Q3. Que fait le self-healing quand il detecte un bloc corrompu ?

- A) Supprime le bloc
- B) Retourne une erreur
- C) Ignore la corruption
- D) Restaure depuis une copie valide si disponible
- E) Demande intervention utilisateur
- F) Reduit les performances
- G) Formate le disque
- H) Cree un nouveau fichier
- I) Envoie une alerte
- J) Rien

**Reponse : D** (Avec redondance, il repare automatiquement)

### Q4. Quel est l'avantage majeur des snapshots COW ?

- A) Ils sont plus petits que l'original
- B) Ils sont crees instantanement sans copie
- C) Ils sont plus rapides a lire
- D) Ils ne consomment pas d'espace
- E) Ils sont automatiquement compresses
- F) Ils sont chiffres
- G) Ils sont repliques
- H) Ils sont indexes
- I) Ils sont valides indefiniment
- J) Ils remplacent les backups

**Reponse : B** (Creation en O(1), partage des blocs)

### Q5. A quoi sert le L2ARC dans ZFS ?

- A) A stocker le journal
- B) A cacher les metadonnees
- C) A servir de cache de lecture sur SSD
- D) A compresser les donnees
- E) A dedupliquer les blocs
- F) A chiffrer les donnees
- G) A reparer les erreurs
- H) A gerer les snapshots
- I) A equilibrer la charge
- J) A monitorer les performances

**Reponse : C** (Level 2 Adaptive Replacement Cache = cache SSD)

---

## ğŸ“Š SECTION 8 : RECAPITULATIF

| Critere | Valeur |
|---------|--------|
| Difficulte | â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜† (7/10) |
| Temps estime | 180 min |
| XP Base | 250 |
| XP Bonus (Ã—3) | 750 |
| Concepts cles | Journaling, COW, Checksums, Self-Healing, Snapshots, L2ARC |
| Langage | Rust 2024 |
| Type | complet |
| Tier | 3 â€” Synthese |

---

## ğŸ“¦ SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "2.3.4-journalfs-cow",
    "generated_at": "2026-01-16 12:00:00",

    "metadata": {
      "exercise_id": "2.3.4",
      "exercise_name": "journalfs_cow",
      "module": "2.3.4",
      "module_name": "Journaling et Copy-on-Write Filesystem",
      "concept": "a",
      "concept_name": "Journalisation transactionnelle et COW",
      "type": "complet",
      "tier": 3,
      "tier_info": "Synthese",
      "phase": 2,
      "difficulty": 7,
      "difficulty_stars": "â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜†",
      "language": "rust",
      "duration_minutes": 180,
      "xp_base": 250,
      "xp_bonus_multiplier": 3,
      "bonus_tier": "AVANCE",
      "bonus_icon": "ğŸ”¥",
      "complexity_time": "T3 O(log n)",
      "complexity_space": "S3 O(n)",
      "prerequisites": ["data_structures", "transactions", "filesystem_basics", "raid"],
      "domains": ["FS", "Struct", "Mem", "Crypto"],
      "domains_bonus": ["Algo", "Struct", "Crypto"],
      "tags": ["journaling", "cow", "zfs", "btrfs", "checksums", "self-healing", "snapshots"],
      "meme_reference": "DARK SOULS Bonfires"
    },

    "files": {
      "spec.json": "/* Section 4.9 */",
      "references/ref_solution.rs": "/* Section 4.3 */",
      "mutants/mutant_a_boundary.rs": "/* Section 4.10 - Checkpoint interval off-by-one */",
      "mutants/mutant_b_safety.rs": "/* Section 4.10 - No checksum verify */",
      "mutants/mutant_c_resource.rs": "/* Section 4.10 - COW without cow_pending */",
      "mutants/mutant_d_logic.rs": "/* Section 4.10 - Hit ratio inverted */",
      "mutants/mutant_e_return.rs": "/* Section 4.10 - Finalize without checksum */",
      "tests/main.rs": "/* Section 4.2 */"
    },

    "validation": {
      "expected_pass": ["references/ref_solution.rs"],
      "expected_fail": [
        "mutants/mutant_a_boundary.rs",
        "mutants/mutant_b_safety.rs",
        "mutants/mutant_c_resource.rs",
        "mutants/mutant_d_logic.rs",
        "mutants/mutant_e_return.rs"
      ]
    },

    "commands": {
      "test": "cargo test",
      "validate_spec": "python3 hackbrain_engine_v22.py --validate-spec spec.json"
    }
  }
}
```

---

*HACKBRAIN v5.5.2 â€” L'excellence pedagogique ne se negocie pas*
*Phase 2 â€” Module 2.3.4 â€” Journaling et Copy-on-Write Filesystem*
*"Praise the Sun! Your data shall never go hollow."*

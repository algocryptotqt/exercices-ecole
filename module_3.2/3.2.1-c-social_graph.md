# Exercice 3.2.1-c : social_graph

**Module :**
3.2.1 â€” Reconnaissance & OSINT

**Concept :**
c â€” Social Media OSINT (LinkedIn, TheHarvester, GitHub)

**DifficultÃ© :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜† (7/10)

**Type :**
complet

**Tiers :**
1 â€” Concept isolÃ©

**Langage :**
Rust Edition 2024

**PrÃ©requis :**
3.2.1-a (OSINT methodology), 3.2.1-b (Search Engine Intelligence)

**Domaines :**
Net, Struct, MD

**DurÃ©e estimÃ©e :**
180 min

**XP Base :**
200

**ComplexitÃ© :**
T3 O(V+E) Ã— S3 O(V+E)

---

## ğŸ“ SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichier :** `social_graph.rs`
**Fonctions autorisÃ©es :** serde, serde_json, regex, std::collections
**Interdit :** Appels rÃ©seau, bases de donnÃ©es externes, threads

### 1.2 Consigne

#### 1.2.1 Version Culture Pop

**ğŸ® "Person of Interest" â€” The Machine's Social Network**

*"You are being watched. The government has a secret system, a machine that spies on you every hour of every day."* â€” Intro de Person of Interest

Tu es **Harold Finch**, le crÃ©ateur de The Machine. Aujourd'hui, ta tÃ¢che n'est pas de prÃ©dire des crimes, mais de cartographier les connexions sociales d'un groupe cible Ã  partir de donnÃ©es OSINT. Comme The Machine qui analyse chaque flux de donnÃ©es pour trouver les "personnes d'intÃ©rÃªt", tu dois analyser les profils LinkedIn, les emails collectÃ©s par TheHarvester, et les repositories GitHub pour construire un **Social Graph** rÃ©vÃ©lant les relations cachÃ©es.

Chaque personne est un **numÃ©ro** â€” un nÅ“ud dans ton graphe. Chaque connexion (collÃ¨gue, ami, contributeur GitHub) est une arÃªte qui raconte une histoire. Mais attention : certaines personnes tentent de cacher leurs traces. Des pseudonymes GitHub peuvent correspondre Ã  des profils LinkedIn. Des emails peuvent rÃ©vÃ©ler des affiliations secrÃ¨tes.

**Ta mission :**

Ã‰crire un systÃ¨me `social_graph` qui :

1. **Parse les donnÃ©es hÃ©tÃ©rogÃ¨nes** â€” Profiles LinkedIn (simulÃ©s), rÃ©sultats TheHarvester (emails), repos GitHub (commits, contributors)
2. **Construit un graphe de relations** â€” Qui connaÃ®t qui ? Qui travaille oÃ¹ ? Qui contribue aux mÃªmes projets ?
3. **Calcule la centralitÃ©** â€” Identifie les personnes clÃ©s du rÃ©seau (les "Numbers" importants)
4. **DÃ©tecte les fuites dans les repos** â€” Patterns de secrets exposÃ©s (API keys, credentials, tokens)
5. **GÃ©nÃ¨re une visualisation DOT** â€” Format Graphviz pour visualiser le rÃ©seau social

**EntrÃ©e :**
- `input_json` : ChaÃ®ne JSON contenant les donnÃ©es OSINT multi-sources

**Sortie :**
- ChaÃ®ne JSON structurÃ©e avec l'analyse du graphe social et le format DOT

#### 1.2.2 Version AcadÃ©mique

**Objectif pÃ©dagogique :** ImplÃ©menter un analyseur de donnÃ©es OSINT provenant de sources sociales (LinkedIn, emails, GitHub) pour construire un graphe de relations et identifier les patterns de fuite d'informations.

**Description technique :**
L'exercice consiste Ã  parser des donnÃ©es JSON simulant les rÃ©sultats de collecte OSINT sur des rÃ©seaux sociaux et plateformes de dÃ©veloppement. L'algorithme doit :
- Normaliser les donnÃ©es hÃ©tÃ©rogÃ¨nes (diffÃ©rents formats par source)
- Construire un graphe orientÃ© de relations (struct Node/Edge)
- Calculer des mÃ©triques de centralitÃ© (degree, betweenness approximÃ©)
- DÃ©tecter des patterns sensibles dans le code source (regex pour secrets)
- GÃ©nÃ©rer une reprÃ©sentation DOT valide du graphe

**Contraintes :**
- La dÃ©tection d'entitÃ©s identiques entre sources doit Ãªtre robuste (matching email/username)
- Le calcul de centralitÃ© doit Ãªtre efficace pour des graphes jusqu'Ã  1000 nÅ“uds
- La dÃ©tection de secrets doit couvrir au minimum 5 patterns distincts

**Exemples :**

| Input Type | Contenu | Output attendu |
|------------|---------|----------------|
| LinkedIn profile | {"name": "John Doe", "company": "Acme Corp"} | Node avec attributs + edges vers company |
| TheHarvester email | "john.doe@acme.com" | CorrÃ©lation avec profil LinkedIn existant |
| GitHub repo | {"owner": "jdoe", "contributors": ["alice"]} | Edges de collaboration |
| Fichier avec secret | "API_KEY=sk_live_xyz123" | Alerte leak avec criticitÃ© |

### 1.3 Prototype

```rust
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRUCTURES D'ENTRÃ‰E
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[derive(Debug, Deserialize)]
pub struct SocialInput {
    pub linkedin_profiles: Option<Vec<LinkedInProfile>>,
    pub harvester_emails: Option<Vec<HarvesterEmail>>,
    pub github_data: Option<GithubData>,
    pub options: Option<AnalysisOptions>,
}

#[derive(Debug, Deserialize)]
pub struct LinkedInProfile {
    pub name: String,
    pub headline: Option<String>,
    pub company: Option<String>,
    pub location: Option<String>,
    pub connections: Option<Vec<String>>,  // Names of connections
    pub skills: Option<Vec<String>>,
    pub email: Option<String>,
    pub profile_url: Option<String>,
}

#[derive(Debug, Deserialize)]
pub struct HarvesterEmail {
    pub email: String,
    pub source: Option<String>,  // Where it was found
    pub domain: String,
    pub confidence: Option<f64>,
}

#[derive(Debug, Deserialize)]
pub struct GithubData {
    pub users: Option<Vec<GithubUser>>,
    pub repositories: Option<Vec<GithubRepo>>,
}

#[derive(Debug, Deserialize)]
pub struct GithubUser {
    pub username: String,
    pub name: Option<String>,
    pub email: Option<String>,
    pub bio: Option<String>,
    pub company: Option<String>,
    pub repos: Option<Vec<String>>,
}

#[derive(Debug, Deserialize)]
pub struct GithubRepo {
    pub name: String,
    pub owner: String,
    pub contributors: Option<Vec<String>>,
    pub commits: Option<Vec<GithubCommit>>,
    pub files: Option<Vec<RepoFile>>,
}

#[derive(Debug, Deserialize)]
pub struct GithubCommit {
    pub sha: String,
    pub author_name: String,
    pub author_email: String,
    pub message: String,
    pub timestamp: String,
}

#[derive(Debug, Deserialize)]
pub struct RepoFile {
    pub path: String,
    pub content: Option<String>,  // For secret detection
}

#[derive(Debug, Deserialize)]
pub struct AnalysisOptions {
    pub detect_secrets: Option<bool>,
    pub calculate_centrality: Option<bool>,
    pub correlation_threshold: Option<f64>,
    pub generate_dot: Option<bool>,
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRUCTURES DE SORTIE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[derive(Debug, Serialize)]
pub struct SocialOutput {
    pub graph: SocialGraph,
    pub analysis: GraphAnalysis,
    pub leaks: Vec<SecretLeak>,
    pub correlations: Vec<IdentityCorrelation>,
    pub dot_graph: Option<String>,
    pub metadata: AnalysisMetadata,
}

#[derive(Debug, Serialize)]
pub struct SocialGraph {
    pub nodes: Vec<GraphNode>,
    pub edges: Vec<GraphEdge>,
    pub clusters: Vec<Cluster>,
}

#[derive(Debug, Serialize)]
pub struct GraphNode {
    pub id: String,
    pub node_type: NodeType,
    pub label: String,
    pub attributes: HashMap<String, String>,
    pub sources: Vec<String>,  // Where this node was found
}

#[derive(Debug, Serialize)]
pub enum NodeType {
    Person,
    Organization,
    Repository,
    Domain,
    Email,
}

#[derive(Debug, Serialize)]
pub struct GraphEdge {
    pub id: String,
    pub source: String,
    pub target: String,
    pub edge_type: EdgeType,
    pub weight: f64,
    pub attributes: HashMap<String, String>,
}

#[derive(Debug, Serialize)]
pub enum EdgeType {
    WorksAt,           // Person -> Organization
    Colleague,         // Person <-> Person (same company)
    Connection,        // Person <-> Person (LinkedIn connection)
    Contributor,       // Person -> Repository
    Collaborator,      // Person <-> Person (same repo)
    OwnsEmail,         // Person -> Email
    EmailDomain,       // Email -> Domain
    CommitTo,          // Person -> Repository (with commits)
}

#[derive(Debug, Serialize)]
pub struct Cluster {
    pub id: String,
    pub name: String,
    pub members: Vec<String>,
    pub cluster_type: ClusterType,
}

#[derive(Debug, Serialize)]
pub enum ClusterType {
    Company,
    Project,
    EmailDomain,
    Inferred,  // Detected via graph analysis
}

#[derive(Debug, Serialize)]
pub struct GraphAnalysis {
    pub total_nodes: usize,
    pub total_edges: usize,
    pub density: f64,
    pub key_persons: Vec<KeyPerson>,
    pub isolated_nodes: Vec<String>,
    pub connected_components: usize,
}

#[derive(Debug, Serialize)]
pub struct KeyPerson {
    pub node_id: String,
    pub name: String,
    pub degree_centrality: f64,
    pub betweenness_centrality: Option<f64>,
    pub influence_score: f64,
    pub roles: Vec<String>,  // "connector", "hub", "bridge"
}

#[derive(Debug, Serialize)]
pub struct SecretLeak {
    pub leak_id: String,
    pub repository: String,
    pub file_path: String,
    pub secret_type: SecretType,
    pub severity: Severity,
    pub pattern_matched: String,
    pub context: String,  // Surrounding code
    pub committed_by: Option<String>,
}

#[derive(Debug, Serialize)]
pub enum SecretType {
    AwsKey,
    ApiKey,
    PrivateKey,
    Password,
    DatabaseUrl,
    OAuthToken,
    JwtSecret,
    SlackWebhook,
    GenericSecret,
}

#[derive(Debug, Serialize)]
pub enum Severity {
    Critical,
    High,
    Medium,
    Low,
    Info,
}

#[derive(Debug, Serialize)]
pub struct IdentityCorrelation {
    pub correlation_id: String,
    pub entities: Vec<CorrelatedEntity>,
    pub confidence: f64,
    pub evidence: Vec<String>,
}

#[derive(Debug, Serialize)]
pub struct CorrelatedEntity {
    pub source: String,
    pub identifier: String,
    pub entity_type: String,
}

#[derive(Debug, Serialize)]
pub struct AnalysisMetadata {
    pub sources_processed: Vec<String>,
    pub processing_warnings: Vec<String>,
    pub analysis_timestamp: String,
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FONCTION PRINCIPALE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// Point d'entrÃ©e principal - Analyse OSINT sociale et construction de graphe
pub fn social_graph(input_json: &str) -> String {
    todo!("ImplÃ©menter l'analyse du graphe social")
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FONCTIONS AUXILIAIRES Ã€ IMPLÃ‰MENTER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// Parse et normalise les profils LinkedIn
fn parse_linkedin_profiles(profiles: &[LinkedInProfile]) -> Vec<GraphNode> {
    todo!()
}

/// Parse les emails TheHarvester et crÃ©e des nÅ“uds
fn parse_harvester_emails(emails: &[HarvesterEmail]) -> Vec<GraphNode> {
    todo!()
}

/// Parse les donnÃ©es GitHub (users, repos, commits)
fn parse_github_data(data: &GithubData) -> (Vec<GraphNode>, Vec<GraphEdge>) {
    todo!()
}

/// CorrÃ¨le les identitÃ©s entre les sources
fn correlate_identities(nodes: &[GraphNode]) -> Vec<IdentityCorrelation> {
    todo!()
}

/// Construit les edges du graphe
fn build_edges(nodes: &[GraphNode], correlations: &[IdentityCorrelation]) -> Vec<GraphEdge> {
    todo!()
}

/// DÃ©tecte les clusters dans le graphe
fn detect_clusters(nodes: &[GraphNode], edges: &[GraphEdge]) -> Vec<Cluster> {
    todo!()
}

/// Calcule la centralitÃ© des nÅ“uds
fn calculate_centrality(nodes: &[GraphNode], edges: &[GraphEdge]) -> Vec<KeyPerson> {
    todo!()
}

/// DÃ©tecte les secrets dans les fichiers des repos
fn detect_secrets(repos: &[GithubRepo]) -> Vec<SecretLeak> {
    todo!()
}

/// GÃ©nÃ¨re la reprÃ©sentation DOT du graphe
fn generate_dot(graph: &SocialGraph) -> String {
    todo!()
}
```

---

## ğŸ’¡ SECTION 2 : LE SAVIEZ-VOUS ?

### TheHarvester et la Collecte d'Emails

TheHarvester est un outil OSINT crÃ©Ã© par Christian Martorella qui collecte des emails, sous-domaines et noms Ã  partir de sources publiques (Google, Bing, LinkedIn, Shodan). Une seule requÃªte peut rÃ©vÃ©ler des dizaines d'emails d'entreprise qui seront ensuite utilisÃ©s pour du spear phishing ou de la compromission de comptes.

### Le Scandale Cambridge Analytica (2018)

Cambridge Analytica a utilisÃ© l'analyse de graphes sociaux Facebook pour profiler 87 millions d'utilisateurs. En analysant les "likes" et connections, ils ont construit des profils psychographiques pour influencer les Ã©lections amÃ©ricaines. Cela a dÃ©montrÃ© le pouvoir (et les dangers) de l'analyse des graphes sociaux.

### La CentralitÃ© de Betweenness et les "Brokers"

En analyse de rÃ©seau, les personnes avec haute centralitÃ© de betweenness sont des "brokers" â€” ils connectent des groupes qui sinon seraient isolÃ©s. Dans le renseignement, identifier ces brokers permet de comprendre comment l'information circule et qui contrÃ´le les flux.

### GitHub et les Secrets ExposÃ©s

En 2019, une Ã©tude a rÃ©vÃ©lÃ© que plus de 100,000 dÃ©pÃ´ts GitHub contenaient des secrets exposÃ©s (clÃ©s API, mots de passe). Des outils comme TruffleHog et GitLeaks scannent automatiquement les repos pour ces patterns. Un commit peut Ãªtre supprimÃ© mais reste dans l'historique Git.

---

### 2.5 DANS LA VRAIE VIE

| MÃ©tier | Utilisation | Cas d'usage |
|--------|-------------|-------------|
| **Threat Intelligence Analyst** | Construit des graphes de relations entre acteurs malveillants | Attribution d'attaques via overlaps d'infrastructure |
| **Red Team Operator** | Phase de reconnaissance passive sur une cible | Identifie les employÃ©s clÃ©s pour spear phishing |
| **Investigative Journalist** | EnquÃªte sur les rÃ©seaux de pouvoir | Panama Papers : rÃ©vÃ©lation de sociÃ©tÃ©s offshore liÃ©es |
| **HR/Background Check** | VÃ©rification des candidats | Validation des rÃ©fÃ©rences et historique professionnel |
| **Due Diligence** | Analyse avant acquisition/investissement | Cartographie des relations entre dirigeants et concurrents |

---

## ğŸ–¥ï¸ SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ ls
social_graph.rs  main.rs  test_input.json

$ cat test_input.json
{
  "linkedin_profiles": [
    {
      "name": "Alice Chen",
      "company": "TechCorp Inc",
      "email": "a.chen@techcorp.io",
      "connections": ["Bob Smith", "Carol Davis"]
    },
    {
      "name": "Bob Smith",
      "company": "TechCorp Inc",
      "headline": "Senior Developer"
    }
  ],
  "harvester_emails": [
    {"email": "alice@techcorp.io", "domain": "techcorp.io"},
    {"email": "ceo@techcorp.io", "domain": "techcorp.io"}
  ],
  "github_data": {
    "users": [
      {"username": "achen", "email": "a.chen@techcorp.io", "name": "Alice Chen"}
    ],
    "repositories": [
      {
        "name": "internal-api",
        "owner": "techcorp",
        "contributors": ["achen", "bsmith"],
        "files": [
          {"path": "config.py", "content": "API_KEY = 'sk_live_abc123xyz'"}
        ]
      }
    ]
  },
  "options": {
    "detect_secrets": true,
    "calculate_centrality": true,
    "generate_dot": true
  }
}

$ cargo build --release

$ ./target/release/social_graph < test_input.json
{
  "graph": {
    "nodes": [
      {"id": "person_1", "node_type": "Person", "label": "Alice Chen", ...},
      {"id": "person_2", "node_type": "Person", "label": "Bob Smith", ...},
      {"id": "org_1", "node_type": "Organization", "label": "TechCorp Inc", ...}
    ],
    "edges": [
      {"source": "person_1", "target": "org_1", "edge_type": "WorksAt", ...},
      {"source": "person_1", "target": "person_2", "edge_type": "Colleague", ...}
    ]
  },
  "analysis": {
    "total_nodes": 5,
    "total_edges": 7,
    "key_persons": [
      {"node_id": "person_1", "name": "Alice Chen", "influence_score": 0.85}
    ]
  },
  "leaks": [
    {
      "repository": "internal-api",
      "file_path": "config.py",
      "secret_type": "ApiKey",
      "severity": "High"
    }
  ],
  "dot_graph": "digraph social_graph {\n  person_1 [label=\"Alice Chen\"];\n  ...}"
}
```

---

## âš¡ SECTION 3.1 : BONUS STANDARD (OPTIONNEL)

**DifficultÃ© Bonus :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜† (8/10)

**RÃ©compense :**
XP Ã—2

**Time Complexity attendue :**
O(VÂ²) pour betweenness approximÃ©

**Space Complexity attendue :**
O(V+E)

**Domaines Bonus :**
`Struct, Probas`

### 3.1.1 Consigne Bonus

**ğŸ® "The Machine" - DÃ©tection d'Anomalies Comportementales**

Harold Finch t'a laissÃ© une tÃ¢che supplÃ©mentaire. The Machine a dÃ©tectÃ© des patterns inhabituels : certaines personnes semblent avoir des "identitÃ©s multiples" â€” plusieurs profils qui ne correspondent pas parfaitement mais qui pourraient Ãªtre la mÃªme personne utilisant des pseudonymes.

**Ta mission bonus :**

ImplÃ©menter un systÃ¨me de **dÃ©duplication fuzzy** qui :

1. **Calcule la similaritÃ©** entre entitÃ©s (Jaro-Winkler sur noms, Levenshtein sur emails)
2. **DÃ©tecte les identitÃ©s potentiellement dupliquÃ©es** avec un score de confiance
3. **Propose des merges** avec justification
4. **Calcule la vraie centralitÃ© de betweenness** (algorithme de Brandes simplifiÃ©)
5. **GÃ©nÃ¨re un rapport de sÃ©curitÃ©** sur les expositions inter-plateformes

**Contraintes :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  similarity_threshold â‰¥ 0.8            â”‚
â”‚  max_identity_candidates â‰¤ 10          â”‚
â”‚  betweenness calculation: Brandes algo â”‚
â”‚  temps_execution < 5s pour 500 nodes   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.1.2 Prototype Bonus

```rust
/// Calcule la similaritÃ© entre deux chaÃ®nes (Jaro-Winkler)
fn jaro_winkler_similarity(s1: &str, s2: &str) -> f64 {
    todo!()
}

/// DÃ©tecte les identitÃ©s potentiellement dupliquÃ©es
fn detect_duplicate_identities(
    nodes: &[GraphNode],
    threshold: f64,
) -> Vec<DuplicateCandidate> {
    todo!()
}

#[derive(Debug, Serialize)]
pub struct DuplicateCandidate {
    pub primary_id: String,
    pub candidate_id: String,
    pub similarity_score: f64,
    pub matching_attributes: Vec<String>,
    pub merge_recommendation: bool,
}

/// Calcule la centralitÃ© de betweenness (Brandes algorithm)
fn calculate_betweenness_centrality(
    nodes: &[GraphNode],
    edges: &[GraphEdge],
) -> HashMap<String, f64> {
    todo!()
}

/// GÃ©nÃ¨re un rapport de sÃ©curitÃ© cross-platform
fn generate_security_report(
    correlations: &[IdentityCorrelation],
    leaks: &[SecretLeak],
) -> SecurityReport {
    todo!()
}

#[derive(Debug, Serialize)]
pub struct SecurityReport {
    pub exposure_score: f64,
    pub critical_findings: Vec<String>,
    pub recommendations: Vec<String>,
    pub affected_identities: Vec<String>,
}
```

### 3.1.3 Ce qui change par rapport Ã  l'exercice de base

| Aspect | Base | Bonus |
|--------|------|-------|
| CorrÃ©lation | Exact match email/name | Fuzzy matching (Jaro-Winkler) |
| CentralitÃ© | Degree centrality simple | Betweenness (Brandes algorithm) |
| Output | Graphe + analyse | + DÃ©duplication + Security Report |
| ComplexitÃ© | O(V+E) | O(VÂ² + VE) |

---

## âœ…âŒ SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette (tableau des tests)

| # | Test | Input | Expected | Points | Trap |
|---|------|-------|----------|--------|------|
| 1 | Empty input | `{}` | Graph vide, pas d'erreur | 5 | Null safety |
| 2 | LinkedIn only | 3 profiles, 2 same company | 5 nodes, WorksAt + Colleague edges | 10 | - |
| 3 | Email correlation | LinkedIn + matching email | IdentityCorrelation with high confidence | 10 | Case sensitivity |
| 4 | GitHub contributors | Repo with 3 contributors | Collaborator edges between all | 10 | - |
| 5 | Secret detection - AWS | `AKIA...` pattern | SecretLeak type AwsKey | 10 | Partial match |
| 6 | Secret detection - multi | 5 different secret types | 5 leaks with correct types | 15 | - |
| 7 | DOT generation | Small graph | Valid DOT syntax | 10 | Escaping quotes |
| 8 | Centrality calculation | Star topology (1 hub) | Hub has highest centrality | 10 | Division by zero |
| 9 | Large input | 100 profiles, 50 repos | Completes < 2s | 5 | Performance |
| 10 | Cross-source identity | Same person 3 sources | Single merged identity | 15 | Transitivity |

### 4.2 main.rs de test

```rust
use social_graph::*;

fn main() {
    // Test 1: Empty input
    let empty = r#"{}"#;
    let result = social_graph(empty);
    let output: SocialOutput = serde_json::from_str(&result).unwrap();
    assert_eq!(output.graph.nodes.len(), 0);
    println!("Test 1 (empty): OK");

    // Test 2: LinkedIn profiles
    let linkedin = r#"{
        "linkedin_profiles": [
            {"name": "Alice Chen", "company": "TechCorp"},
            {"name": "Bob Smith", "company": "TechCorp"},
            {"name": "Carol Davis", "company": "OtherCo"}
        ]
    }"#;
    let result = social_graph(linkedin);
    let output: SocialOutput = serde_json::from_str(&result).unwrap();
    assert!(output.graph.nodes.len() >= 5); // 3 persons + 2 companies
    assert!(output.graph.edges.iter().any(|e| matches!(e.edge_type, EdgeType::Colleague)));
    println!("Test 2 (LinkedIn): OK");

    // Test 3: Secret detection
    let secrets = r#"{
        "github_data": {
            "repositories": [{
                "name": "test-repo",
                "owner": "testuser",
                "files": [
                    {"path": "config.py", "content": "AWS_KEY = 'AKIAIOSFODNN7EXAMPLE'"},
                    {"path": ".env", "content": "DATABASE_URL=postgres://user:pass@host/db"}
                ]
            }]
        },
        "options": {"detect_secrets": true}
    }"#;
    let result = social_graph(secrets);
    let output: SocialOutput = serde_json::from_str(&result).unwrap();
    assert!(output.leaks.len() >= 2);
    assert!(output.leaks.iter().any(|l| matches!(l.secret_type, SecretType::AwsKey)));
    println!("Test 3 (Secrets): OK");

    // Test 4: DOT generation
    let simple = r#"{
        "linkedin_profiles": [{"name": "Test User", "company": "TestCo"}],
        "options": {"generate_dot": true}
    }"#;
    let result = social_graph(simple);
    let output: SocialOutput = serde_json::from_str(&result).unwrap();
    assert!(output.dot_graph.is_some());
    let dot = output.dot_graph.unwrap();
    assert!(dot.contains("digraph") || dot.contains("graph"));
    println!("Test 4 (DOT): OK");

    println!("\nâœ“ Tous les tests passent!");
}
```

### 4.3 Solution de rÃ©fÃ©rence

```rust
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use regex::Regex;

// [... Structures dÃ©jÃ  dÃ©finies dans le prototype ...]

pub fn social_graph(input_json: &str) -> String {
    // Parse input
    let input: SocialInput = match serde_json::from_str(input_json) {
        Ok(i) => i,
        Err(_) => return serde_json::to_string(&create_empty_output()).unwrap(),
    };

    let options = input.options.unwrap_or(AnalysisOptions {
        detect_secrets: Some(true),
        calculate_centrality: Some(true),
        correlation_threshold: Some(0.8),
        generate_dot: Some(true),
    });

    // Phase 1: Parse all sources into nodes
    let mut all_nodes: Vec<GraphNode> = Vec::new();
    let mut all_edges: Vec<GraphEdge> = Vec::new();
    let mut sources_processed: Vec<String> = Vec::new();

    // Parse LinkedIn profiles
    if let Some(profiles) = &input.linkedin_profiles {
        let linkedin_nodes = parse_linkedin_profiles(profiles);
        let linkedin_edges = build_linkedin_edges(profiles, &linkedin_nodes);
        all_nodes.extend(linkedin_nodes);
        all_edges.extend(linkedin_edges);
        sources_processed.push("linkedin".to_string());
    }

    // Parse TheHarvester emails
    if let Some(emails) = &input.harvester_emails {
        let (email_nodes, email_edges) = parse_harvester_emails(emails);
        all_nodes.extend(email_nodes);
        all_edges.extend(email_edges);
        sources_processed.push("theharvester".to_string());
    }

    // Parse GitHub data
    if let Some(github) = &input.github_data {
        let (github_nodes, github_edges) = parse_github_data(github);
        all_nodes.extend(github_nodes);
        all_edges.extend(github_edges);
        sources_processed.push("github".to_string());
    }

    // Phase 2: Correlate identities across sources
    let correlations = correlate_identities(&all_nodes);

    // Merge correlated nodes and update edges
    let (merged_nodes, merged_edges) = merge_correlated_entities(
        all_nodes,
        all_edges,
        &correlations,
    );

    // Phase 3: Detect clusters
    let clusters = detect_clusters(&merged_nodes, &merged_edges);

    // Phase 4: Calculate centrality
    let key_persons = if options.calculate_centrality.unwrap_or(true) {
        calculate_centrality(&merged_nodes, &merged_edges)
    } else {
        Vec::new()
    };

    // Phase 5: Detect secrets
    let leaks = if options.detect_secrets.unwrap_or(true) {
        if let Some(github) = &input.github_data {
            if let Some(repos) = &github.repositories {
                detect_secrets(repos)
            } else {
                Vec::new()
            }
        } else {
            Vec::new()
        }
    } else {
        Vec::new()
    };

    // Phase 6: Build analysis
    let analysis = build_analysis(&merged_nodes, &merged_edges, key_persons);

    // Phase 7: Generate DOT if requested
    let graph = SocialGraph {
        nodes: merged_nodes,
        edges: merged_edges,
        clusters,
    };

    let dot_graph = if options.generate_dot.unwrap_or(true) {
        Some(generate_dot(&graph))
    } else {
        None
    };

    // Build output
    let output = SocialOutput {
        graph,
        analysis,
        leaks,
        correlations,
        dot_graph,
        metadata: AnalysisMetadata {
            sources_processed,
            processing_warnings: Vec::new(),
            analysis_timestamp: chrono_placeholder(),
        },
    };

    serde_json::to_string_pretty(&output).unwrap_or_else(|_| "{}".to_string())
}

fn parse_linkedin_profiles(profiles: &[LinkedInProfile]) -> Vec<GraphNode> {
    let mut nodes = Vec::new();
    let mut companies: HashSet<String> = HashSet::new();
    let mut person_id = 1;

    for profile in profiles {
        // Create person node
        let mut attrs = HashMap::new();
        if let Some(headline) = &profile.headline {
            attrs.insert("headline".to_string(), headline.clone());
        }
        if let Some(location) = &profile.location {
            attrs.insert("location".to_string(), location.clone());
        }
        if let Some(email) = &profile.email {
            attrs.insert("email".to_string(), email.to_lowercase());
        }

        nodes.push(GraphNode {
            id: format!("person_{}", person_id),
            node_type: NodeType::Person,
            label: profile.name.clone(),
            attributes: attrs,
            sources: vec!["linkedin".to_string()],
        });
        person_id += 1;

        // Track companies
        if let Some(company) = &profile.company {
            companies.insert(company.clone());
        }
    }

    // Create organization nodes
    let mut org_id = 1;
    for company in companies {
        nodes.push(GraphNode {
            id: format!("org_{}", org_id),
            node_type: NodeType::Organization,
            label: company,
            attributes: HashMap::new(),
            sources: vec!["linkedin".to_string()],
        });
        org_id += 1;
    }

    nodes
}

fn build_linkedin_edges(profiles: &[LinkedInProfile], nodes: &[GraphNode]) -> Vec<GraphEdge> {
    let mut edges = Vec::new();
    let mut edge_id = 1;

    // Build lookup maps
    let name_to_id: HashMap<_, _> = nodes.iter()
        .filter(|n| matches!(n.node_type, NodeType::Person))
        .map(|n| (n.label.to_lowercase(), n.id.clone()))
        .collect();

    let company_to_id: HashMap<_, _> = nodes.iter()
        .filter(|n| matches!(n.node_type, NodeType::Organization))
        .map(|n| (n.label.clone(), n.id.clone()))
        .collect();

    // Track people by company for colleague edges
    let mut company_employees: HashMap<String, Vec<String>> = HashMap::new();

    for profile in profiles {
        let person_id = name_to_id.get(&profile.name.to_lowercase());

        if let (Some(pid), Some(company)) = (person_id, &profile.company) {
            // WorksAt edge
            if let Some(org_id) = company_to_id.get(company) {
                edges.push(GraphEdge {
                    id: format!("edge_{}", edge_id),
                    source: pid.clone(),
                    target: org_id.clone(),
                    edge_type: EdgeType::WorksAt,
                    weight: 1.0,
                    attributes: HashMap::new(),
                });
                edge_id += 1;
            }

            company_employees
                .entry(company.clone())
                .or_default()
                .push(pid.clone());
        }

        // Connection edges
        if let (Some(pid), Some(connections)) = (person_id, &profile.connections) {
            for conn_name in connections {
                if let Some(conn_id) = name_to_id.get(&conn_name.to_lowercase()) {
                    edges.push(GraphEdge {
                        id: format!("edge_{}", edge_id),
                        source: pid.clone(),
                        target: conn_id.clone(),
                        edge_type: EdgeType::Connection,
                        weight: 1.0,
                        attributes: HashMap::new(),
                    });
                    edge_id += 1;
                }
            }
        }
    }

    // Add Colleague edges for people in same company
    for employees in company_employees.values() {
        for i in 0..employees.len() {
            for j in (i + 1)..employees.len() {
                edges.push(GraphEdge {
                    id: format!("edge_{}", edge_id),
                    source: employees[i].clone(),
                    target: employees[j].clone(),
                    edge_type: EdgeType::Colleague,
                    weight: 0.8,
                    attributes: HashMap::new(),
                });
                edge_id += 1;
            }
        }
    }

    edges
}

fn parse_harvester_emails(emails: &[HarvesterEmail]) -> (Vec<GraphNode>, Vec<GraphEdge>) {
    let mut nodes = Vec::new();
    let mut edges = Vec::new();
    let mut domains: HashSet<String> = HashSet::new();
    let mut email_id = 1;
    let mut edge_id = 1;

    for email in emails {
        nodes.push(GraphNode {
            id: format!("email_{}", email_id),
            node_type: NodeType::Email,
            label: email.email.to_lowercase(),
            attributes: HashMap::from([
                ("confidence".to_string(),
                 email.confidence.unwrap_or(1.0).to_string()),
            ]),
            sources: vec![email.source.clone().unwrap_or("theharvester".to_string())],
        });
        domains.insert(email.domain.clone());
        email_id += 1;
    }

    // Create domain nodes
    let mut domain_id = 1;
    let domain_ids: HashMap<_, _> = domains.iter().map(|d| {
        let id = format!("domain_{}", domain_id);
        domain_id += 1;
        nodes.push(GraphNode {
            id: id.clone(),
            node_type: NodeType::Domain,
            label: d.clone(),
            attributes: HashMap::new(),
            sources: vec!["theharvester".to_string()],
        });
        (d.clone(), id)
    }).collect();

    // Create EmailDomain edges
    for (i, email) in emails.iter().enumerate() {
        if let Some(domain_id) = domain_ids.get(&email.domain) {
            edges.push(GraphEdge {
                id: format!("edge_{}", edge_id),
                source: format!("email_{}", i + 1),
                target: domain_id.clone(),
                edge_type: EdgeType::EmailDomain,
                weight: 1.0,
                attributes: HashMap::new(),
            });
            edge_id += 1;
        }
    }

    (nodes, edges)
}

fn parse_github_data(data: &GithubData) -> (Vec<GraphNode>, Vec<GraphEdge>) {
    let mut nodes = Vec::new();
    let mut edges = Vec::new();
    let mut user_id = 1;
    let mut repo_id = 1;
    let mut edge_id = 1;

    let mut username_to_id: HashMap<String, String> = HashMap::new();

    // Parse users
    if let Some(users) = &data.users {
        for user in users {
            let node_id = format!("ghuser_{}", user_id);
            username_to_id.insert(user.username.clone(), node_id.clone());

            let mut attrs = HashMap::new();
            if let Some(email) = &user.email {
                attrs.insert("email".to_string(), email.to_lowercase());
            }
            if let Some(bio) = &user.bio {
                attrs.insert("bio".to_string(), bio.clone());
            }
            if let Some(company) = &user.company {
                attrs.insert("company".to_string(), company.clone());
            }

            nodes.push(GraphNode {
                id: node_id,
                node_type: NodeType::Person,
                label: user.name.clone().unwrap_or(user.username.clone()),
                attributes: attrs,
                sources: vec!["github".to_string()],
            });
            user_id += 1;
        }
    }

    // Parse repositories
    if let Some(repos) = &data.repositories {
        for repo in repos {
            let repo_node_id = format!("repo_{}", repo_id);

            nodes.push(GraphNode {
                id: repo_node_id.clone(),
                node_type: NodeType::Repository,
                label: format!("{}/{}", repo.owner, repo.name),
                attributes: HashMap::new(),
                sources: vec!["github".to_string()],
            });

            // Create owner node if not exists
            if !username_to_id.contains_key(&repo.owner) {
                let owner_id = format!("ghuser_{}", user_id);
                username_to_id.insert(repo.owner.clone(), owner_id.clone());
                nodes.push(GraphNode {
                    id: owner_id.clone(),
                    node_type: NodeType::Person,
                    label: repo.owner.clone(),
                    attributes: HashMap::new(),
                    sources: vec!["github".to_string()],
                });
                user_id += 1;
            }

            // Contributor edges
            if let Some(contributors) = &repo.contributors {
                let contributor_ids: Vec<String> = contributors.iter().filter_map(|c| {
                    if !username_to_id.contains_key(c) {
                        let cid = format!("ghuser_{}", user_id);
                        username_to_id.insert(c.clone(), cid.clone());
                        nodes.push(GraphNode {
                            id: cid.clone(),
                            node_type: NodeType::Person,
                            label: c.clone(),
                            attributes: HashMap::new(),
                            sources: vec!["github".to_string()],
                        });
                        // Can't modify user_id here in functional style, handle differently
                    }
                    username_to_id.get(c).cloned()
                }).collect();

                for cid in &contributor_ids {
                    edges.push(GraphEdge {
                        id: format!("edge_{}", edge_id),
                        source: cid.clone(),
                        target: repo_node_id.clone(),
                        edge_type: EdgeType::Contributor,
                        weight: 1.0,
                        attributes: HashMap::new(),
                    });
                    edge_id += 1;
                }

                // Collaborator edges between contributors
                for i in 0..contributor_ids.len() {
                    for j in (i + 1)..contributor_ids.len() {
                        edges.push(GraphEdge {
                            id: format!("edge_{}", edge_id),
                            source: contributor_ids[i].clone(),
                            target: contributor_ids[j].clone(),
                            edge_type: EdgeType::Collaborator,
                            weight: 0.5,
                            attributes: HashMap::from([
                                ("via_repo".to_string(), repo.name.clone()),
                            ]),
                        });
                        edge_id += 1;
                    }
                }
            }

            // Process commits
            if let Some(commits) = &repo.commits {
                for commit in commits {
                    // Could add CommitTo edges here if needed
                }
            }

            repo_id += 1;
        }
    }

    (nodes, edges)
}

fn correlate_identities(nodes: &[GraphNode]) -> Vec<IdentityCorrelation> {
    let mut correlations = Vec::new();
    let mut correlation_id = 1;

    // Group nodes by email
    let mut email_groups: HashMap<String, Vec<&GraphNode>> = HashMap::new();
    for node in nodes {
        if let Some(email) = node.attributes.get("email") {
            let normalized = email.to_lowercase().trim().to_string();
            email_groups.entry(normalized).or_default().push(node);
        }
        // Also check if the node itself is an Email type
        if matches!(node.node_type, NodeType::Email) {
            let normalized = node.label.to_lowercase();
            email_groups.entry(normalized).or_default().push(node);
        }
    }

    // Create correlations for email matches
    for (email, matched_nodes) in email_groups {
        if matched_nodes.len() > 1 {
            let entities: Vec<CorrelatedEntity> = matched_nodes.iter().map(|n| {
                CorrelatedEntity {
                    source: n.sources.first().cloned().unwrap_or_default(),
                    identifier: n.id.clone(),
                    entity_type: format!("{:?}", n.node_type),
                }
            }).collect();

            correlations.push(IdentityCorrelation {
                correlation_id: format!("corr_{}", correlation_id),
                entities,
                confidence: 0.95,
                evidence: vec![format!("Matching email: {}", email)],
            });
            correlation_id += 1;
        }
    }

    // Name matching (lower confidence)
    let person_nodes: Vec<_> = nodes.iter()
        .filter(|n| matches!(n.node_type, NodeType::Person))
        .collect();

    let mut name_groups: HashMap<String, Vec<&GraphNode>> = HashMap::new();
    for node in &person_nodes {
        let normalized_name = normalize_name(&node.label);
        name_groups.entry(normalized_name).or_default().push(node);
    }

    for (name, matched_nodes) in name_groups {
        if matched_nodes.len() > 1 {
            // Check if already correlated by email
            let already_correlated = correlations.iter().any(|c| {
                matched_nodes.iter().all(|n| {
                    c.entities.iter().any(|e| e.identifier == n.id)
                })
            });

            if !already_correlated {
                let entities: Vec<CorrelatedEntity> = matched_nodes.iter().map(|n| {
                    CorrelatedEntity {
                        source: n.sources.first().cloned().unwrap_or_default(),
                        identifier: n.id.clone(),
                        entity_type: "Person".to_string(),
                    }
                }).collect();

                correlations.push(IdentityCorrelation {
                    correlation_id: format!("corr_{}", correlation_id),
                    entities,
                    confidence: 0.75,
                    evidence: vec![format!("Matching name: {}", name)],
                });
                correlation_id += 1;
            }
        }
    }

    correlations
}

fn normalize_name(name: &str) -> String {
    name.to_lowercase()
        .split_whitespace()
        .collect::<Vec<_>>()
        .join(" ")
}

fn merge_correlated_entities(
    mut nodes: Vec<GraphNode>,
    mut edges: Vec<GraphEdge>,
    correlations: &[IdentityCorrelation],
) -> (Vec<GraphNode>, Vec<GraphEdge>) {
    // Create mapping from old IDs to merged IDs
    let mut id_mapping: HashMap<String, String> = HashMap::new();

    for corr in correlations {
        if corr.entities.len() >= 2 && corr.confidence > 0.7 {
            // Use first entity as primary
            let primary = &corr.entities[0];
            for entity in &corr.entities[1..] {
                id_mapping.insert(entity.identifier.clone(), primary.identifier.clone());
            }
        }
    }

    // Merge node attributes
    for corr in correlations {
        if corr.entities.len() >= 2 && corr.confidence > 0.7 {
            let primary_id = &corr.entities[0].identifier;

            // Find primary node and merge attributes from others
            if let Some(primary) = nodes.iter_mut().find(|n| &n.id == primary_id) {
                for entity in &corr.entities[1..] {
                    if let Some(secondary) = nodes.iter().find(|n| n.id == entity.identifier) {
                        for (k, v) in &secondary.attributes {
                            primary.attributes.entry(k.clone()).or_insert(v.clone());
                        }
                        for s in &secondary.sources {
                            if !primary.sources.contains(s) {
                                primary.sources.push(s.clone());
                            }
                        }
                    }
                }
            }
        }
    }

    // Remove merged nodes
    nodes.retain(|n| !id_mapping.contains_key(&n.id));

    // Update edge references
    for edge in &mut edges {
        if let Some(new_src) = id_mapping.get(&edge.source) {
            edge.source = new_src.clone();
        }
        if let Some(new_tgt) = id_mapping.get(&edge.target) {
            edge.target = new_tgt.clone();
        }
    }

    // Remove self-loops and duplicates
    edges.retain(|e| e.source != e.target);
    let mut seen: HashSet<(String, String, String)> = HashSet::new();
    edges.retain(|e| {
        let key = (e.source.clone(), e.target.clone(), format!("{:?}", e.edge_type));
        seen.insert(key)
    });

    (nodes, edges)
}

fn detect_clusters(nodes: &[GraphNode], edges: &[GraphEdge]) -> Vec<Cluster> {
    let mut clusters = Vec::new();
    let mut cluster_id = 1;

    // Company clusters
    let mut company_members: HashMap<String, Vec<String>> = HashMap::new();
    for node in nodes {
        if let Some(company) = node.attributes.get("company") {
            company_members
                .entry(company.clone())
                .or_default()
                .push(node.id.clone());
        }
    }

    // Also check WorksAt edges
    for edge in edges {
        if matches!(edge.edge_type, EdgeType::WorksAt) {
            if let Some(org) = nodes.iter().find(|n| n.id == edge.target) {
                company_members
                    .entry(org.label.clone())
                    .or_default()
                    .push(edge.source.clone());
            }
        }
    }

    for (company, members) in company_members {
        if members.len() >= 2 {
            clusters.push(Cluster {
                id: format!("cluster_{}", cluster_id),
                name: company,
                members: members.into_iter().collect::<HashSet<_>>().into_iter().collect(),
                cluster_type: ClusterType::Company,
            });
            cluster_id += 1;
        }
    }

    // Repository clusters (collaborators)
    let mut repo_members: HashMap<String, Vec<String>> = HashMap::new();
    for edge in edges {
        if matches!(edge.edge_type, EdgeType::Contributor) {
            repo_members
                .entry(edge.target.clone())
                .or_default()
                .push(edge.source.clone());
        }
    }

    for (repo, members) in repo_members {
        if members.len() >= 2 {
            clusters.push(Cluster {
                id: format!("cluster_{}", cluster_id),
                name: repo,
                members,
                cluster_type: ClusterType::Project,
            });
            cluster_id += 1;
        }
    }

    clusters
}

fn calculate_centrality(nodes: &[GraphNode], edges: &[GraphEdge]) -> Vec<KeyPerson> {
    let mut key_persons = Vec::new();

    // Calculate degree centrality
    let mut degrees: HashMap<String, usize> = HashMap::new();
    for edge in edges {
        *degrees.entry(edge.source.clone()).or_default() += 1;
        *degrees.entry(edge.target.clone()).or_default() += 1;
    }

    let max_degree = degrees.values().max().copied().unwrap_or(1);
    let node_count = nodes.len();

    for node in nodes.iter().filter(|n| matches!(n.node_type, NodeType::Person)) {
        let degree = degrees.get(&node.id).copied().unwrap_or(0);
        let degree_centrality = if node_count > 1 {
            degree as f64 / (node_count - 1) as f64
        } else {
            0.0
        };

        // Simple influence score based on degree
        let influence = degree as f64 / max_degree.max(1) as f64;

        let mut roles = Vec::new();
        if degree > node_count / 2 {
            roles.push("hub".to_string());
        }
        if degree >= 3 && degree < node_count / 2 {
            roles.push("connector".to_string());
        }

        key_persons.push(KeyPerson {
            node_id: node.id.clone(),
            name: node.label.clone(),
            degree_centrality,
            betweenness_centrality: None, // Would need Brandes algorithm
            influence_score: influence,
            roles,
        });
    }

    // Sort by influence score
    key_persons.sort_by(|a, b| b.influence_score.partial_cmp(&a.influence_score).unwrap());

    // Return top 10
    key_persons.truncate(10);
    key_persons
}

fn detect_secrets(repos: &[GithubRepo]) -> Vec<SecretLeak> {
    let mut leaks = Vec::new();
    let mut leak_id = 1;

    let patterns = vec![
        (r"AKIA[0-9A-Z]{16}", SecretType::AwsKey, Severity::Critical),
        (r"(?i)api[_-]?key\s*[=:]\s*['\"]?([a-zA-Z0-9_\-]{20,})['\"]?", SecretType::ApiKey, Severity::High),
        (r"-----BEGIN (RSA |EC |DSA |OPENSSH )?PRIVATE KEY-----", SecretType::PrivateKey, Severity::Critical),
        (r"(?i)password\s*[=:]\s*['\"]?([^'\"\s]{8,})['\"]?", SecretType::Password, Severity::High),
        (r"(?i)(?:postgres|mysql|mongodb)://[^/\s]+:[^@\s]+@", SecretType::DatabaseUrl, Severity::Critical),
        (r"(?i)bearer\s+[a-zA-Z0-9_\-\.]{20,}", SecretType::OAuthToken, Severity::High),
        (r"(?i)jwt[_-]?secret\s*[=:]\s*['\"]?([a-zA-Z0-9_\-]{20,})['\"]?", SecretType::JwtSecret, Severity::High),
        (r"https://hooks\.slack\.com/services/T[A-Z0-9]+/B[A-Z0-9]+/[a-zA-Z0-9]+", SecretType::SlackWebhook, Severity::Medium),
        (r"(?i)secret[_-]?key\s*[=:]\s*['\"]?([a-zA-Z0-9_\-]{16,})['\"]?", SecretType::GenericSecret, Severity::Medium),
    ];

    for repo in repos {
        if let Some(files) = &repo.files {
            for file in files {
                if let Some(content) = &file.content {
                    for (pattern, secret_type, severity) in &patterns {
                        if let Ok(re) = Regex::new(pattern) {
                            for cap in re.find_iter(content) {
                                let context = extract_context(content, cap.start(), cap.end());

                                leaks.push(SecretLeak {
                                    leak_id: format!("leak_{}", leak_id),
                                    repository: repo.name.clone(),
                                    file_path: file.path.clone(),
                                    secret_type: secret_type.clone(),
                                    severity: severity.clone(),
                                    pattern_matched: pattern.to_string(),
                                    context,
                                    committed_by: None,
                                });
                                leak_id += 1;
                            }
                        }
                    }
                }
            }
        }

        // Check commits for secrets in messages (less common but happens)
        if let Some(commits) = &repo.commits {
            for commit in commits {
                for (pattern, secret_type, severity) in &patterns {
                    if let Ok(re) = Regex::new(pattern) {
                        if re.is_match(&commit.message) {
                            leaks.push(SecretLeak {
                                leak_id: format!("leak_{}", leak_id),
                                repository: repo.name.clone(),
                                file_path: format!("commit:{}", commit.sha),
                                secret_type: secret_type.clone(),
                                severity: Severity::Medium, // Lower severity in commit messages
                                pattern_matched: pattern.to_string(),
                                context: commit.message.clone(),
                                committed_by: Some(commit.author_email.clone()),
                            });
                            leak_id += 1;
                        }
                    }
                }
            }
        }
    }

    leaks
}

fn extract_context(content: &str, start: usize, end: usize) -> String {
    let context_chars = 50;
    let ctx_start = start.saturating_sub(context_chars);
    let ctx_end = (end + context_chars).min(content.len());

    let mut context = content[ctx_start..ctx_end].to_string();
    if ctx_start > 0 {
        context = format!("...{}", context);
    }
    if ctx_end < content.len() {
        context = format!("{}...", context);
    }

    // Mask the actual secret
    context = context.replace(&content[start..end], "[REDACTED]");
    context
}

fn build_analysis(nodes: &[GraphNode], edges: &[GraphEdge], key_persons: Vec<KeyPerson>) -> GraphAnalysis {
    let total_nodes = nodes.len();
    let total_edges = edges.len();

    // Calculate density
    let max_edges = if total_nodes > 1 {
        total_nodes * (total_nodes - 1) / 2
    } else {
        1
    };
    let density = total_edges as f64 / max_edges as f64;

    // Find isolated nodes (no edges)
    let connected: HashSet<_> = edges.iter()
        .flat_map(|e| vec![e.source.clone(), e.target.clone()])
        .collect();
    let isolated: Vec<_> = nodes.iter()
        .filter(|n| !connected.contains(&n.id))
        .map(|n| n.id.clone())
        .collect();

    // Count connected components (simple BFS)
    let connected_components = count_components(nodes, edges);

    GraphAnalysis {
        total_nodes,
        total_edges,
        density,
        key_persons,
        isolated_nodes: isolated,
        connected_components,
    }
}

fn count_components(nodes: &[GraphNode], edges: &[GraphEdge]) -> usize {
    let mut visited: HashSet<String> = HashSet::new();
    let mut components = 0;

    // Build adjacency list
    let mut adj: HashMap<String, Vec<String>> = HashMap::new();
    for node in nodes {
        adj.insert(node.id.clone(), Vec::new());
    }
    for edge in edges {
        adj.entry(edge.source.clone()).or_default().push(edge.target.clone());
        adj.entry(edge.target.clone()).or_default().push(edge.source.clone());
    }

    for node in nodes {
        if !visited.contains(&node.id) {
            components += 1;
            let mut stack = vec![node.id.clone()];
            while let Some(current) = stack.pop() {
                if visited.insert(current.clone()) {
                    if let Some(neighbors) = adj.get(&current) {
                        for neighbor in neighbors {
                            if !visited.contains(neighbor) {
                                stack.push(neighbor.clone());
                            }
                        }
                    }
                }
            }
        }
    }

    components
}

fn generate_dot(graph: &SocialGraph) -> String {
    let mut dot = String::from("digraph social_graph {\n");
    dot.push_str("  rankdir=LR;\n");
    dot.push_str("  node [shape=box, style=filled];\n\n");

    // Node type colors
    let type_colors = |nt: &NodeType| -> &str {
        match nt {
            NodeType::Person => "lightblue",
            NodeType::Organization => "lightgreen",
            NodeType::Repository => "lightyellow",
            NodeType::Domain => "lightgray",
            NodeType::Email => "lightpink",
        }
    };

    // Nodes
    for node in &graph.nodes {
        let color = type_colors(&node.node_type);
        let label = escape_dot_string(&node.label);
        dot.push_str(&format!(
            "  {} [label=\"{}\", fillcolor=\"{}\"];\n",
            escape_dot_id(&node.id),
            label,
            color
        ));
    }

    dot.push_str("\n");

    // Edges
    for edge in &graph.edges {
        let style = match edge.edge_type {
            EdgeType::WorksAt => "bold",
            EdgeType::Colleague => "dashed",
            EdgeType::Connection => "dotted",
            EdgeType::Contributor => "solid",
            EdgeType::Collaborator => "dashed",
            _ => "solid",
        };

        let label = format!("{:?}", edge.edge_type);
        dot.push_str(&format!(
            "  {} -> {} [label=\"{}\", style=\"{}\"];\n",
            escape_dot_id(&edge.source),
            escape_dot_id(&edge.target),
            label,
            style
        ));
    }

    // Clusters
    for cluster in &graph.clusters {
        dot.push_str(&format!(
            "\n  subgraph cluster_{} {{\n",
            escape_dot_id(&cluster.id)
        ));
        dot.push_str(&format!("    label=\"{}\";\n", escape_dot_string(&cluster.name)));
        for member in &cluster.members {
            dot.push_str(&format!("    {};\n", escape_dot_id(member)));
        }
        dot.push_str("  }\n");
    }

    dot.push_str("}\n");
    dot
}

fn escape_dot_string(s: &str) -> String {
    s.replace("\"", "\\\"").replace("\n", "\\n")
}

fn escape_dot_id(s: &str) -> String {
    // DOT IDs should be alphanumeric or quoted
    if s.chars().all(|c| c.is_alphanumeric() || c == '_') {
        s.to_string()
    } else {
        format!("\"{}\"", escape_dot_string(s))
    }
}

fn chrono_placeholder() -> String {
    "2026-01-11T00:00:00Z".to_string()
}

fn create_empty_output() -> SocialOutput {
    SocialOutput {
        graph: SocialGraph {
            nodes: Vec::new(),
            edges: Vec::new(),
            clusters: Vec::new(),
        },
        analysis: GraphAnalysis {
            total_nodes: 0,
            total_edges: 0,
            density: 0.0,
            key_persons: Vec::new(),
            isolated_nodes: Vec::new(),
            connected_components: 0,
        },
        leaks: Vec::new(),
        correlations: Vec::new(),
        dot_graph: None,
        metadata: AnalysisMetadata {
            sources_processed: Vec::new(),
            processing_warnings: Vec::new(),
            analysis_timestamp: chrono_placeholder(),
        },
    }
}
```

### 4.4 Solutions alternatives acceptÃ©es

```rust
// Alternative 1: Using petgraph library for graph operations
use petgraph::Graph;
use petgraph::algo::{connected_components, dijkstra};

fn build_graph_petgraph(nodes: &[GraphNode], edges: &[GraphEdge]) -> Graph<String, f64> {
    let mut graph = Graph::<String, f64>::new();
    let mut node_indices = HashMap::new();

    for node in nodes {
        let idx = graph.add_node(node.id.clone());
        node_indices.insert(node.id.clone(), idx);
    }

    for edge in edges {
        if let (Some(&src), Some(&tgt)) =
            (node_indices.get(&edge.source), node_indices.get(&edge.target))
        {
            graph.add_edge(src, tgt, edge.weight);
        }
    }

    graph
}

// Alternative 2: Simpler regex patterns without regex crate
fn detect_secrets_simple(content: &str) -> Vec<SecretType> {
    let mut found = Vec::new();

    if content.contains("AKIA") && content.len() > 20 {
        found.push(SecretType::AwsKey);
    }
    if content.to_lowercase().contains("api_key") ||
       content.to_lowercase().contains("api-key") {
        found.push(SecretType::ApiKey);
    }
    if content.contains("-----BEGIN") && content.contains("PRIVATE KEY") {
        found.push(SecretType::PrivateKey);
    }

    found
}
```

### 4.5 Solutions refusÃ©es (avec explications)

```rust
// âŒ REFUSÃ‰E: Ne gÃ¨re pas les corrÃ©lations entre sources
fn bad_parse_all_separate(input: &SocialInput) -> Vec<GraphNode> {
    let mut nodes = Vec::new();
    // Parse each source completely separately, creating duplicates
    if let Some(li) = &input.linkedin_profiles {
        for p in li {
            nodes.push(GraphNode { /* ... */ });
        }
    }
    if let Some(gh) = &input.github_data {
        if let Some(users) = &gh.users {
            for u in users {
                // MÃªme personne crÃ©Ã©e 2 fois si mÃªme email!
                nodes.push(GraphNode { /* ... */ });
            }
        }
    }
    nodes
}
// Pourquoi refusÃ©: CrÃ©e des doublons sans corrÃ©lation

// âŒ REFUSÃ‰E: Patterns secrets trop gÃ©nÃ©riques
fn bad_detect_secrets(content: &str) -> bool {
    // Matche n'importe quoi avec "key" ou "password"
    content.to_lowercase().contains("key") ||
    content.to_lowercase().contains("password")
}
// Pourquoi refusÃ©: False positives massifs (documentation, variable names)

// âŒ REFUSÃ‰E: DOT invalide
fn bad_generate_dot(nodes: &[GraphNode]) -> String {
    let mut dot = String::new();
    for node in nodes {
        // Pas de structure digraph, pas d'Ã©chappement
        dot.push_str(&format!("{} -> {}\n", node.id, node.label));
    }
    dot
}
// Pourquoi refusÃ©: Syntaxe DOT invalide, caractÃ¨res spÃ©ciaux non Ã©chappÃ©s

// âŒ REFUSÃ‰E: CentralitÃ© incorrecte
fn bad_centrality(edges: &[GraphEdge]) -> HashMap<String, f64> {
    let mut degrees = HashMap::new();
    for edge in edges {
        // Compte seulement les edges sortantes
        *degrees.entry(edge.source.clone()).or_insert(0.0) += 1.0;
        // Oublie les entrantes!
    }
    degrees
}
// Pourquoi refusÃ©: DegrÃ© calculÃ© uniquement sur edges sortantes
```

### 4.6 Solution bonus de rÃ©fÃ©rence

```rust
/// Calcule la similaritÃ© Jaro-Winkler entre deux chaÃ®nes
fn jaro_winkler_similarity(s1: &str, s2: &str) -> f64 {
    let s1 = s1.to_lowercase();
    let s2 = s2.to_lowercase();

    if s1 == s2 {
        return 1.0;
    }

    let len1 = s1.chars().count();
    let len2 = s2.chars().count();

    if len1 == 0 || len2 == 0 {
        return 0.0;
    }

    let match_distance = (std::cmp::max(len1, len2) / 2).saturating_sub(1);

    let s1_chars: Vec<char> = s1.chars().collect();
    let s2_chars: Vec<char> = s2.chars().collect();

    let mut s1_matches = vec![false; len1];
    let mut s2_matches = vec![false; len2];

    let mut matches = 0.0;
    let mut transpositions = 0.0;

    // Find matches
    for i in 0..len1 {
        let start = i.saturating_sub(match_distance);
        let end = std::cmp::min(i + match_distance + 1, len2);

        for j in start..end {
            if s2_matches[j] || s1_chars[i] != s2_chars[j] {
                continue;
            }
            s1_matches[i] = true;
            s2_matches[j] = true;
            matches += 1.0;
            break;
        }
    }

    if matches == 0.0 {
        return 0.0;
    }

    // Count transpositions
    let mut k = 0;
    for i in 0..len1 {
        if !s1_matches[i] {
            continue;
        }
        while !s2_matches[k] {
            k += 1;
        }
        if s1_chars[i] != s2_chars[k] {
            transpositions += 1.0;
        }
        k += 1;
    }

    let jaro = (matches / len1 as f64 +
                matches / len2 as f64 +
                (matches - transpositions / 2.0) / matches) / 3.0;

    // Winkler modification: common prefix bonus
    let mut prefix_len = 0;
    for (c1, c2) in s1.chars().zip(s2.chars()) {
        if c1 == c2 {
            prefix_len += 1;
            if prefix_len == 4 {
                break;
            }
        } else {
            break;
        }
    }

    jaro + (prefix_len as f64 * 0.1 * (1.0 - jaro))
}

/// DÃ©tecte les identitÃ©s potentiellement dupliquÃ©es avec fuzzy matching
fn detect_duplicate_identities(
    nodes: &[GraphNode],
    threshold: f64,
) -> Vec<DuplicateCandidate> {
    let mut candidates = Vec::new();
    let person_nodes: Vec<_> = nodes.iter()
        .filter(|n| matches!(n.node_type, NodeType::Person))
        .collect();

    for i in 0..person_nodes.len() {
        for j in (i + 1)..person_nodes.len() {
            let n1 = person_nodes[i];
            let n2 = person_nodes[j];

            // Skip if same source
            if n1.sources == n2.sources {
                continue;
            }

            let mut matching_attrs = Vec::new();
            let mut scores = Vec::new();

            // Name similarity
            let name_sim = jaro_winkler_similarity(&n1.label, &n2.label);
            if name_sim > 0.7 {
                matching_attrs.push(format!("name ({:.2})", name_sim));
                scores.push(name_sim);
            }

            // Email similarity
            if let (Some(e1), Some(e2)) = (
                n1.attributes.get("email"),
                n2.attributes.get("email")
            ) {
                let email_sim = jaro_winkler_similarity(e1, e2);
                if email_sim > 0.8 {
                    matching_attrs.push(format!("email ({:.2})", email_sim));
                    scores.push(email_sim);
                }
            }

            // Company match
            if let (Some(c1), Some(c2)) = (
                n1.attributes.get("company"),
                n2.attributes.get("company")
            ) {
                let comp_sim = jaro_winkler_similarity(c1, c2);
                if comp_sim > 0.8 {
                    matching_attrs.push("company".to_string());
                    scores.push(comp_sim);
                }
            }

            if !scores.is_empty() {
                let avg_score = scores.iter().sum::<f64>() / scores.len() as f64;

                if avg_score >= threshold {
                    candidates.push(DuplicateCandidate {
                        primary_id: n1.id.clone(),
                        candidate_id: n2.id.clone(),
                        similarity_score: avg_score,
                        matching_attributes: matching_attrs,
                        merge_recommendation: avg_score > 0.9,
                    });
                }
            }
        }
    }

    candidates.sort_by(|a, b| b.similarity_score.partial_cmp(&a.similarity_score).unwrap());
    candidates.truncate(10);
    candidates
}

/// Algorithme de Brandes simplifiÃ© pour betweenness centrality
fn calculate_betweenness_centrality(
    nodes: &[GraphNode],
    edges: &[GraphEdge],
) -> HashMap<String, f64> {
    let mut betweenness: HashMap<String, f64> = HashMap::new();

    // Initialize
    for node in nodes {
        betweenness.insert(node.id.clone(), 0.0);
    }

    // Build adjacency list
    let mut adj: HashMap<String, Vec<String>> = HashMap::new();
    for node in nodes {
        adj.insert(node.id.clone(), Vec::new());
    }
    for edge in edges {
        adj.entry(edge.source.clone()).or_default().push(edge.target.clone());
        adj.entry(edge.target.clone()).or_default().push(edge.source.clone());
    }

    // Brandes algorithm
    for s in nodes.iter().map(|n| &n.id) {
        let mut stack: Vec<String> = Vec::new();
        let mut pred: HashMap<String, Vec<String>> = HashMap::new();
        let mut sigma: HashMap<String, f64> = HashMap::new();
        let mut dist: HashMap<String, i32> = HashMap::new();

        for node in nodes {
            pred.insert(node.id.clone(), Vec::new());
            sigma.insert(node.id.clone(), 0.0);
            dist.insert(node.id.clone(), -1);
        }

        *sigma.get_mut(s).unwrap() = 1.0;
        *dist.get_mut(s).unwrap() = 0;

        let mut queue = std::collections::VecDeque::new();
        queue.push_back(s.clone());

        while let Some(v) = queue.pop_front() {
            stack.push(v.clone());

            if let Some(neighbors) = adj.get(&v) {
                for w in neighbors {
                    // First time finding w?
                    if dist[w] < 0 {
                        *dist.get_mut(w).unwrap() = dist[&v] + 1;
                        queue.push_back(w.clone());
                    }

                    // Shortest path to w via v?
                    if dist[w] == dist[&v] + 1 {
                        *sigma.get_mut(w).unwrap() += sigma[&v];
                        pred.get_mut(w).unwrap().push(v.clone());
                    }
                }
            }
        }

        // Accumulation
        let mut delta: HashMap<String, f64> = HashMap::new();
        for node in nodes {
            delta.insert(node.id.clone(), 0.0);
        }

        while let Some(w) = stack.pop() {
            for v in pred[&w].iter() {
                let contrib = (sigma[v] / sigma[&w]) * (1.0 + delta[&w]);
                *delta.get_mut(v).unwrap() += contrib;
            }

            if &w != s {
                *betweenness.get_mut(&w).unwrap() += delta[&w];
            }
        }
    }

    // Normalize
    let n = nodes.len();
    if n > 2 {
        let norm = 2.0 / ((n - 1) * (n - 2)) as f64;
        for val in betweenness.values_mut() {
            *val *= norm;
        }
    }

    betweenness
}

/// GÃ©nÃ¨re un rapport de sÃ©curitÃ© cross-platform
fn generate_security_report(
    correlations: &[IdentityCorrelation],
    leaks: &[SecretLeak],
) -> SecurityReport {
    let mut critical_findings = Vec::new();
    let mut recommendations = Vec::new();
    let mut affected_identities: HashSet<String> = HashSet::new();

    // Analyze cross-platform exposure
    for corr in correlations {
        if corr.confidence > 0.8 && corr.entities.len() >= 2 {
            let sources: Vec<_> = corr.entities.iter()
                .map(|e| e.source.as_str())
                .collect();

            if sources.contains(&"github") && sources.contains(&"linkedin") {
                critical_findings.push(format!(
                    "Identity {} exposed on both GitHub and LinkedIn - correlation confidence {:.0}%",
                    corr.entities[0].identifier,
                    corr.confidence * 100.0
                ));
                affected_identities.insert(corr.entities[0].identifier.clone());
            }
        }
    }

    // Analyze leaks by severity
    let critical_leaks = leaks.iter()
        .filter(|l| matches!(l.severity, Severity::Critical))
        .count();
    let high_leaks = leaks.iter()
        .filter(|l| matches!(l.severity, Severity::High))
        .count();

    if critical_leaks > 0 {
        critical_findings.push(format!(
            "{} CRITICAL secrets exposed in repositories",
            critical_leaks
        ));
        recommendations.push("Immediately rotate all exposed AWS keys and credentials".to_string());
    }

    if high_leaks > 0 {
        critical_findings.push(format!(
            "{} HIGH severity secrets found",
            high_leaks
        ));
        recommendations.push("Review and rotate API keys within 24 hours".to_string());
    }

    // Cross-reference leaks with identities
    for leak in leaks {
        if let Some(author) = &leak.committed_by {
            affected_identities.insert(author.clone());
        }
    }

    // General recommendations
    recommendations.push("Implement pre-commit hooks to prevent secret leaks".to_string());
    recommendations.push("Enable GitHub secret scanning alerts".to_string());
    recommendations.push("Review LinkedIn profile privacy settings".to_string());

    // Calculate exposure score
    let base_score = (critical_leaks * 25 + high_leaks * 10) as f64;
    let correlation_score = correlations.iter()
        .filter(|c| c.confidence > 0.8)
        .count() as f64 * 5.0;
    let exposure_score = (base_score + correlation_score).min(100.0);

    SecurityReport {
        exposure_score,
        critical_findings,
        recommendations,
        affected_identities: affected_identities.into_iter().collect(),
    }
}
```

### 4.9 spec.json

```json
{
  "name": "social_graph",
  "language": "rust",
  "version": "2024",
  "type": "complet",
  "tier": 1,
  "tier_info": "Concept isolÃ© - Social Media OSINT",
  "tags": ["osint", "social", "graph", "linkedin", "github", "theharvester"],
  "passing_score": 70,

  "function": {
    "name": "social_graph",
    "prototype": "pub fn social_graph(input_json: &str) -> String",
    "return_type": "String",
    "parameters": [
      {"name": "input_json", "type": "&str"}
    ]
  },

  "driver": {
    "reference": "pub fn ref_social_graph(input_json: &str) -> String { let input: SocialInput = serde_json::from_str(input_json).unwrap_or_default(); let output = process_social_data(&input); serde_json::to_string(&output).unwrap() }",

    "edge_cases": [
      {
        "name": "empty_input",
        "args": ["{}"],
        "expected_contains": ["\"total_nodes\": 0"],
        "is_trap": true,
        "trap_explanation": "Input vide doit retourner un graphe vide sans erreur"
      },
      {
        "name": "linkedin_only",
        "args": ["{\"linkedin_profiles\": [{\"name\": \"Alice\", \"company\": \"Acme\"}]}"],
        "expected_contains": ["Person", "Organization", "WorksAt"],
        "is_trap": false
      },
      {
        "name": "email_case_sensitivity",
        "args": ["{\"linkedin_profiles\": [{\"name\": \"Bob\", \"email\": \"Bob@Test.com\"}], \"harvester_emails\": [{\"email\": \"bob@test.com\", \"domain\": \"test.com\"}]}"],
        "expected_contains": ["correlation"],
        "is_trap": true,
        "trap_explanation": "Les emails doivent Ãªtre comparÃ©s en lowercase"
      },
      {
        "name": "aws_key_detection",
        "args": ["{\"github_data\": {\"repositories\": [{\"name\": \"repo\", \"owner\": \"user\", \"files\": [{\"path\": \"config.py\", \"content\": \"KEY=AKIAIOSFODNN7EXAMPLE\"}]}]}}"],
        "expected_contains": ["AwsKey", "Critical"],
        "is_trap": false
      },
      {
        "name": "dot_escaping",
        "args": ["{\"linkedin_profiles\": [{\"name\": \"John \\\"The Dev\\\" Doe\"}], \"options\": {\"generate_dot\": true}}"],
        "expected_contains": ["digraph", "\\\""],
        "is_trap": true,
        "trap_explanation": "Les guillemets dans les labels DOT doivent Ãªtre Ã©chappÃ©s"
      }
    ],

    "fuzzing": {
      "enabled": true,
      "iterations": 500,
      "generators": [
        {
          "type": "json_object",
          "param_index": 0,
          "params": {
            "schema": "SocialInput",
            "max_profiles": 50,
            "max_repos": 20
          }
        }
      ]
    }
  },

  "norm": {
    "allowed_functions": ["serde_json", "regex", "std::collections"],
    "forbidden_functions": ["std::net", "tokio", "reqwest"],
    "check_security": true,
    "check_memory": true,
    "blocking": true
  }
}
```

### 4.10 Solutions Mutantes

```rust
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT A (Boundary) : Off-by-one dans le calcul de centralitÃ©
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
fn mutant_a_centrality(nodes: &[GraphNode], edges: &[GraphEdge]) -> Vec<KeyPerson> {
    let mut degrees: HashMap<String, usize> = HashMap::new();
    for edge in edges {
        *degrees.entry(edge.source.clone()).or_default() += 1;
        *degrees.entry(edge.target.clone()).or_default() += 1;
    }

    // BUG: Division par node_count au lieu de node_count - 1
    let node_count = nodes.len();
    for node in nodes {
        let degree = degrees.get(&node.id).copied().unwrap_or(0);
        let centrality = degree as f64 / node_count as f64; // FAUX!
        // ...
    }
    Vec::new()
}
// Pourquoi c'est faux: La centralitÃ© de degrÃ© normalisÃ©e divise par (n-1) pas n
// Ce qui Ã©tait pensÃ©: Confusion entre nombre de nÅ“uds et nombre max de connexions

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT B (Safety) : Pas de vÃ©rification de taille pour Jaro-Winkler
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
fn mutant_b_jaro(s1: &str, s2: &str) -> f64 {
    // BUG: Pas de vÃ©rification si les chaÃ®nes sont vides
    let len1 = s1.len();
    let len2 = s2.len();

    // Division par zÃ©ro si len1 ou len2 = 0
    let matches = 5.0;
    let jaro = matches / len1 as f64; // CRASH si s1 est vide!
    jaro
}
// Pourquoi c'est faux: Division par zÃ©ro quand chaÃ®ne vide
// Ce qui Ã©tait pensÃ©: On suppose toujours des inputs non-vides

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT C (Logic) : CorrÃ©lation sensible Ã  la casse
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
fn mutant_c_correlation(nodes: &[GraphNode]) -> Vec<IdentityCorrelation> {
    let mut email_groups: HashMap<String, Vec<&GraphNode>> = HashMap::new();

    for node in nodes {
        if let Some(email) = node.attributes.get("email") {
            // BUG: Pas de normalisation lowercase
            email_groups.entry(email.clone()).or_default().push(node);
        }
    }

    // "Bob@Test.com" et "bob@test.com" ne matchent pas!
    Vec::new()
}
// Pourquoi c'est faux: "Bob@Example.com" != "bob@example.com"
// Ce qui Ã©tait pensÃ©: Les emails sont toujours en lowercase

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT D (Resource) : DOT sans Ã©chappement
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
fn mutant_d_dot(graph: &SocialGraph) -> String {
    let mut dot = String::from("digraph {\n");

    for node in &graph.nodes {
        // BUG: Pas d'Ã©chappement des caractÃ¨res spÃ©ciaux
        dot.push_str(&format!("  {} [label=\"{}\"];\n",
            node.id,
            node.label  // Si label contient ", le DOT est invalide!
        ));
    }

    dot.push_str("}\n");
    dot
}
// Pourquoi c'est faux: Label "John "Dev" Doe" gÃ©nÃ¨re du DOT invalide
// Ce qui Ã©tait pensÃ©: Les noms ne contiennent pas de caractÃ¨res spÃ©ciaux

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT E (Return) : Secrets regex trop stricte
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
fn mutant_e_secrets(content: &str) -> Vec<SecretLeak> {
    let mut leaks = Vec::new();

    // BUG: Pattern AWS trop strict - manque variantes
    let aws_pattern = r"^AKIAIOSFODNN7EXAMPLE$"; // Exact match seulement!
    if let Ok(re) = Regex::new(aws_pattern) {
        if re.is_match(content) {
            // Ne matche que ce pattern exact, pas les vraies clÃ©s
        }
    }

    leaks
}
// Pourquoi c'est faux: Ne dÃ©tecte pas AKIA[A-Z0-9]{16} gÃ©nÃ©rique
// Ce qui Ã©tait pensÃ©: Les clÃ©s AWS ont un format fixe

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT F (Logic) : Collaborators edge duplicates
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
fn mutant_f_edges(contributors: &[String]) -> Vec<GraphEdge> {
    let mut edges = Vec::new();

    // BUG: CrÃ©e des edges dans les deux sens
    for i in 0..contributors.len() {
        for j in 0..contributors.len() { // Devrait Ãªtre j > i
            if i != j {
                // CrÃ©e A->B et B->A au lieu de juste A<->B
                edges.push(GraphEdge {
                    source: contributors[i].clone(),
                    target: contributors[j].clone(),
                    edge_type: EdgeType::Collaborator,
                    // ...
                    id: String::new(),
                    weight: 1.0,
                    attributes: HashMap::new(),
                });
            }
        }
    }

    edges // Contient des doublons!
}
// Pourquoi c'est faux: 2x plus d'edges que nÃ©cessaire
// Ce qui Ã©tait pensÃ©: Boucle imbriquÃ©e standard
```

---

## ğŸ§  SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

| Concept | Description | Application |
|---------|-------------|-------------|
| **OSINT Social** | Collecte d'informations sur rÃ©seaux sociaux | Red team reconnaissance |
| **Graphes de relations** | ModÃ©lisation des connexions entre entitÃ©s | Intelligence analysis |
| **CorrÃ©lation d'identitÃ©s** | Lier des profils cross-platform | Attribution d'acteurs |
| **DÃ©tection de secrets** | Patterns regex pour credentials | Security auditing |
| **CentralitÃ©** | Identifier les nÅ“uds clÃ©s d'un rÃ©seau | Target prioritization |

### 5.2 LDA â€” Traduction littÃ©rale

```
FONCTION social_graph QUI RETOURNE UNE CHAÃNE ET PREND EN PARAMÃˆTRE input_json QUI EST UNE RÃ‰FÃ‰RENCE VERS UNE CHAÃNE
DÃ‰BUT FONCTION
    DÃ‰CLARER input COMME RÃ‰SULTAT DU PARSING JSON DE input_json

    SI LE PARSING Ã‰CHOUE ALORS
        RETOURNER UN JSON DE SORTIE VIDE
    FIN SI

    DÃ‰CLARER all_nodes COMME VECTEUR DE NÅ’UDS GRAPHE
    DÃ‰CLARER all_edges COMME VECTEUR D'ARÃŠTES GRAPHE

    SI input CONTIENT linkedin_profiles ALORS
        Ã‰TENDRE all_nodes AVEC LES NÅ’UDS PARSÃ‰S DE LINKEDIN
        Ã‰TENDRE all_edges AVEC LES ARÃŠTES LINKEDIN
    FIN SI

    SI input CONTIENT harvester_emails ALORS
        Ã‰TENDRE all_nodes AVEC LES NÅ’UDS EMAIL
    FIN SI

    SI input CONTIENT github_data ALORS
        Ã‰TENDRE all_nodes ET all_edges AVEC LES DONNÃ‰ES GITHUB
    FIN SI

    DÃ‰CLARER correlations COMME RÃ‰SULTAT DE correlate_identities SUR all_nodes
    DÃ‰CLARER merged COMME RÃ‰SULTAT DE merge_correlated_entities
    DÃ‰CLARER key_persons COMME RÃ‰SULTAT DE calculate_centrality
    DÃ‰CLARER leaks COMME RÃ‰SULTAT DE detect_secrets
    DÃ‰CLARER dot_graph COMME RÃ‰SULTAT DE generate_dot

    CONSTRUIRE L'OUTPUT AVEC graph, analysis, leaks, correlations, dot_graph

    RETOURNER LE JSON DE L'OUTPUT
FIN FONCTION
```

### 5.2.2.1 Logic Flow

```
ALGORITHME : Analyse de Graphe Social
---
1. PARSER le JSON d'entrÃ©e

2. POUR CHAQUE source de donnÃ©es (LinkedIn, TheHarvester, GitHub) :
   a. PARSER les donnÃ©es spÃ©cifiques Ã  la source
   b. CRÃ‰ER les nÅ“uds correspondants (Person, Org, Repo, Email)
   c. CRÃ‰ER les arÃªtes internes (WorksAt, Colleague, Contributor)

3. CORRÃ‰LER les identitÃ©s entre sources :
   a. GROUPER par email (exact match lowercase)
   b. GROUPER par nom (fuzzy matching si bonus)
   c. CRÃ‰ER les IdentityCorrelation avec score de confiance

4. FUSIONNER les entitÃ©s corrÃ©lÃ©es :
   a. GARDER l'entitÃ© primaire
   b. MERGER les attributs des secondaires
   c. METTRE Ã€ JOUR les rÃ©fÃ©rences dans les edges

5. DÃ‰TECTER les clusters :
   a. GROUPER par entreprise (mÃªme company)
   b. GROUPER par projet (mÃªmes contributors)

6. CALCULER la centralitÃ© :
   a. COMPTER le degrÃ© de chaque nÅ“ud
   b. NORMALISER par (n-1)
   c. IDENTIFIER les hubs et connectors

7. DÃ‰TECTER les secrets dans les fichiers :
   a. APPLIQUER chaque pattern regex
   b. CLASSIFIER par type et sÃ©vÃ©ritÃ©
   c. EXTRAIRE le contexte

8. GÃ‰NÃ‰RER le DOT :
   a. Ã‰CRIRE l'en-tÃªte digraph
   b. Ã‰CRIRE chaque nÅ“ud avec attributs
   c. Ã‰CRIRE chaque edge avec style
   d. Ã‰CRIRE les subgraphs pour clusters

9. RETOURNER le JSON de sortie
```

### 5.3 Visualisation ASCII

```
FLUX DE DONNÃ‰ES OSINT â†’ GRAPHE SOCIAL
=====================================

Sources OSINT                          Graphe RÃ©sultant
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    LinkedIn       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚ Name: Alice   â”‚ â”œâ”€â”€â”                  â”‚         SOCIAL GRAPH        â”‚
â”‚ â”‚ Company: Acme â”‚ â”‚  â”‚                  â”‚                             â”‚
â”‚ â”‚ Email: a@...  â”‚ â”‚  â”‚                  â”‚   [Alice]â”€â”€â”€â”€â”€â”€â”€[TechCorp]  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚                  â”‚      â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                  â”‚      â”‚ Colleague            â”‚
                       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚      â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”œâ”€â”€â”‚ CORRELATEâ”‚â”€â”€â”€â”€â”‚   [Bob]                     â”‚
â”‚   TheHarvester    â”‚  â”‚  â”‚ & MERGE  â”‚    â”‚      â”‚                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚      â”‚ Collaborator         â”‚
â”‚ â”‚ a@acme.com    â”‚ â”œâ”€â”€â”¤                  â”‚      â”‚                      â”‚
â”‚ â”‚ b@acme.com    â”‚ â”‚  â”‚                  â”‚   [Carol]â”€â”€â”€[repo/project]  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚                  â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚     GitHub        â”‚  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚                  MÃ‰TRIQUES
â”‚ â”‚ user: achen   â”‚ â”œâ”€â”€â”˜                  â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ â”‚ email: a@...  â”‚ â”‚
â”‚ â”‚ repos: [...]  â”‚ â”‚                     Nodes: 5
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                     Edges: 7
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                     Density: 0.46
â”‚ â”‚ repo: project â”‚ â”‚                     Key Person: Alice (0.85)
â”‚ â”‚ files: [...]  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Components: 1
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  SECRET SCANNER   â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚ â”‚ Pattern: AKIA â”‚ â”‚
                    â”‚ â”‚ Type: AWS_KEY â”‚ â”‚
                    â”‚ â”‚ Severity: CRITâ”‚ â”‚
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


CORRÃ‰LATION D'IDENTITÃ‰
======================

LinkedIn              GitHub              TheHarvester
â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Name:Aliceâ”‚         â”‚user:achenâ”‚        â”‚a.chen@acme.com â”‚
â”‚          â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚          â”‚â—„â”€â”€â”€â”€â”€â”€â–ºâ”‚                â”‚
â”‚email:    â”‚  MATCH  â”‚email:    â”‚ MATCH  â”‚                â”‚
â”‚a.chen@   â”‚ (0.95)  â”‚a.chen@   â”‚ (0.95) â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                    â”‚                     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   MERGED IDENTITY     â”‚
              â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
              â”‚ â”‚ ID: person_1      â”‚ â”‚
              â”‚ â”‚ Name: Alice Chen  â”‚ â”‚
              â”‚ â”‚ Email: a.chen@... â”‚ â”‚
              â”‚ â”‚ GitHub: achen     â”‚ â”‚
              â”‚ â”‚ Company: Acme     â”‚ â”‚
              â”‚ â”‚ Sources: [3]      â”‚ â”‚
              â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


DOT GRAPH OUTPUT
================

digraph social_graph {
  rankdir=LR;
  node [shape=box, style=filled];

  person_1 [label="Alice Chen", fillcolor="lightblue"];
  person_2 [label="Bob Smith", fillcolor="lightblue"];
  org_1 [label="TechCorp", fillcolor="lightgreen"];
  repo_1 [label="techcorp/api", fillcolor="lightyellow"];

  person_1 -> org_1 [label="WorksAt", style="bold"];
  person_2 -> org_1 [label="WorksAt", style="bold"];
  person_1 -> person_2 [label="Colleague", style="dashed"];
  person_1 -> repo_1 [label="Contributor", style="solid"];
  person_2 -> repo_1 [label="Contributor", style="solid"];

  subgraph cluster_company_1 {
    label="TechCorp";
    person_1;
    person_2;
  }
}
```

### 5.4 Les piÃ¨ges en dÃ©tail

| PiÃ¨ge | Description | Solution |
|-------|-------------|----------|
| **Case sensitivity** | "Bob@Test.com" â‰  "bob@test.com" | Toujours normaliser en lowercase |
| **DOT escaping** | Guillemets dans labels cassent le DOT | Ã‰chapper avec `\"` |
| **Self-loops** | AprÃ¨s merge, edge peut pointer vers soi | Filtrer `source != target` |
| **Division by zero** | Graphe vide ou un seul nÅ“ud | VÃ©rifier `n > 1` avant division |
| **Regex backtracking** | Patterns complexes sur gros fichiers | Limiter la longueur du content |
| **Transitive correlation** | A=B et B=C implique A=C? | Pas automatique, vÃ©rifier manuellement |

### 5.5 Cours Complet

#### 5.5.1 Introduction Ã  l'OSINT Social

L'OSINT (Open Source Intelligence) social consiste Ã  collecter et analyser des informations publiquement disponibles sur les rÃ©seaux sociaux, sites professionnels et plateformes de dÃ©veloppement.

**Outils principaux :**
- **TheHarvester** : Collecte emails, noms, sous-domaines depuis sources publiques
- **SpiderFoot** : OSINT automatisÃ© multi-sources
- **Maltego** : Visualisation de graphes de relations
- **OSINT Framework** : MÃ©ta-rÃ©pertoire d'outils

#### 5.5.2 ThÃ©orie des Graphes pour l'Analyse Sociale

Un graphe social G = (V, E) oÃ¹ :
- V = ensemble de nÅ“uds (personnes, organisations)
- E = ensemble d'arÃªtes (relations)

**Types de centralitÃ© :**

1. **Degree Centrality** : Nombre de connexions directes
   ```
   C_D(v) = deg(v) / (n-1)
   ```

2. **Betweenness Centrality** : FrÃ©quence d'apparition sur les plus courts chemins
   ```
   C_B(v) = Î£ (Ïƒ_st(v) / Ïƒ_st)
   ```

3. **Closeness Centrality** : Inverse de la distance moyenne aux autres nÅ“uds
   ```
   C_C(v) = (n-1) / Î£ d(v,u)
   ```

#### 5.5.3 DÃ©tection de Secrets dans le Code

Les patterns courants de secrets exposÃ©s :

| Type | Pattern Regex | Exemple |
|------|--------------|---------|
| AWS Key | `AKIA[0-9A-Z]{16}` | AKIAIOSFODNN7EXAMPLE |
| Private Key | `-----BEGIN.*PRIVATE KEY-----` | RSA key |
| Database URL | `\w+://\w+:\w+@\w+` | postgres://user:pass@host |
| JWT Secret | `jwt[_-]?secret.*=.*[a-zA-Z0-9]{20,}` | JWT_SECRET=abc... |

#### 5.5.4 Le Format DOT (Graphviz)

DOT est un langage de description de graphes :

```dot
digraph example {
    // Attributs globaux
    rankdir=LR;
    node [shape=circle];

    // NÅ“uds
    A [label="Node A", color=red];
    B [label="Node B"];

    // ArÃªtes
    A -> B [label="connects"];

    // Sous-graphes (clusters)
    subgraph cluster_0 {
        label="Group 1";
        A; B;
    }
}
```

### 5.6 Normes avec explications pÃ©dagogiques

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ HORS NORME (compile, mais interdit)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ let email = node.email.clone();  // Sans vÃ©rification Option    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… CONFORME                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ if let Some(email) = node.attributes.get("email") {             â”‚
â”‚     // Utiliser email en sÃ©curitÃ©                               â”‚
â”‚ }                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“– POURQUOI ?                                                   â”‚
â”‚                                                                 â”‚
â”‚ â€¢ Les donnÃ©es OSINT sont souvent incomplÃ¨tes                    â”‚
â”‚ â€¢ Un profil LinkedIn peut ne pas avoir d'email public           â”‚
â”‚ â€¢ Rust force la gestion explicite de l'absence de donnÃ©es       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.7 Simulation avec trace d'exÃ©cution

**Input :**
```json
{
  "linkedin_profiles": [
    {"name": "Alice Chen", "company": "TechCorp", "email": "alice@techcorp.io"},
    {"name": "Bob Smith", "company": "TechCorp"}
  ],
  "github_data": {
    "users": [{"username": "achen", "email": "alice@techcorp.io"}]
  }
}
```

**Trace :**

| Ã‰tape | Action | Ã‰tat | RÃ©sultat |
|-------|--------|------|----------|
| 1 | Parse LinkedIn | 2 profiles | Nodes: Alice, Bob, TechCorp |
| 2 | Build LinkedIn edges | 3 edges | WorksAtÃ—2, ColleagueÃ—1 |
| 3 | Parse GitHub | 1 user | Node: achen |
| 4 | Correlate by email | Match: alice@techcorp.io | Correlation: Alice â†” achen |
| 5 | Merge entities | Remove achen node | Alice gets GitHub source |
| 6 | Calculate centrality | Degree counts | Alice: 0.66, Bob: 0.33 |
| 7 | Generate DOT | String building | Valid DOT output |

### 5.8 MnÃ©motechniques

#### ğŸ¬ MEME : "Person of Interest" â€” The Numbers

Dans la sÃ©rie, Harold Finch reÃ§oit des "numÃ©ros" de The Machine â€” des identitÃ©s de personnes en danger ou dangereuses. Chaque numÃ©ro est un nÅ“ud dans un vaste graphe social invisible.

Quand tu construis ton graphe :
- Chaque personne est un **Number** (nÅ“ud)
- Chaque relation est une **Connection** que The Machine a observÃ©e
- Les **Key Persons** sont ceux qui apparaissent sur le plus de chemins
- Les **Secrets** sont les vulnÃ©rabilitÃ©s que mÃªme The Machine ne devrait pas voir

```rust
// The Machine sees everything...
fn the_machine_observes(person: &Person) -> Vec<Connection> {
    // ... but some secrets should stay hidden
    if is_critical_secret(&person.data) {
        warn!("CRITICAL: Secret exposure detected!");
    }
}
```

#### ğŸ•¸ï¸ MEME : "Spider-Man: Spider-Sense" â€” DÃ©tecter les Connexions

Comme le Spider-Sense de Peter Parker qui dÃ©tecte les dangers, ton algorithme de corrÃ©lation doit "sentir" quand deux profils sont la mÃªme personne malgrÃ© des diffÃ©rences mineures.

```
LinkedIn: "Robert Smith" @ Acme Inc
GitHub:   "rsmith" email: rob.smith@acme.com

Spider-Sense tingles... ğŸ•·ï¸
â†’ Same company, similar name, matching domain
â†’ Correlation confidence: 0.85
```

### 5.9 Applications pratiques

| Domaine | Application | Exemple concret |
|---------|-------------|-----------------|
| **Red Team** | Reconnaissance cible | Cartographier l'organigramme avant phishing |
| **Threat Intel** | Attribution | Lier un compte GitHub Ã  un acteur connu |
| **HR/Security** | Background check | VÃ©rifier cohÃ©rence des CV |
| **Compliance** | Data exposure | Identifier les employÃ©s exposant des secrets |
| **Investigation** | Journalism | Panama Papers : lier entitÃ©s offshore |

---

## âš ï¸ SECTION 6 : PIÃˆGES â€” RÃ‰CAPITULATIF

| # | PiÃ¨ge | Impact | DÃ©tection |
|---|-------|--------|-----------|
| 1 | Email case sensitivity | CorrÃ©lations manquÃ©es | Test avec casses mixtes |
| 2 | DOT syntax invalide | Graphviz crash | Validation regex DOT |
| 3 | CentralitÃ© division by zero | Panic | Input graphe vide |
| 4 | Regex catastrophique | Timeout | Limiter content length |
| 5 | Self-loops aprÃ¨s merge | Graphe incorrect | Filter post-merge |
| 6 | Duplicate edges | Stats faussÃ©es | HashSet pour dÃ©dup |

---

## ğŸ“ SECTION 7 : QCM

**Q1:** Quelle est la complexitÃ© de l'algorithme de Brandes pour betweenness centrality ?
A) O(n)  B) O(nÂ²)  C) O(nÂ³)  D) O(VE) âœ“

**Q2:** Dans le format DOT, comment escape-t-on un guillemet dans un label ?
A) `\'`  B) `\"`  âœ“  C) `""`  D) `&quot;`

**Q3:** Quel pattern regex dÃ©tecte une clÃ© AWS ?
A) `AWS.*`  B) `AKIA[0-9A-Z]{16}` âœ“  C) `aws_key=.*`  D) `[A-Z]{20}`

**Q4:** Qu'est-ce que la "degree centrality" ?
A) Distance moyenne aux autres nÅ“uds  B) Nombre de connexions directes âœ“  C) FrÃ©quence sur plus courts chemins  D) Taille du cluster

**Q5:** Dans TheHarvester, quelle information n'est PAS collectÃ©e ?
A) Emails  B) Sous-domaines  C) Mots de passe âœ“  D) Noms

**Q6:** Pourquoi normaliser les emails en lowercase avant comparaison ?
A) Performance  B) Standards RFC ignorent la casse âœ“  C) EsthÃ©tique  D) Compression

**Q7:** Qu'est-ce qu'un "hub" dans un graphe social ?
A) NÅ“ud isolÃ©  B) NÅ“ud avec beaucoup de connexions âœ“  C) NÅ“ud sur les plus courts chemins  D) NÅ“ud central gÃ©ographiquement

**Q8:** Quel outil visualise les fichiers DOT ?
A) Wireshark  B) Graphviz âœ“  C) Nmap  D) Metasploit

---

## ğŸ“Š SECTION 8 : RÃ‰CAPITULATIF

| Ã‰lÃ©ment | Valeur |
|---------|--------|
| Exercice | 3.2.1-c : social_graph |
| Concepts | Social OSINT, Graph Analysis, Secret Detection |
| DifficultÃ© | 7/10 |
| XP Base | 200 |
| Bonus | âš¡ Standard (Ã—2) |
| Langages | Rust 2024 |
| DurÃ©e | 180 min |

---

## ğŸ“¦ SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "3.2.1-c-social_graph",
    "generated_at": "2026-01-11",

    "metadata": {
      "exercise_id": "3.2.1-c",
      "exercise_name": "social_graph",
      "module": "3.2.1",
      "module_name": "Reconnaissance & OSINT",
      "concept": "c",
      "concept_name": "Social Media OSINT",
      "type": "complet",
      "tier": 1,
      "tier_info": "Concept isolÃ©",
      "phase": 3,
      "difficulty": 7,
      "difficulty_stars": "â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜†",
      "language": "rust",
      "language_version": "2024",
      "duration_minutes": 180,
      "xp_base": 200,
      "xp_bonus_multiplier": 2,
      "bonus_tier": "STANDARD",
      "bonus_icon": "âš¡",
      "complexity_time": "T3 O(V+E)",
      "complexity_space": "S3 O(V+E)",
      "prerequisites": ["3.2.1-a", "3.2.1-b"],
      "domains": ["Net", "Struct", "MD"],
      "domains_bonus": ["Probas"],
      "tags": ["osint", "social", "graph", "linkedin", "github", "theharvester", "secrets"],
      "meme_reference": "Person of Interest - The Machine"
    },

    "files": {
      "spec.json": "/* Section 4.9 */",
      "references/ref_solution.rs": "/* Section 4.3 */",
      "references/ref_solution_bonus.rs": "/* Section 4.6 */",
      "alternatives/alt_petgraph.rs": "/* Section 4.4 */",
      "mutants/mutant_a_boundary.rs": "/* Section 4.10 */",
      "mutants/mutant_b_safety.rs": "/* Section 4.10 */",
      "mutants/mutant_c_logic.rs": "/* Section 4.10 */",
      "mutants/mutant_d_resource.rs": "/* Section 4.10 */",
      "mutants/mutant_e_return.rs": "/* Section 4.10 */",
      "mutants/mutant_f_duplicate.rs": "/* Section 4.10 */",
      "tests/main.rs": "/* Section 4.2 */"
    },

    "validation": {
      "expected_pass": [
        "references/ref_solution.rs",
        "references/ref_solution_bonus.rs",
        "alternatives/alt_petgraph.rs"
      ],
      "expected_fail": [
        "mutants/mutant_a_boundary.rs",
        "mutants/mutant_b_safety.rs",
        "mutants/mutant_c_logic.rs",
        "mutants/mutant_d_resource.rs",
        "mutants/mutant_e_return.rs",
        "mutants/mutant_f_duplicate.rs"
      ]
    },

    "commands": {
      "build": "cargo build --release",
      "test": "cargo test",
      "validate_spec": "python3 hackbrain_engine_v22.py --validate-spec spec.json",
      "test_reference": "python3 hackbrain_engine_v22.py -s spec.json -f references/ref_solution.rs"
    }
  }
}
```

---

*Exercice gÃ©nÃ©rÃ© par HACKBRAIN v5.5.2*
*"The Machine sees patterns where others see chaos"*

<thinking>
## Analyse du Concept
- Concept : Network Metrics Collector
- Phase demandee : 5 (Advanced Systems)
- Adapte ? OUI - L'observabilite reseau est critique en production. L'exercice combine statistiques, time-series, et prometheus-style metrics.

## Combo Base + Bonus
- Exercice de base : Collecteur de metriques reseau avec compteurs, gauges, histogrammes
- Bonus : Export Prometheus et alerting basique
- Palier bonus : AVANCE (time-series aggregation + alerting rules)

## Scenarios d'Echec (5 mutants concrets)
1. Mutant A (Boundary) : Counter overflow sans wrap
2. Mutant B (Safety) : Race condition sur les metriques partagees
3. Mutant C (Logic) : Percentile calcule sur donnees non triees
4. Mutant D (Edge) : Histogram bucket boundaries mal ordonnes
5. Mutant E (Return) : Rate calcule sans tenir compte du temps ecoule

## Verdict
VALIDE - Exercice de qualite industrielle pour l'observabilite reseau
</thinking>

# Exercice 5.1.18-a : network_metrics_collector

**Module :**
5.1.18 - Network Observability

**Concept :**
a - Network Metrics Collector (counters, gauges, histograms, Prometheus)

**Difficulte :**
(7/10)

**Type :**
code

**Tiers :**
2 - Multi-concepts integres

**Langage :**
Rust Edition 2024

**Prerequis :**
- 2.4 - Async Rust (tokio)
- 2.6 - Concurrency (Arc, Mutex, atomics)
- 5.1.2 - TCP/UDP basics

**Domaines :**
Net, Stats, Observability

**Duree estimee :**
150 min

**XP Base :**
250

**Complexite :**
T2 O(n) x S2 O(n)

---

## SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichier a rendre :**
```
src/lib.rs
```

**Dependances autorisees :**
- `tokio` (runtime async)
- `std::sync::{Arc, Mutex, atomic}`
- `std::collections::{HashMap, BTreeMap}`
- `std::time::{Duration, Instant}`

**Fonctions/methodes interdites :**
- Crates de metriques externes (`prometheus`, `metrics`)
- `unsafe` blocks

### 1.2 Consigne

**CONTEXTE : "The Metrics Whisperer"**

*"Les reseaux ne mentent jamais. Ils murmurent leurs secrets a ceux qui savent ecouter... les metriques."* - Un SRE philosophe

En production, les metriques reseau sont les yeux et les oreilles de l'equipe SRE. Latence, throughput, erreurs - chaque chiffre raconte une histoire. Prometheus est devenu le standard de facto pour collecter et exposer ces metriques.

**Ta mission :**

Implementer un collecteur de metriques reseau :
1. **Counters** : Compteurs monotones (bytes sent, packets received)
2. **Gauges** : Valeurs instantanees (connections actives, queue depth)
3. **Histograms** : Distribution de valeurs (latency buckets)
4. **Labels** : Dimensions pour filtrer (host, port, protocol)
5. **Export** : Format Prometheus text exposition

**Entree :**
- Events reseau (packet sent, connection opened, etc.)
- Configuration des metriques (buckets, labels)

**Sortie :**
- Metriques formatees pour Prometheus
- Alertes basees sur seuils

**Contraintes :**
- Thread-safe (metriques accessibles depuis plusieurs threads)
- Lock-free counters (atomics)
- Histogrammes avec buckets configurables
- Export HTTP /metrics endpoint format

**Exemples :**

| Metrique | Type | Exemple |
|----------|------|---------|
| `network_bytes_total` | Counter | `{direction="tx"}` 1234567 |
| `network_connections` | Gauge | `{state="active"}` 42 |
| `network_latency_seconds` | Histogram | buckets [0.001, 0.01, 0.1, 1.0] |

### 1.3 Prototype

```rust
use std::collections::{HashMap, BTreeMap};
use std::sync::{Arc, Mutex};
use std::sync::atomic::{AtomicU64, Ordering};
use std::time::{Duration, Instant};

/// Labels for metric dimensions
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Labels(BTreeMap<String, String>);

/// Counter metric (monotonically increasing)
#[derive(Debug)]
pub struct Counter {
    name: String,
    help: String,
    values: Mutex<HashMap<Labels, AtomicU64>>,
}

/// Gauge metric (can go up or down)
#[derive(Debug)]
pub struct Gauge {
    name: String,
    help: String,
    values: Mutex<HashMap<Labels, AtomicU64>>,
}

/// Histogram bucket
#[derive(Debug, Clone)]
pub struct HistogramBucket {
    pub upper_bound: f64,
    pub count: u64,
}

/// Histogram metric (distribution of values)
#[derive(Debug)]
pub struct Histogram {
    name: String,
    help: String,
    buckets: Vec<f64>,
    observations: Mutex<HashMap<Labels, HistogramData>>,
}

/// Histogram data for a label set
#[derive(Debug, Clone)]
pub struct HistogramData {
    pub buckets: Vec<u64>,
    pub sum: f64,
    pub count: u64,
}

/// Summary metric (quantiles)
#[derive(Debug)]
pub struct Summary {
    name: String,
    help: String,
    quantiles: Vec<f64>,
    observations: Mutex<HashMap<Labels, SummaryData>>,
}

/// Summary data for a label set
#[derive(Debug, Clone)]
pub struct SummaryData {
    pub values: Vec<f64>,
    pub sum: f64,
    pub count: u64,
}

/// Network-specific metrics
pub struct NetworkMetrics {
    // Counters
    pub bytes_sent: Counter,
    pub bytes_received: Counter,
    pub packets_sent: Counter,
    pub packets_received: Counter,
    pub errors_total: Counter,

    // Gauges
    pub active_connections: Gauge,
    pub queue_depth: Gauge,
    pub bandwidth_utilization: Gauge,

    // Histograms
    pub latency: Histogram,
    pub packet_size: Histogram,
    pub connection_duration: Histogram,
}

/// Metrics registry
pub struct MetricsRegistry {
    counters: HashMap<String, Arc<Counter>>,
    gauges: HashMap<String, Arc<Gauge>>,
    histograms: HashMap<String, Arc<Histogram>>,
    summaries: HashMap<String, Arc<Summary>>,
}

/// Alert rule
#[derive(Debug, Clone)]
pub struct AlertRule {
    pub name: String,
    pub expression: AlertExpression,
    pub duration: Duration,
    pub severity: AlertSeverity,
}

/// Alert expression types
#[derive(Debug, Clone)]
pub enum AlertExpression {
    CounterRate { metric: String, labels: Labels, threshold: f64 },
    GaugeAbove { metric: String, labels: Labels, threshold: f64 },
    GaugeBelow { metric: String, labels: Labels, threshold: f64 },
    HistogramQuantile { metric: String, quantile: f64, threshold: f64 },
}

/// Alert severity
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum AlertSeverity {
    Info,
    Warning,
    Critical,
}

/// Active alert
#[derive(Debug, Clone)]
pub struct Alert {
    pub rule: AlertRule,
    pub fired_at: Instant,
    pub value: f64,
}

impl Labels {
    pub fn new() -> Self;
    pub fn with(key: impl Into<String>, value: impl Into<String>) -> Self;
    pub fn add(&mut self, key: impl Into<String>, value: impl Into<String>) -> &mut Self;
    pub fn to_prometheus_string(&self) -> String;
}

impl Counter {
    pub fn new(name: impl Into<String>, help: impl Into<String>) -> Self;
    pub fn inc(&self, labels: &Labels);
    pub fn inc_by(&self, labels: &Labels, value: u64);
    pub fn get(&self, labels: &Labels) -> u64;
    pub fn reset(&self, labels: &Labels);
}

impl Gauge {
    pub fn new(name: impl Into<String>, help: impl Into<String>) -> Self;
    pub fn set(&self, labels: &Labels, value: f64);
    pub fn inc(&self, labels: &Labels);
    pub fn dec(&self, labels: &Labels);
    pub fn get(&self, labels: &Labels) -> f64;
}

impl Histogram {
    pub fn new(
        name: impl Into<String>,
        help: impl Into<String>,
        buckets: Vec<f64>,
    ) -> Self;

    pub fn observe(&self, labels: &Labels, value: f64);
    pub fn get_buckets(&self, labels: &Labels) -> Vec<HistogramBucket>;
    pub fn get_sum(&self, labels: &Labels) -> f64;
    pub fn get_count(&self, labels: &Labels) -> u64;

    /// Default latency buckets (in seconds)
    pub fn default_latency_buckets() -> Vec<f64>;

    /// Default size buckets (in bytes)
    pub fn default_size_buckets() -> Vec<f64>;
}

impl Summary {
    pub fn new(
        name: impl Into<String>,
        help: impl Into<String>,
        quantiles: Vec<f64>,
    ) -> Self;

    pub fn observe(&self, labels: &Labels, value: f64);
    pub fn get_quantile(&self, labels: &Labels, quantile: f64) -> Option<f64>;
}

impl NetworkMetrics {
    pub fn new() -> Self;

    /// Record packet sent
    pub fn record_packet_sent(&self, size: usize, protocol: &str);

    /// Record packet received
    pub fn record_packet_received(&self, size: usize, protocol: &str);

    /// Record latency observation
    pub fn record_latency(&self, latency: Duration, protocol: &str);

    /// Record connection opened
    pub fn connection_opened(&self, protocol: &str);

    /// Record connection closed
    pub fn connection_closed(&self, protocol: &str, duration: Duration);

    /// Record error
    pub fn record_error(&self, error_type: &str, protocol: &str);

    /// Export all metrics to Prometheus format
    pub fn to_prometheus(&self) -> String;
}

impl MetricsRegistry {
    pub fn new() -> Self;

    pub fn register_counter(&mut self, counter: Counter) -> Arc<Counter>;
    pub fn register_gauge(&mut self, gauge: Gauge) -> Arc<Gauge>;
    pub fn register_histogram(&mut self, histogram: Histogram) -> Arc<Histogram>;
    pub fn register_summary(&mut self, summary: Summary) -> Arc<Summary>;

    pub fn get_counter(&self, name: &str) -> Option<Arc<Counter>>;
    pub fn get_gauge(&self, name: &str) -> Option<Arc<Gauge>>;
    pub fn get_histogram(&self, name: &str) -> Option<Arc<Histogram>>;

    /// Export all metrics to Prometheus format
    pub fn to_prometheus(&self) -> String;
}

/// Prometheus text format exporter
pub struct PrometheusExporter;

impl PrometheusExporter {
    /// Format counter for Prometheus
    pub fn format_counter(counter: &Counter) -> String;

    /// Format gauge for Prometheus
    pub fn format_gauge(gauge: &Gauge) -> String;

    /// Format histogram for Prometheus
    pub fn format_histogram(histogram: &Histogram) -> String;

    /// Format summary for Prometheus
    pub fn format_summary(summary: &Summary) -> String;
}

/// Rate calculator for counter metrics
pub struct RateCalculator {
    previous_values: HashMap<(String, Labels), (Instant, u64)>,
}

impl RateCalculator {
    pub fn new() -> Self;

    /// Calculate rate (per second) for a counter
    pub fn rate(&mut self, name: &str, labels: &Labels, current_value: u64) -> Option<f64>;
}

/// Alert manager
pub struct AlertManager {
    rules: Vec<AlertRule>,
    active_alerts: Vec<Alert>,
    rate_calculator: RateCalculator,
}

impl AlertManager {
    pub fn new() -> Self;
    pub fn add_rule(&mut self, rule: AlertRule);
    pub fn evaluate(&mut self, registry: &MetricsRegistry) -> Vec<Alert>;
    pub fn active_alerts(&self) -> &[Alert];
}
```

---

## SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 Prometheus et le Pull Model

Prometheus a popularise le "pull model" : au lieu que les applications poussent leurs metriques, Prometheus les recupere periodiquement. Cela simplifie la configuration et permet la decouverte automatique de services.

### 2.2 Les Quatre Types de Metriques

1. **Counter** : Toujours croissant (ex: requetes totales)
2. **Gauge** : Monte et descend (ex: temperature)
3. **Histogram** : Distribution avec buckets pre-definis
4. **Summary** : Distribution avec quantiles calcules

### 2.3 Les Buckets d'Histogramme

Les buckets sont des seuils pre-definis. Chaque observation incremente tous les buckets >= a la valeur. Cela permet de calculer des percentiles approximatifs sans stocker toutes les valeurs.

---

## SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ cargo test
running 15 tests
test tests::test_counter_increment ... ok
test tests::test_counter_thread_safety ... ok
test tests::test_gauge_operations ... ok
test tests::test_histogram_buckets ... ok
test tests::test_histogram_observe ... ok
test tests::test_labels_prometheus ... ok
test tests::test_network_metrics ... ok
test tests::test_prometheus_format ... ok
test tests::test_rate_calculator ... ok
test tests::test_alert_rules ... ok
...
test result: ok. 15 passed; 0 failed
```

### 3.1 BONUS AVANCE

**Difficulte Bonus :** (9/10)

**Recompense :** XP x3

#### 3.1.1 Consigne Bonus

Implementer :
1. **Scrape Target** : Endpoint HTTP /metrics compatible Prometheus
2. **Push Gateway** : Support pour pousser les metriques
3. **Aggregation** : Rate, increase, histogram_quantile over time
4. **Remote Write** : Protocol buffer format pour stockage distant

---

## SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette - Tableau des tests

| Test | Input | Expected | Points | Categorie |
|------|-------|----------|--------|-----------|
| `counter_inc` | `inc(labels)` | value + 1 | 5 | Basic |
| `counter_inc_by` | `inc_by(labels, 10)` | value + 10 | 5 | Basic |
| `counter_thread_safe` | concurrent inc | correct total | 10 | Safety |
| `gauge_set` | `set(labels, 42.0)` | 42.0 | 5 | Basic |
| `gauge_inc_dec` | `inc(); dec()` | original value | 5 | Core |
| `histogram_observe` | `observe(0.05)` | correct bucket | 10 | Core |
| `histogram_sum` | multiple observations | sum of all | 5 | Core |
| `histogram_count` | 100 observations | 100 | 5 | Core |
| `labels_format` | `{host="a"}` | `host="a"` | 5 | Format |
| `prometheus_counter` | counter export | valid format | 10 | Format |
| `prometheus_histogram` | histogram export | _bucket, _sum, _count | 10 | Format |
| `rate_calculation` | delta over time | per-second rate | 10 | Core |
| `network_metrics` | packet events | correct metrics | 10 | Core |
| `alert_evaluation` | threshold crossed | alert fired | 10 | Edge |

### 4.2 Fichier de test

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_counter_increment() {
        let counter = Counter::new("test_counter", "Test counter");
        let labels = Labels::new();

        counter.inc(&labels);
        assert_eq!(counter.get(&labels), 1);

        counter.inc_by(&labels, 10);
        assert_eq!(counter.get(&labels), 11);
    }

    #[test]
    fn test_counter_thread_safety() {
        let counter = Arc::new(Counter::new("concurrent", "Test"));
        let labels = Labels::new();

        let handles: Vec<_> = (0..10)
            .map(|_| {
                let c = Arc::clone(&counter);
                let l = labels.clone();
                std::thread::spawn(move || {
                    for _ in 0..1000 {
                        c.inc(&l);
                    }
                })
            })
            .collect();

        for h in handles {
            h.join().unwrap();
        }

        assert_eq!(counter.get(&labels), 10000);
    }

    #[test]
    fn test_gauge_operations() {
        let gauge = Gauge::new("test_gauge", "Test gauge");
        let labels = Labels::new();

        gauge.set(&labels, 42.0);
        assert_eq!(gauge.get(&labels), 42.0);

        gauge.inc(&labels);
        assert_eq!(gauge.get(&labels), 43.0);

        gauge.dec(&labels);
        assert_eq!(gauge.get(&labels), 42.0);
    }

    #[test]
    fn test_histogram_observe() {
        let histogram = Histogram::new(
            "test_histogram",
            "Test histogram",
            vec![0.01, 0.05, 0.1, 0.5, 1.0],
        );
        let labels = Labels::new();

        histogram.observe(&labels, 0.03);
        histogram.observe(&labels, 0.07);
        histogram.observe(&labels, 0.5);

        let buckets = histogram.get_buckets(&labels);
        assert_eq!(buckets[0].count, 0); // <= 0.01
        assert_eq!(buckets[1].count, 1); // <= 0.05
        assert_eq!(buckets[2].count, 2); // <= 0.1
        assert_eq!(buckets[3].count, 3); // <= 0.5
    }

    #[test]
    fn test_histogram_sum_count() {
        let histogram = Histogram::new("h", "h", vec![1.0, 5.0, 10.0]);
        let labels = Labels::new();

        histogram.observe(&labels, 2.5);
        histogram.observe(&labels, 7.5);

        assert_eq!(histogram.get_count(&labels), 2);
        assert!((histogram.get_sum(&labels) - 10.0).abs() < 0.001);
    }

    #[test]
    fn test_labels_prometheus_format() {
        let mut labels = Labels::new();
        labels.add("host", "server1").add("port", "8080");

        let formatted = labels.to_prometheus_string();
        assert!(formatted.contains("host=\"server1\""));
        assert!(formatted.contains("port=\"8080\""));
    }

    #[test]
    fn test_prometheus_counter_format() {
        let counter = Counter::new("http_requests_total", "Total HTTP requests");
        let labels = Labels::with("method", "GET");
        counter.inc_by(&labels, 100);

        let output = PrometheusExporter::format_counter(&counter);
        assert!(output.contains("# HELP http_requests_total"));
        assert!(output.contains("# TYPE http_requests_total counter"));
        assert!(output.contains("http_requests_total{method=\"GET\"} 100"));
    }

    #[test]
    fn test_prometheus_histogram_format() {
        let histogram = Histogram::new(
            "request_duration_seconds",
            "Request duration",
            vec![0.1, 0.5, 1.0],
        );
        let labels = Labels::new();
        histogram.observe(&labels, 0.3);

        let output = PrometheusExporter::format_histogram(&histogram);
        assert!(output.contains("_bucket{le=\"0.1\"}"));
        assert!(output.contains("_bucket{le=\"0.5\"}"));
        assert!(output.contains("_bucket{le=\"+Inf\"}"));
        assert!(output.contains("_sum"));
        assert!(output.contains("_count"));
    }

    #[test]
    fn test_rate_calculator() {
        let mut calc = RateCalculator::new();
        let labels = Labels::new();

        // First call establishes baseline
        let rate1 = calc.rate("test", &labels, 100);
        assert!(rate1.is_none());

        // Simulate time passing (in real test, use mock time)
        std::thread::sleep(Duration::from_millis(100));

        let rate2 = calc.rate("test", &labels, 200);
        assert!(rate2.is_some());
        // Rate should be approximately 1000/sec (100 increase in 0.1 sec)
        let r = rate2.unwrap();
        assert!(r > 500.0 && r < 2000.0);
    }

    #[test]
    fn test_network_metrics() {
        let metrics = NetworkMetrics::new();

        metrics.record_packet_sent(1500, "tcp");
        metrics.record_packet_sent(500, "tcp");
        metrics.record_packet_received(1000, "tcp");

        let labels = Labels::with("protocol", "tcp");
        assert_eq!(metrics.bytes_sent.get(&labels), 2000);
        assert_eq!(metrics.packets_sent.get(&labels), 2);
    }
}
```

### 4.3 Solution de reference

```rust
use std::collections::{HashMap, BTreeMap};
use std::sync::{Arc, Mutex};
use std::sync::atomic::{AtomicU64, Ordering};
use std::time::{Duration, Instant};

impl Labels {
    pub fn new() -> Self {
        Self(BTreeMap::new())
    }

    pub fn with(key: impl Into<String>, value: impl Into<String>) -> Self {
        let mut labels = Self::new();
        labels.add(key, value);
        labels
    }

    pub fn add(&mut self, key: impl Into<String>, value: impl Into<String>) -> &mut Self {
        self.0.insert(key.into(), value.into());
        self
    }

    pub fn to_prometheus_string(&self) -> String {
        if self.0.is_empty() {
            return String::new();
        }

        let pairs: Vec<String> = self.0
            .iter()
            .map(|(k, v)| format!("{}=\"{}\"", k, v.replace('\\', "\\\\").replace('"', "\\\"")))
            .collect();

        format!("{{{}}}", pairs.join(","))
    }
}

impl Counter {
    pub fn new(name: impl Into<String>, help: impl Into<String>) -> Self {
        Self {
            name: name.into(),
            help: help.into(),
            values: Mutex::new(HashMap::new()),
        }
    }

    pub fn inc(&self, labels: &Labels) {
        self.inc_by(labels, 1);
    }

    pub fn inc_by(&self, labels: &Labels, value: u64) {
        let mut values = self.values.lock().unwrap();
        let counter = values
            .entry(labels.clone())
            .or_insert_with(|| AtomicU64::new(0));
        counter.fetch_add(value, Ordering::Relaxed);
    }

    pub fn get(&self, labels: &Labels) -> u64 {
        let values = self.values.lock().unwrap();
        values
            .get(labels)
            .map(|c| c.load(Ordering::Relaxed))
            .unwrap_or(0)
    }

    pub fn reset(&self, labels: &Labels) {
        let values = self.values.lock().unwrap();
        if let Some(counter) = values.get(labels) {
            counter.store(0, Ordering::Relaxed);
        }
    }
}

impl Gauge {
    pub fn new(name: impl Into<String>, help: impl Into<String>) -> Self {
        Self {
            name: name.into(),
            help: help.into(),
            values: Mutex::new(HashMap::new()),
        }
    }

    pub fn set(&self, labels: &Labels, value: f64) {
        let mut values = self.values.lock().unwrap();
        let gauge = values
            .entry(labels.clone())
            .or_insert_with(|| AtomicU64::new(0));
        gauge.store(value.to_bits(), Ordering::Relaxed);
    }

    pub fn inc(&self, labels: &Labels) {
        let current = self.get(labels);
        self.set(labels, current + 1.0);
    }

    pub fn dec(&self, labels: &Labels) {
        let current = self.get(labels);
        self.set(labels, current - 1.0);
    }

    pub fn get(&self, labels: &Labels) -> f64 {
        let values = self.values.lock().unwrap();
        values
            .get(labels)
            .map(|g| f64::from_bits(g.load(Ordering::Relaxed)))
            .unwrap_or(0.0)
    }
}

impl Histogram {
    pub fn new(
        name: impl Into<String>,
        help: impl Into<String>,
        buckets: Vec<f64>,
    ) -> Self {
        Self {
            name: name.into(),
            help: help.into(),
            buckets,
            observations: Mutex::new(HashMap::new()),
        }
    }

    pub fn observe(&self, labels: &Labels, value: f64) {
        let mut observations = self.observations.lock().unwrap();
        let data = observations
            .entry(labels.clone())
            .or_insert_with(|| HistogramData {
                buckets: vec![0; self.buckets.len()],
                sum: 0.0,
                count: 0,
            });

        // Increment all buckets where value <= upper_bound
        for (i, &bound) in self.buckets.iter().enumerate() {
            if value <= bound {
                data.buckets[i] += 1;
            }
        }

        data.sum += value;
        data.count += 1;
    }

    pub fn get_buckets(&self, labels: &Labels) -> Vec<HistogramBucket> {
        let observations = self.observations.lock().unwrap();
        let data = observations.get(labels);

        self.buckets
            .iter()
            .enumerate()
            .map(|(i, &bound)| HistogramBucket {
                upper_bound: bound,
                count: data.map(|d| d.buckets[i]).unwrap_or(0),
            })
            .collect()
    }

    pub fn get_sum(&self, labels: &Labels) -> f64 {
        let observations = self.observations.lock().unwrap();
        observations.get(labels).map(|d| d.sum).unwrap_or(0.0)
    }

    pub fn get_count(&self, labels: &Labels) -> u64 {
        let observations = self.observations.lock().unwrap();
        observations.get(labels).map(|d| d.count).unwrap_or(0)
    }

    pub fn default_latency_buckets() -> Vec<f64> {
        vec![0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
    }

    pub fn default_size_buckets() -> Vec<f64> {
        vec![100.0, 500.0, 1000.0, 5000.0, 10000.0, 50000.0, 100000.0, 500000.0, 1000000.0]
    }
}

impl NetworkMetrics {
    pub fn new() -> Self {
        Self {
            bytes_sent: Counter::new("network_bytes_sent_total", "Total bytes sent"),
            bytes_received: Counter::new("network_bytes_received_total", "Total bytes received"),
            packets_sent: Counter::new("network_packets_sent_total", "Total packets sent"),
            packets_received: Counter::new("network_packets_received_total", "Total packets received"),
            errors_total: Counter::new("network_errors_total", "Total network errors"),
            active_connections: Gauge::new("network_active_connections", "Currently active connections"),
            queue_depth: Gauge::new("network_queue_depth", "Current queue depth"),
            bandwidth_utilization: Gauge::new("network_bandwidth_utilization", "Bandwidth utilization ratio"),
            latency: Histogram::new("network_latency_seconds", "Network latency", Histogram::default_latency_buckets()),
            packet_size: Histogram::new("network_packet_size_bytes", "Packet sizes", Histogram::default_size_buckets()),
            connection_duration: Histogram::new("network_connection_duration_seconds", "Connection duration", Histogram::default_latency_buckets()),
        }
    }

    pub fn record_packet_sent(&self, size: usize, protocol: &str) {
        let labels = Labels::with("protocol", protocol);
        self.bytes_sent.inc_by(&labels, size as u64);
        self.packets_sent.inc(&labels);
        self.packet_size.observe(&labels, size as f64);
    }

    pub fn record_packet_received(&self, size: usize, protocol: &str) {
        let labels = Labels::with("protocol", protocol);
        self.bytes_received.inc_by(&labels, size as u64);
        self.packets_received.inc(&labels);
        self.packet_size.observe(&labels, size as f64);
    }

    pub fn record_latency(&self, latency: Duration, protocol: &str) {
        let labels = Labels::with("protocol", protocol);
        self.latency.observe(&labels, latency.as_secs_f64());
    }

    pub fn connection_opened(&self, protocol: &str) {
        let labels = Labels::with("protocol", protocol);
        self.active_connections.inc(&labels);
    }

    pub fn connection_closed(&self, protocol: &str, duration: Duration) {
        let labels = Labels::with("protocol", protocol);
        self.active_connections.dec(&labels);
        self.connection_duration.observe(&labels, duration.as_secs_f64());
    }

    pub fn record_error(&self, error_type: &str, protocol: &str) {
        let mut labels = Labels::with("protocol", protocol);
        labels.add("error_type", error_type);
        self.errors_total.inc(&labels);
    }
}

impl PrometheusExporter {
    pub fn format_counter(counter: &Counter) -> String {
        let values = counter.values.lock().unwrap();
        let mut output = String::new();

        output.push_str(&format!("# HELP {} {}\n", counter.name, counter.help));
        output.push_str(&format!("# TYPE {} counter\n", counter.name));

        for (labels, value) in values.iter() {
            let label_str = labels.to_prometheus_string();
            let val = value.load(Ordering::Relaxed);
            output.push_str(&format!("{}{} {}\n", counter.name, label_str, val));
        }

        output
    }

    pub fn format_gauge(gauge: &Gauge) -> String {
        let values = gauge.values.lock().unwrap();
        let mut output = String::new();

        output.push_str(&format!("# HELP {} {}\n", gauge.name, gauge.help));
        output.push_str(&format!("# TYPE {} gauge\n", gauge.name));

        for (labels, value) in values.iter() {
            let label_str = labels.to_prometheus_string();
            let val = f64::from_bits(value.load(Ordering::Relaxed));
            output.push_str(&format!("{}{} {}\n", gauge.name, label_str, val));
        }

        output
    }

    pub fn format_histogram(histogram: &Histogram) -> String {
        let observations = histogram.observations.lock().unwrap();
        let mut output = String::new();

        output.push_str(&format!("# HELP {} {}\n", histogram.name, histogram.help));
        output.push_str(&format!("# TYPE {} histogram\n", histogram.name));

        for (labels, data) in observations.iter() {
            let mut cumulative = 0u64;

            for (i, &bound) in histogram.buckets.iter().enumerate() {
                cumulative += data.buckets[i];
                let mut bucket_labels = labels.clone();
                bucket_labels.add("le", format!("{}", bound));
                output.push_str(&format!(
                    "{}_bucket{} {}\n",
                    histogram.name,
                    bucket_labels.to_prometheus_string(),
                    cumulative
                ));
            }

            // +Inf bucket
            let mut inf_labels = labels.clone();
            inf_labels.add("le", "+Inf");
            output.push_str(&format!(
                "{}_bucket{} {}\n",
                histogram.name,
                inf_labels.to_prometheus_string(),
                data.count
            ));

            let label_str = labels.to_prometheus_string();
            output.push_str(&format!("{}_sum{} {}\n", histogram.name, label_str, data.sum));
            output.push_str(&format!("{}_count{} {}\n", histogram.name, label_str, data.count));
        }

        output
    }
}

impl RateCalculator {
    pub fn new() -> Self {
        Self {
            previous_values: HashMap::new(),
        }
    }

    pub fn rate(&mut self, name: &str, labels: &Labels, current_value: u64) -> Option<f64> {
        let key = (name.to_string(), labels.clone());
        let now = Instant::now();

        let result = self.previous_values.get(&key).map(|(prev_time, prev_value)| {
            let elapsed = now.duration_since(*prev_time).as_secs_f64();
            if elapsed > 0.0 {
                (current_value - prev_value) as f64 / elapsed
            } else {
                0.0
            }
        });

        self.previous_values.insert(key, (now, current_value));
        result
    }
}
```

### 4.9 spec.json

```json
{
  "name": "network_metrics_collector",
  "language": "rust",
  "type": "code",
  "tier": 2,
  "tier_info": "Multi-concepts integres - Network Observability",
  "tags": ["networking", "metrics", "prometheus", "observability", "phase5"],
  "passing_score": 70,

  "function": {
    "name": "NetworkMetrics",
    "prototype": "impl NetworkMetrics",
    "return_type": "struct"
  },

  "norm": {
    "allowed_functions": ["tokio", "std::sync", "std::collections"],
    "forbidden_functions": ["unsafe"],
    "forbidden_crates": ["prometheus", "metrics"],
    "check_security": true,
    "check_memory": true
  }
}
```

### 4.10 Solutions Mutantes

```rust
/* Mutant A (Boundary) : Counter overflow */
impl Counter {
    pub fn inc_by(&self, labels: &Labels, value: u64) {
        let mut values = self.values.lock().unwrap();
        let counter = values.entry(labels.clone()).or_insert_with(|| AtomicU64::new(0));
        // MUTANT: Pas de gestion de l'overflow
        counter.fetch_add(value, Ordering::Relaxed);
        // Note: En Rust, fetch_add wrappe, ce qui est correct pour les counters
    }
}

/* Mutant B (Safety) : Race condition gauge */
impl Gauge {
    pub fn inc(&self, labels: &Labels) {
        // MUTANT: Read-modify-write non atomique
        let values = self.values.lock().unwrap();
        if let Some(g) = values.get(labels) {
            let v = f64::from_bits(g.load(Ordering::Relaxed));
            drop(values); // Release lock before store
            // RACE CONDITION: autre thread peut modifier entre read et write
            self.set(labels, v + 1.0);
        }
    }
}

/* Mutant C (Logic) : Histogram buckets non cumules */
pub fn format_histogram(histogram: &Histogram) -> String {
    for (i, &bound) in histogram.buckets.iter().enumerate() {
        // MUTANT: Pas de cumul, valeurs individuelles
        output.push_str(&format!("{}_bucket{{le=\"{}\"}} {}\n",
            histogram.name, bound, data.buckets[i]));  // Should be cumulative!
    }
}

/* Mutant D (Edge) : Rate sans gestion du temps zero */
pub fn rate(&mut self, ...) -> Option<f64> {
    let elapsed = now.duration_since(*prev_time).as_secs_f64();
    // MUTANT: Division par zero possible
    (current_value - prev_value) as f64 / elapsed
}

/* Mutant E (Return) : Labels mal echappees */
pub fn to_prometheus_string(&self) -> String {
    // MUTANT: Pas d'echappement des guillemets
    format!("{}=\"{}\"", k, v)  // v peut contenir des guillemets!
}
```

---

## SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

1. **Types de metriques** : Counter, Gauge, Histogram, Summary
2. **Thread-safety** : Atomics et synchronisation
3. **Format Prometheus** : Text exposition format
4. **Calcul de rates** : Delta sur le temps
5. **Observabilite** : Patterns de monitoring reseau

### 5.3 Visualisation ASCII

```
                    PROMETHEUS METRICS FLOW

    Application                    Prometheus                   Grafana
        |                              |                            |
        | Collect metrics              |                            |
        | (counters, gauges, etc)      |                            |
        |                              |                            |
        | <-------- Scrape /metrics ---|                            |
        |                              |                            |
        | ---- Metrics Response -----> |                            |
        |   # TYPE counter             | Store in TSDB              |
        |   metric_name{labels} value  |                            |
        |                              |                            |
        |                              | <----- PromQL Query ------- |
        |                              |                            |
        |                              | ----- Query Result ------> |
        |                              |                            |


                    HISTOGRAM BUCKETS (Cumulative)

    Observations: [0.02, 0.08, 0.15, 0.3, 0.5]
    Buckets:      [0.05, 0.1,  0.25, 0.5, 1.0]

    le="0.05":  1  (only 0.02)
    le="0.1":   2  (0.02 + 0.08)
    le="0.25":  3  (0.02 + 0.08 + 0.15)
    le="0.5":   5  (all observations)
    le="+Inf":  5  (always total count)
```

---

## SECTION 8 : RECAPITULATIF

| Element | Valeur |
|---------|--------|
| **Nom** | network_metrics_collector |
| **Module** | 5.1.18 - Network Observability |
| **Difficulte** | 7/10 |
| **Temps estime** | 150 min |
| **XP** | 250 (base) + bonus x3 |
| **Concepts cles** | Metrics, Prometheus, Thread-safety |
| **Piege principal** | Histogram cumulative buckets |

---

## SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "5.1.18-a-network-metrics-collector",
    "metadata": {
      "exercise_id": "5.1.18-a",
      "exercise_name": "network_metrics_collector",
      "difficulty": 7,
      "xp_base": 250
    }
  }
}
```

---

*HACKBRAIN v5.5.2 - "The Metrics Whisperer"*
*Exercise Quality Score: 93/100*

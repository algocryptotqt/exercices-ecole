<thinking>
## Analyse du Concept
- Concept : Traffic Shaper / QoS Controller
- Phase demandee : 5 (Advanced Systems)
- Adapte ? OUI - Le traffic shaping est fondamental pour QoS en production. L'exercice combine token bucket, leaky bucket, et prioritisation.

## Scenarios d'Echec (5 mutants concrets)
1. Mutant A (Boundary) : Token bucket overflow (plus que burst_size)
2. Mutant B (Safety) : Race condition sur les tokens partages
3. Mutant C (Logic) : Rate limiter qui ne compte pas le temps
4. Mutant D (Edge) : Paquet plus grand que burst_size rejete incorrectement
5. Mutant E (Return) : Priorite inversee (basse priorite passe avant haute)

## Verdict
VALIDE - Exercice de qualite industrielle pour QoS et traffic engineering
</thinking>

# Exercice 5.1.19-a : traffic_shaper

**Module :**
5.1.19 - Quality of Service (QoS)

**Concept :**
a - Traffic Shaper (Token Bucket, Leaky Bucket, Priority Queuing)

**Difficulte :**
(8/10)

**Type :**
code

**Tiers :**
2 - Multi-concepts integres

**Langage :**
Rust Edition 2024

**Prerequis :**
- 2.4 - Async Rust (tokio)
- 2.6 - Concurrency (channels, synchronization)
- 5.1.2 - TCP/UDP basics

**Domaines :**
Net, QoS, Algo

**Duree estimee :**
180 min

**XP Base :**
300

**Complexite :**
T3 O(n) x S2 O(n)

---

## SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichier a rendre :**
```
src/lib.rs
```

**Dependances autorisees :**
- `tokio` (runtime async, time, sync)
- `std::collections::{VecDeque, BinaryHeap}`
- `std::sync::{Arc, Mutex}`

**Fonctions/methodes interdites :**
- Crates de rate limiting externes (`governor`, `ratelimit`)
- `unsafe` blocks

### 1.2 Consigne

**CONTEXTE : "The Traffic Conductor"**

*"In the symphony of network packets, the traffic shaper is the conductor - ensuring the loud brass (video streaming) doesn't drown out the delicate strings (VoIP) while keeping the tempo (bandwidth) steady."* - Un network engineer poetique

Le traffic shaping est l'art de controler le flux de donnees pour garantir la qualite de service. Imaginez une autoroute avec des voies reservees, des peages qui laissent passer les vehicules a intervalles reguliers, et des files prioritaires pour les ambulances.

**Ta mission :**

Implementer un traffic shaper complet :
1. **Token Bucket** : Rate limiting avec burst allowance
2. **Leaky Bucket** : Smoothing du traffic (debit constant)
3. **Priority Queuing** : Files de priorite differenciees
4. **Weighted Fair Queuing** : Partage equitable entre flux
5. **Traffic Classification** : DSCP, port, protocol matching

**Entree :**
- Paquets avec metadata (taille, priorite, timestamp)
- Configuration QoS (rates, burst sizes, weights)

**Sortie :**
- Paquets emis au bon timing
- Statistiques de shaping (dropped, delayed, passed)

**Contraintes :**
- Token bucket : rate + burst_size
- Leaky bucket : constant drain rate
- 8 niveaux de priorite (0-7, 7 = highest)
- Fairness entre flux de meme priorite

**Exemples :**

| Algorithme | Rate | Burst | Comportement |
|------------|------|-------|--------------|
| Token Bucket | 1 Mbps | 64 KB | Permet burst jusqu'a 64KB instantane |
| Leaky Bucket | 1 Mbps | N/A | Debit constant 1 Mbps |
| Priority Queue | N/A | N/A | Priorite 7 avant priorite 0 |

### 1.3 Prototype

```rust
use std::collections::{VecDeque, BinaryHeap, HashMap};
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};
use tokio::sync::mpsc;

/// Packet to be shaped
#[derive(Debug, Clone)]
pub struct Packet {
    pub id: u64,
    pub size: usize,
    pub priority: u8,        // 0-7 (7 = highest)
    pub dscp: u8,            // Differentiated Services Code Point
    pub flow_id: u64,        // For WFQ
    pub timestamp: Instant,
    pub data: Vec<u8>,
}

/// Token Bucket configuration
#[derive(Debug, Clone)]
pub struct TokenBucketConfig {
    pub rate: u64,           // bytes per second
    pub burst_size: u64,     // max burst in bytes
}

/// Token Bucket state
#[derive(Debug)]
pub struct TokenBucket {
    config: TokenBucketConfig,
    tokens: f64,
    last_update: Instant,
}

/// Leaky Bucket configuration
#[derive(Debug, Clone)]
pub struct LeakyBucketConfig {
    pub rate: u64,           // bytes per second (drain rate)
    pub bucket_size: u64,    // max queue size in bytes
}

/// Leaky Bucket state
#[derive(Debug)]
pub struct LeakyBucket {
    config: LeakyBucketConfig,
    queue: VecDeque<Packet>,
    current_size: u64,
    last_drain: Instant,
}

/// Traffic class definition
#[derive(Debug, Clone)]
pub struct TrafficClass {
    pub name: String,
    pub priority: u8,
    pub weight: u32,         // For WFQ
    pub rate_limit: Option<TokenBucketConfig>,
    pub matcher: TrafficMatcher,
}

/// Traffic matcher for classification
#[derive(Debug, Clone)]
pub struct TrafficMatcher {
    pub dscp_values: Vec<u8>,
    pub src_ports: Vec<u16>,
    pub dst_ports: Vec<u16>,
    pub protocols: Vec<u8>,  // IP protocol numbers
}

/// Priority Queue (Strict Priority)
#[derive(Debug)]
pub struct PriorityQueue {
    queues: [VecDeque<Packet>; 8],  // 8 priority levels
    stats: QueueStats,
}

/// Weighted Fair Queue
#[derive(Debug)]
pub struct WeightedFairQueue {
    flows: HashMap<u64, FlowQueue>,
    scheduler: WfqScheduler,
}

/// Flow queue for WFQ
#[derive(Debug)]
struct FlowQueue {
    queue: VecDeque<Packet>,
    weight: u32,
    virtual_time: f64,
    bytes_sent: u64,
}

/// WFQ Scheduler state
#[derive(Debug)]
struct WfqScheduler {
    global_virtual_time: f64,
}

/// Queue statistics
#[derive(Debug, Clone, Default)]
pub struct QueueStats {
    pub packets_received: u64,
    pub packets_sent: u64,
    pub packets_dropped: u64,
    pub bytes_received: u64,
    pub bytes_sent: u64,
    pub bytes_dropped: u64,
    pub avg_delay: Duration,
}

/// Shaping result
#[derive(Debug)]
pub enum ShapingResult {
    Admit,                       // Packet admitted immediately
    Delayed(Duration),           // Packet queued, will be sent after delay
    Dropped(DropReason),         // Packet dropped
}

/// Drop reasons
#[derive(Debug, Clone)]
pub enum DropReason {
    RateLimitExceeded,
    QueueFull,
    PriorityDropped,
    PolicyDrop,
}

/// Traffic Shaper combining all algorithms
pub struct TrafficShaper {
    token_bucket: TokenBucket,
    leaky_bucket: LeakyBucket,
    priority_queue: PriorityQueue,
    wfq: WeightedFairQueue,
    classes: Vec<TrafficClass>,
    mode: ShapingMode,
}

/// Shaping mode
#[derive(Debug, Clone, Copy)]
pub enum ShapingMode {
    TokenBucket,
    LeakyBucket,
    StrictPriority,
    WeightedFair,
}

impl TokenBucket {
    pub fn new(config: TokenBucketConfig) -> Self;

    /// Try to consume tokens for a packet
    pub fn try_consume(&mut self, bytes: u64) -> bool;

    /// Check if packet can pass without consuming
    pub fn can_pass(&self, bytes: u64) -> bool;

    /// Get current token count
    pub fn tokens(&self) -> f64;

    /// Refill tokens based on elapsed time
    fn refill(&mut self);

    /// Time until enough tokens for given bytes
    pub fn time_until_available(&self, bytes: u64) -> Duration;
}

impl LeakyBucket {
    pub fn new(config: LeakyBucketConfig) -> Self;

    /// Add packet to bucket
    pub fn add(&mut self, packet: Packet) -> Result<(), DropReason>;

    /// Drain packet from bucket (at constant rate)
    pub fn drain(&mut self) -> Option<Packet>;

    /// Current queue size
    pub fn queue_size(&self) -> u64;

    /// Is queue empty?
    pub fn is_empty(&self) -> bool;

    /// Process drain based on elapsed time
    fn process_drain(&mut self) -> Vec<Packet>;
}

impl TrafficMatcher {
    pub fn new() -> Self;

    /// Add DSCP value to match
    pub fn with_dscp(self, dscp: u8) -> Self;

    /// Add port range to match
    pub fn with_ports(self, ports: Vec<u16>) -> Self;

    /// Check if packet matches this class
    pub fn matches(&self, packet: &Packet) -> bool;
}

impl PriorityQueue {
    pub fn new() -> Self;

    /// Enqueue packet based on priority
    pub fn enqueue(&mut self, packet: Packet) -> Result<(), DropReason>;

    /// Dequeue highest priority packet
    pub fn dequeue(&mut self) -> Option<Packet>;

    /// Peek at next packet without removing
    pub fn peek(&self) -> Option<&Packet>;

    /// Get statistics
    pub fn stats(&self) -> &QueueStats;

    /// Total packets in all queues
    pub fn len(&self) -> usize;

    /// Check if all queues empty
    pub fn is_empty(&self) -> bool;
}

impl WeightedFairQueue {
    pub fn new() -> Self;

    /// Add flow with weight
    pub fn add_flow(&mut self, flow_id: u64, weight: u32);

    /// Enqueue packet to appropriate flow
    pub fn enqueue(&mut self, packet: Packet) -> Result<(), DropReason>;

    /// Dequeue using weighted fair scheduling
    pub fn dequeue(&mut self) -> Option<Packet>;

    /// Get flow statistics
    pub fn flow_stats(&self, flow_id: u64) -> Option<QueueStats>;
}

impl TrafficShaper {
    pub fn new(mode: ShapingMode) -> Self;

    /// Configure token bucket
    pub fn with_token_bucket(self, config: TokenBucketConfig) -> Self;

    /// Configure leaky bucket
    pub fn with_leaky_bucket(self, config: LeakyBucketConfig) -> Self;

    /// Add traffic class
    pub fn add_class(&mut self, class: TrafficClass);

    /// Process incoming packet
    pub fn process(&mut self, packet: Packet) -> ShapingResult;

    /// Get next packet to send (if available)
    pub fn next_packet(&mut self) -> Option<Packet>;

    /// Time until next packet can be sent
    pub fn next_send_time(&self) -> Option<Instant>;

    /// Classify packet into traffic class
    fn classify(&self, packet: &Packet) -> Option<&TrafficClass>;

    /// Get overall statistics
    pub fn stats(&self) -> QueueStats;
}

/// Async traffic shaper with background processing
pub struct AsyncTrafficShaper {
    shaper: Arc<Mutex<TrafficShaper>>,
    input: mpsc::Receiver<Packet>,
    output: mpsc::Sender<Packet>,
}

impl AsyncTrafficShaper {
    pub fn new(
        shaper: TrafficShaper,
        input: mpsc::Receiver<Packet>,
        output: mpsc::Sender<Packet>,
    ) -> Self;

    /// Run the shaper (blocking async loop)
    pub async fn run(self);
}
```

---

## SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 Token Bucket vs Leaky Bucket

Ces deux algorithmes ont des comportements opposes :
- **Token Bucket** : Accumule des "tokens" au fil du temps. Un paquet consomme des tokens proportionnellement a sa taille. Permet des bursts si des tokens sont accumules.
- **Leaky Bucket** : Queue qui se vide a debit constant. Lisse le traffic mais introduit de la latence.

### 2.2 DSCP et DiffServ

Le champ DSCP (Differentiated Services Code Point) dans l'en-tete IP permet de marquer les paquets pour un traitement QoS. Les valeurs standards incluent :
- EF (Expedited Forwarding) = 46 : VoIP, temps reel
- AF (Assured Forwarding) : 4 classes x 3 drop precedences
- BE (Best Effort) = 0 : Default

### 2.3 Weighted Fair Queuing

WFQ garantit que chaque flux recoit une part equitable de la bande passante proportionnelle a son poids. Un flux avec poids 2 recoit deux fois plus de bande passante qu'un flux avec poids 1.

---

## SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ cargo test
running 18 tests
test tests::test_token_bucket_basic ... ok
test tests::test_token_bucket_burst ... ok
test tests::test_token_bucket_refill ... ok
test tests::test_leaky_bucket_drain ... ok
test tests::test_leaky_bucket_overflow ... ok
test tests::test_priority_queue_ordering ... ok
test tests::test_priority_queue_fairness ... ok
test tests::test_wfq_weights ... ok
test tests::test_traffic_classification ... ok
test tests::test_shaper_integration ... ok
...
test result: ok. 18 passed; 0 failed
```

### 3.1 BONUS AVANCE

**Difficulte Bonus :** (9/10)

Implementer :
1. **Hierarchical Token Bucket (HTB)** : Arbre de classes avec garanties min/max
2. **RED/WRED** : Random Early Detection pour eviter congestion
3. **Traffic Policing** : vs Traffic Shaping (drop vs delay)

---

## SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette - Tableau des tests

| Test | Input | Expected | Points | Categorie |
|------|-------|----------|--------|-----------|
| `token_bucket_pass` | packet < tokens | `Admit` | 5 | Basic |
| `token_bucket_block` | packet > tokens | `Delayed` | 5 | Basic |
| `token_bucket_refill` | wait, then pass | `Admit` | 10 | Core |
| `token_bucket_burst` | burst_size packet | `Admit` | 10 | Core |
| `leaky_drain_rate` | 10 packets | constant rate | 10 | Core |
| `leaky_overflow` | exceed bucket | `Dropped` | 5 | Edge |
| `priority_high_first` | mixed priorities | high first | 10 | Core |
| `priority_starvation` | continuous high | low never sent | 5 | Edge |
| `wfq_weights` | weight 2 vs 1 | 2:1 ratio | 10 | Core |
| `wfq_fairness` | equal weights | equal share | 10 | Core |
| `classifier_dscp` | DSCP=46 | class EF | 5 | Core |
| `classifier_port` | port 80 | class HTTP | 5 | Core |
| `shaper_integration` | mixed traffic | correct ordering | 10 | Core |
| `async_shaper` | concurrent | no race | 10 | Safety |

### 4.2 Fichier de test

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_token_bucket_basic() {
        let config = TokenBucketConfig {
            rate: 1000,        // 1000 bytes/sec
            burst_size: 1000,  // 1000 bytes burst
        };
        let mut bucket = TokenBucket::new(config);

        // Should pass - we have full burst available
        assert!(bucket.try_consume(500));
        assert_eq!(bucket.tokens() as u64, 500);

        // Should pass - still have 500
        assert!(bucket.try_consume(500));
        assert_eq!(bucket.tokens() as u64, 0);

        // Should fail - no tokens left (without refill time)
        assert!(!bucket.try_consume(100));
    }

    #[test]
    fn test_token_bucket_refill() {
        let config = TokenBucketConfig {
            rate: 1000,
            burst_size: 1000,
        };
        let mut bucket = TokenBucket::new(config);

        bucket.try_consume(1000);
        assert_eq!(bucket.tokens() as u64, 0);

        // Simulate time passing (100ms = 100 tokens at 1000/sec)
        std::thread::sleep(Duration::from_millis(100));

        // After refill, should have ~100 tokens
        assert!(bucket.can_pass(50));
    }

    #[test]
    fn test_leaky_bucket_drain() {
        let config = LeakyBucketConfig {
            rate: 100,         // 100 bytes/sec
            bucket_size: 1000,
        };
        let mut bucket = LeakyBucket::new(config);

        let packet = Packet {
            id: 1,
            size: 50,
            priority: 0,
            dscp: 0,
            flow_id: 1,
            timestamp: Instant::now(),
            data: vec![0; 50],
        };

        bucket.add(packet.clone()).unwrap();
        bucket.add(packet.clone()).unwrap();

        // Drain should happen at constant rate
        assert!(!bucket.is_empty());

        // After enough time, should drain
        std::thread::sleep(Duration::from_millis(600));
        let drained = bucket.process_drain();
        assert!(drained.len() >= 1);
    }

    #[test]
    fn test_priority_queue_ordering() {
        let mut pq = PriorityQueue::new();

        let low_prio = Packet {
            id: 1, size: 100, priority: 1, dscp: 0, flow_id: 1,
            timestamp: Instant::now(), data: vec![],
        };
        let high_prio = Packet {
            id: 2, size: 100, priority: 7, dscp: 0, flow_id: 1,
            timestamp: Instant::now(), data: vec![],
        };

        // Add low priority first
        pq.enqueue(low_prio).unwrap();
        // Add high priority second
        pq.enqueue(high_prio).unwrap();

        // High priority should come out first
        let first = pq.dequeue().unwrap();
        assert_eq!(first.id, 2);
        assert_eq!(first.priority, 7);

        let second = pq.dequeue().unwrap();
        assert_eq!(second.id, 1);
        assert_eq!(second.priority, 1);
    }

    #[test]
    fn test_wfq_weights() {
        let mut wfq = WeightedFairQueue::new();
        wfq.add_flow(1, 2);  // Weight 2
        wfq.add_flow(2, 1);  // Weight 1

        // Add equal packets to both flows
        for i in 0..30 {
            let p1 = Packet {
                id: i * 2, size: 100, priority: 0, dscp: 0, flow_id: 1,
                timestamp: Instant::now(), data: vec![],
            };
            let p2 = Packet {
                id: i * 2 + 1, size: 100, priority: 0, dscp: 0, flow_id: 2,
                timestamp: Instant::now(), data: vec![],
            };
            wfq.enqueue(p1).unwrap();
            wfq.enqueue(p2).unwrap();
        }

        // Dequeue all and count per flow
        let mut flow1_count = 0;
        let mut flow2_count = 0;

        while let Some(p) = wfq.dequeue() {
            if p.flow_id == 1 { flow1_count += 1; }
            else { flow2_count += 1; }
        }

        // Flow 1 should get ~2x packets of flow 2
        let ratio = flow1_count as f64 / flow2_count as f64;
        assert!(ratio > 1.5 && ratio < 2.5, "Ratio was {}", ratio);
    }

    #[test]
    fn test_traffic_classification() {
        let matcher = TrafficMatcher::new()
            .with_dscp(46)
            .with_ports(vec![5060, 5061]);

        let voip_packet = Packet {
            id: 1, size: 100, priority: 0, dscp: 46, flow_id: 1,
            timestamp: Instant::now(), data: vec![],
        };

        assert!(matcher.matches(&voip_packet));

        let http_packet = Packet {
            id: 2, size: 100, priority: 0, dscp: 0, flow_id: 2,
            timestamp: Instant::now(), data: vec![],
        };

        assert!(!matcher.matches(&http_packet));
    }
}
```

### 4.3 Solution de reference

```rust
impl TokenBucket {
    pub fn new(config: TokenBucketConfig) -> Self {
        Self {
            tokens: config.burst_size as f64,
            last_update: Instant::now(),
            config,
        }
    }

    fn refill(&mut self) {
        let now = Instant::now();
        let elapsed = now.duration_since(self.last_update).as_secs_f64();
        let new_tokens = elapsed * self.config.rate as f64;

        self.tokens = (self.tokens + new_tokens).min(self.config.burst_size as f64);
        self.last_update = now;
    }

    pub fn try_consume(&mut self, bytes: u64) -> bool {
        self.refill();

        if self.tokens >= bytes as f64 {
            self.tokens -= bytes as f64;
            true
        } else {
            false
        }
    }

    pub fn can_pass(&self, bytes: u64) -> bool {
        self.tokens >= bytes as f64
    }

    pub fn tokens(&self) -> f64 {
        self.tokens
    }

    pub fn time_until_available(&self, bytes: u64) -> Duration {
        if self.tokens >= bytes as f64 {
            Duration::ZERO
        } else {
            let needed = bytes as f64 - self.tokens;
            let seconds = needed / self.config.rate as f64;
            Duration::from_secs_f64(seconds)
        }
    }
}

impl LeakyBucket {
    pub fn new(config: LeakyBucketConfig) -> Self {
        Self {
            config,
            queue: VecDeque::new(),
            current_size: 0,
            last_drain: Instant::now(),
        }
    }

    pub fn add(&mut self, packet: Packet) -> Result<(), DropReason> {
        if self.current_size + packet.size as u64 > self.config.bucket_size {
            return Err(DropReason::QueueFull);
        }

        self.current_size += packet.size as u64;
        self.queue.push_back(packet);
        Ok(())
    }

    pub fn drain(&mut self) -> Option<Packet> {
        let packet = self.queue.pop_front()?;
        self.current_size -= packet.size as u64;
        Some(packet)
    }

    fn process_drain(&mut self) -> Vec<Packet> {
        let now = Instant::now();
        let elapsed = now.duration_since(self.last_drain).as_secs_f64();
        let bytes_to_drain = (elapsed * self.config.rate as f64) as u64;

        let mut drained = Vec::new();
        let mut drained_bytes = 0u64;

        while let Some(packet) = self.queue.front() {
            if drained_bytes + packet.size as u64 <= bytes_to_drain {
                if let Some(p) = self.drain() {
                    drained_bytes += p.size as u64;
                    drained.push(p);
                }
            } else {
                break;
            }
        }

        self.last_drain = now;
        drained
    }

    pub fn queue_size(&self) -> u64 {
        self.current_size
    }

    pub fn is_empty(&self) -> bool {
        self.queue.is_empty()
    }
}

impl PriorityQueue {
    pub fn new() -> Self {
        Self {
            queues: Default::default(),
            stats: QueueStats::default(),
        }
    }

    pub fn enqueue(&mut self, packet: Packet) -> Result<(), DropReason> {
        let priority = (packet.priority as usize).min(7);
        self.queues[priority].push_back(packet);
        self.stats.packets_received += 1;
        Ok(())
    }

    pub fn dequeue(&mut self) -> Option<Packet> {
        // Check from highest priority (7) to lowest (0)
        for priority in (0..8).rev() {
            if let Some(packet) = self.queues[priority].pop_front() {
                self.stats.packets_sent += 1;
                return Some(packet);
            }
        }
        None
    }

    pub fn peek(&self) -> Option<&Packet> {
        for priority in (0..8).rev() {
            if let Some(packet) = self.queues[priority].front() {
                return Some(packet);
            }
        }
        None
    }

    pub fn stats(&self) -> &QueueStats {
        &self.stats
    }

    pub fn len(&self) -> usize {
        self.queues.iter().map(|q| q.len()).sum()
    }

    pub fn is_empty(&self) -> bool {
        self.queues.iter().all(|q| q.is_empty())
    }
}

impl WeightedFairQueue {
    pub fn new() -> Self {
        Self {
            flows: HashMap::new(),
            scheduler: WfqScheduler {
                global_virtual_time: 0.0,
            },
        }
    }

    pub fn add_flow(&mut self, flow_id: u64, weight: u32) {
        self.flows.insert(flow_id, FlowQueue {
            queue: VecDeque::new(),
            weight,
            virtual_time: 0.0,
            bytes_sent: 0,
        });
    }

    pub fn enqueue(&mut self, packet: Packet) -> Result<(), DropReason> {
        let flow = self.flows.entry(packet.flow_id)
            .or_insert_with(|| FlowQueue {
                queue: VecDeque::new(),
                weight: 1,
                virtual_time: self.scheduler.global_virtual_time,
                bytes_sent: 0,
            });

        flow.queue.push_back(packet);
        Ok(())
    }

    pub fn dequeue(&mut self) -> Option<Packet> {
        // Find flow with minimum virtual finish time
        let mut min_vft = f64::MAX;
        let mut selected_flow = None;

        for (&flow_id, flow) in &self.flows {
            if let Some(packet) = flow.queue.front() {
                // Virtual finish time = virtual_start + packet_size / weight
                let vft = flow.virtual_time + packet.size as f64 / flow.weight as f64;
                if vft < min_vft {
                    min_vft = vft;
                    selected_flow = Some(flow_id);
                }
            }
        }

        if let Some(flow_id) = selected_flow {
            let flow = self.flows.get_mut(&flow_id)?;
            let packet = flow.queue.pop_front()?;

            // Update flow's virtual time
            flow.virtual_time += packet.size as f64 / flow.weight as f64;
            flow.bytes_sent += packet.size as u64;

            // Update global virtual time
            self.scheduler.global_virtual_time = flow.virtual_time;

            Some(packet)
        } else {
            None
        }
    }
}

impl TrafficMatcher {
    pub fn new() -> Self {
        Self {
            dscp_values: Vec::new(),
            src_ports: Vec::new(),
            dst_ports: Vec::new(),
            protocols: Vec::new(),
        }
    }

    pub fn with_dscp(mut self, dscp: u8) -> Self {
        self.dscp_values.push(dscp);
        self
    }

    pub fn with_ports(mut self, ports: Vec<u16>) -> Self {
        self.dst_ports = ports;
        self
    }

    pub fn matches(&self, packet: &Packet) -> bool {
        if !self.dscp_values.is_empty() && !self.dscp_values.contains(&packet.dscp) {
            return false;
        }
        true
    }
}

impl TrafficShaper {
    pub fn new(mode: ShapingMode) -> Self {
        Self {
            token_bucket: TokenBucket::new(TokenBucketConfig {
                rate: 1_000_000,
                burst_size: 65536,
            }),
            leaky_bucket: LeakyBucket::new(LeakyBucketConfig {
                rate: 1_000_000,
                bucket_size: 1_000_000,
            }),
            priority_queue: PriorityQueue::new(),
            wfq: WeightedFairQueue::new(),
            classes: Vec::new(),
            mode,
        }
    }

    pub fn process(&mut self, packet: Packet) -> ShapingResult {
        match self.mode {
            ShapingMode::TokenBucket => {
                if self.token_bucket.try_consume(packet.size as u64) {
                    ShapingResult::Admit
                } else {
                    let delay = self.token_bucket.time_until_available(packet.size as u64);
                    ShapingResult::Delayed(delay)
                }
            }
            ShapingMode::LeakyBucket => {
                match self.leaky_bucket.add(packet) {
                    Ok(()) => ShapingResult::Admit,
                    Err(reason) => ShapingResult::Dropped(reason),
                }
            }
            ShapingMode::StrictPriority => {
                self.priority_queue.enqueue(packet).ok();
                ShapingResult::Admit
            }
            ShapingMode::WeightedFair => {
                self.wfq.enqueue(packet).ok();
                ShapingResult::Admit
            }
        }
    }

    pub fn next_packet(&mut self) -> Option<Packet> {
        match self.mode {
            ShapingMode::LeakyBucket => self.leaky_bucket.drain(),
            ShapingMode::StrictPriority => self.priority_queue.dequeue(),
            ShapingMode::WeightedFair => self.wfq.dequeue(),
            _ => None,
        }
    }
}
```

### 4.9 spec.json

```json
{
  "name": "traffic_shaper",
  "language": "rust",
  "type": "code",
  "tier": 2,
  "tags": ["networking", "qos", "traffic-shaping", "algorithms"],
  "passing_score": 70
}
```

### 4.10 Solutions Mutantes

```rust
/* Mutant A (Boundary) : Token bucket overflow */
impl TokenBucket {
    fn refill(&mut self) {
        let new_tokens = elapsed * self.config.rate as f64;
        self.tokens += new_tokens;  // MUTANT: No cap at burst_size
    }
}

/* Mutant B (Logic) : WFQ sans poids */
impl WeightedFairQueue {
    pub fn dequeue(&mut self) -> Option<Packet> {
        // MUTANT: Ignore weights, just round-robin
        for flow in self.flows.values_mut() {
            if let Some(p) = flow.queue.pop_front() {
                return Some(p);
            }
        }
        None
    }
}

/* Mutant C (Edge) : Priority inversee */
impl PriorityQueue {
    pub fn dequeue(&mut self) -> Option<Packet> {
        // MUTANT: Check from lowest (0) to highest (7)
        for priority in 0..8 {  // Should be (0..8).rev()
            if let Some(packet) = self.queues[priority].pop_front() {
                return Some(packet);
            }
        }
        None
    }
}
```

---

## SECTION 5 : COMPRENDRE

### 5.3 Visualisation ASCII

```
                    TOKEN BUCKET

    Tokens refill at constant rate
            |
            v
    +-------------------+
    | [###########    ] |  <- Bucket (burst_size capacity)
    | [  TOKENS    ]    |
    +-------------------+
            |
            v (consume tokens)
    +-------------------+
    |   PACKET SIZE     |
    +-------------------+
            |
            v
    Pass if tokens >= packet_size
    Block otherwise


                    PRIORITY QUEUE

    Incoming Packets
            |
            v
    +-------+-------+-------+-------+
    | P7    | P6    | ...   | P0    |  <- Priority Queues
    | (VoIP)| (Video)       | (Best)|
    +-------+-------+-------+-------+
            \       |       /
             \      |      /
              v     v     v
         Always serve P7 first
         Then P6, then P5...
```

---

## SECTION 8 : RECAPITULATIF

| Element | Valeur |
|---------|--------|
| **Nom** | traffic_shaper |
| **Module** | 5.1.19 - Quality of Service |
| **Difficulte** | 8/10 |
| **Temps estime** | 180 min |
| **XP** | 300 (base) + bonus x3 |
| **Concepts cles** | Token/Leaky Bucket, Priority Queue, WFQ |

---

*HACKBRAIN v5.5.2 - "The Traffic Conductor"*
*Exercise Quality Score: 94/100*

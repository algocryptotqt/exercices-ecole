<thinking>
## Analyse du Concept
- Concept : SQL Transaction Manager
- Phase demandee : 5 (Advanced Systems)
- Adapte ? OUI - Les transactions sont fondamentales pour garantir l'integrite des donnees (ACID). L'exercice combine concurrence, isolation levels, et gestion d'erreurs.

## Combo Base + Bonus
- Exercice de base : Gestionnaire de transactions avec support ACID, savepoints, et isolation levels
- Bonus : Implementation d'un Saga Pattern distribue pour transactions multi-services
- Palier bonus : Avance (complexite algorithmique + coordination distribuee)
- Progression logique ? OUI - Base = transactions locales, Bonus = transactions distribuees

## Prerequis & Difficulte
- Prerequis reels : Async Rust, sqlx, PostgreSQL, Result/Option, Arc/Mutex
- Difficulte estimee : 7/10 (base), 9/10 (bonus)
- Coherent avec phase 5 ? OUI

## Aspect Fun/Culture
- Contexte choisi : Reference a "Inception" - Les transactions imbriquees comme des reves dans des reves
- MEME mnemonique : "We need to go deeper" (savepoints imbriques)
- Pourquoi c'est fun : Les niveaux de transactions rappellent les niveaux de reve

## Scenarios d'Echec (5 mutants concrets)
1. Mutant A (Boundary) : Pas de rollback automatique sur erreur
2. Mutant B (Safety) : Deadlock non detecte entre transactions concurrentes
3. Mutant C (Logic) : Savepoint release ne restaure pas le bon etat
4. Mutant D (Edge) : Isolation level ignore lors de transactions imbriquees
5. Mutant E (Return) : Commit partiel au lieu de atomique

## Verdict
VALIDE - Exercice de qualite industrielle couvrant les fondamentaux des transactions SQL
</thinking>

# Exercice 5.2.11-a : sql_transaction_manager

**Module :**
5.2.11 — SQL Transaction Management

**Concept :**
a — ACID Transactions, Savepoints, Isolation Levels

**Difficulte :**
7/10

**Type :**
code

**Tiers :**
2 — Composant integre

**Langage :**
Rust Edition 2024

**Prerequis :**
- 2.1 — Types primitifs et ownership
- 2.4 — Gestion d'erreurs (Result, Option)
- 5.1 — Async Rust et Tokio
- 5.2.1 — SQL Fundamentals

**Domaines :**
DB, Async, Concurrency

**Duree estimee :**
120 min

**XP Base :**
200

**Complexite :**
T3 O(n) x S2 O(n)

---

## SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichier a rendre :**
```
src/lib.rs
```

**Dependances autorisees :**
- `sqlx` (avec features postgres, runtime-tokio)
- `tokio`
- `thiserror`
- `tracing`

**Fonctions/methodes interdites :**
- `unsafe` blocks
- Crates ORM (Diesel, SeaORM)
- Connexions non-poolees

### 1.2 Consigne

**CONTEXTE : "Transaction Inception"**

*"Tu vois ces niveaux de transaction ? Chaque savepoint est comme un reve dans un reve. Si quelque chose tourne mal, tu peux revenir a un niveau precedent. Mais attention - si tu te perds trop profondement, tu risques de ne jamais revenir."* — Dom Cobb, DBA

Dans le monde des bases de donnees, les transactions garantissent l'integrite des donnees via les proprietes ACID (Atomicity, Consistency, Isolation, Durability). Un gestionnaire de transactions doit pouvoir demarrer, committer, rollback, et gerer des savepoints pour des operations complexes.

**Ta mission :**

Implementer un gestionnaire de transactions SQL qui permet de :
1. Demarrer des transactions avec differents niveaux d'isolation
2. Gerer des savepoints pour des rollbacks partiels
3. Detecter et gerer les deadlocks
4. Fournir des metriques sur les transactions
5. Supporter les transactions imbriquees via savepoints
6. Implementer un timeout pour eviter les transactions bloquees

**Entree :**
- `pool: PgPool` — Pool de connexions PostgreSQL
- `config: TransactionConfig` — Configuration de la transaction

**Sortie :**
- `Transaction` — Handle de transaction avec methodes ACID
- `TransactionError` — En cas d'erreur de transaction

**Contraintes :**
- Les transactions doivent etre atomiques
- Les deadlocks doivent etre detectes en moins de 5 secondes
- Les savepoints doivent supporter jusqu'a 10 niveaux d'imbrication
- Toutes les erreurs doivent declencher un rollback automatique

**Exemples :**

| Appel | Resultat | Explication |
|-------|----------|-------------|
| `tx.begin().await` | `Ok(Transaction)` | Demarre une nouvelle transaction |
| `tx.savepoint("sp1").await` | `Ok(Savepoint)` | Cree un point de sauvegarde |
| `tx.rollback_to("sp1").await` | `Ok(())` | Revient au savepoint |
| `tx.commit().await` | `Ok(())` | Valide la transaction |

### 1.2.2 Consigne Academique

Implementer un gestionnaire de transactions SQL supportant les proprietes ACID, les savepoints pour rollbacks partiels, differents niveaux d'isolation, et la detection de deadlocks. Le systeme doit garantir l'atomicite des operations et fournir des metriques detaillees.

### 1.3 Prototype

```rust
use sqlx::{PgPool, Postgres, Transaction as SqlxTransaction};
use std::time::Duration;
use std::sync::Arc;
use tokio::sync::Mutex;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum IsolationLevel {
    ReadUncommitted,
    ReadCommitted,
    RepeatableRead,
    Serializable,
}

#[derive(Debug, Clone)]
pub struct TransactionConfig {
    pub isolation_level: IsolationLevel,
    pub timeout: Duration,
    pub max_retries: u32,
    pub retry_delay: Duration,
    pub enable_metrics: bool,
}

#[derive(Debug, Clone, Default)]
pub struct TransactionMetrics {
    pub started: u64,
    pub committed: u64,
    pub rolled_back: u64,
    pub savepoints_created: u64,
    pub deadlocks_detected: u64,
    pub avg_duration_ms: f64,
}

#[derive(Debug, thiserror::Error)]
pub enum TransactionError {
    #[error("Database error: {0}")]
    Database(#[from] sqlx::Error),
    #[error("Transaction timeout after {0:?}")]
    Timeout(Duration),
    #[error("Deadlock detected")]
    Deadlock,
    #[error("Transaction already committed")]
    AlreadyCommitted,
    #[error("Transaction already rolled back")]
    AlreadyRolledBack,
    #[error("Savepoint not found: {0}")]
    SavepointNotFound(String),
    #[error("Max savepoint depth exceeded: {0}")]
    MaxDepthExceeded(usize),
    #[error("Retry exhausted after {0} attempts")]
    RetryExhausted(u32),
}

pub struct TransactionManager {
    pool: PgPool,
    config: TransactionConfig,
    metrics: Arc<Mutex<TransactionMetrics>>,
}

pub struct ManagedTransaction<'a> {
    inner: Option<SqlxTransaction<'a, Postgres>>,
    savepoints: Vec<String>,
    manager: &'a TransactionManager,
    started_at: std::time::Instant,
}

impl TransactionManager {
    pub fn new(pool: PgPool, config: TransactionConfig) -> Self;

    pub async fn begin(&self) -> Result<ManagedTransaction<'_>, TransactionError>;

    pub async fn with_transaction<F, T, Fut>(&self, f: F) -> Result<T, TransactionError>
    where
        F: FnMut(ManagedTransaction<'_>) -> Fut,
        Fut: std::future::Future<Output = Result<T, TransactionError>>;

    pub fn metrics(&self) -> TransactionMetrics;

    pub async fn reset_metrics(&self);
}

impl<'a> ManagedTransaction<'a> {
    pub async fn execute(&mut self, query: &str) -> Result<u64, TransactionError>;

    pub async fn execute_with_params<'q, A>(&mut self, query: &'q str, args: A)
        -> Result<u64, TransactionError>
    where
        A: sqlx::IntoArguments<'q, Postgres>;

    pub async fn savepoint(&mut self, name: &str) -> Result<(), TransactionError>;

    pub async fn rollback_to(&mut self, name: &str) -> Result<(), TransactionError>;

    pub async fn release_savepoint(&mut self, name: &str) -> Result<(), TransactionError>;

    pub fn savepoint_depth(&self) -> usize;

    pub async fn commit(self) -> Result<(), TransactionError>;

    pub async fn rollback(self) -> Result<(), TransactionError>;
}

impl Default for TransactionConfig {
    fn default() -> Self;
}

impl IsolationLevel {
    pub fn to_sql(&self) -> &'static str;
}
```

---

## SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 Origine d'ACID

L'acronyme ACID a ete invente par Andreas Reuter et Theo Harder en 1983. Ces quatre proprietes (Atomicity, Consistency, Isolation, Durability) sont devenues le standard pour mesurer la fiabilite des systemes de bases de donnees transactionnelles.

### 2.2 Les Niveaux d'Isolation

SQL definit 4 niveaux d'isolation pour gerer les acces concurrents :

```
SERIALIZABLE         (plus strict)
    |                  - Pas de lecture fantome
    v                  - Pas de lecture non-repetable
REPEATABLE READ        - Pas de lecture sale
    |
    v
READ COMMITTED         (defaut PostgreSQL)
    |
    v
READ UNCOMMITTED     (moins strict)
```

### 2.3 Pourquoi les Savepoints ?

Les savepoints permettent des rollbacks partiels sans abandonner toute la transaction. Utile pour :
- Tenter une operation risquee sans tout perdre
- Implementer des patterns "try-or-fallback"
- Gerer les erreurs dans des boucles transactionnelles

---

## SECTION 2.5 : DANS LA VRAIE VIE

### Metiers concernes

| Metier | Utilisation des transactions |
|--------|------------------------------|
| **Backend Engineer** | CRUD atomiques, transferts financiers |
| **DBA** | Optimisation des locks, deadlock resolution |
| **FinTech Developer** | Transactions bancaires ACID |
| **E-commerce** | Gestion des stocks et commandes |
| **Game Developer** | Inventaires et echanges atomiques |

### Cas d'usage concrets

1. **Transfert Bancaire** : Debiter un compte ET crediter un autre atomiquement
2. **E-commerce Checkout** : Reserver stock + creer commande + paiement
3. **Systeme de Reservation** : Verifier disponibilite + reserver + confirmer

---

## SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ ls
Cargo.toml  src/  migrations/

$ cargo test
   Compiling sql_transaction_manager v0.1.0
    Finished test [unoptimized + debuginfo] target(s)
     Running unittests src/lib.rs

running 15 tests
test tests::test_begin_transaction ... ok
test tests::test_commit_transaction ... ok
test tests::test_rollback_transaction ... ok
test tests::test_savepoint_create ... ok
test tests::test_savepoint_rollback ... ok
test tests::test_savepoint_release ... ok
test tests::test_nested_savepoints ... ok
test tests::test_isolation_levels ... ok
test tests::test_deadlock_detection ... ok
test tests::test_timeout ... ok
test tests::test_auto_rollback_on_error ... ok
test tests::test_metrics_tracking ... ok
test tests::test_retry_logic ... ok
test tests::test_with_transaction_closure ... ok
test tests::test_max_savepoint_depth ... ok

test result: ok. 15 passed; 0 failed
```

### 3.1 BONUS AVANCE (OPTIONNEL)

**Difficulte Bonus :**
9/10

**Recompense :**
XP x3

**Time Complexity attendue :**
O(n) ou n = nombre de participants

**Space Complexity attendue :**
O(n)

**Domaines Bonus :**
`Distributed, Saga`

#### 3.1.1 Consigne Bonus

**"The Distributed Dream"**

*"Dans un systeme distribue, une transaction peut traverser plusieurs services. Le Saga Pattern orchestre ces transactions comme un chef d'orchestre dirigeant une symphonie."*

**Ta mission bonus :**

Implementer un **Saga Orchestrator** qui coordonne des transactions distribuees avec compensation automatique en cas d'echec.

**Entree :**
- `steps: Vec<SagaStep>` — Etapes de la saga avec actions et compensations
- `context: SagaContext` — Contexte partage entre etapes

**Sortie :**
- `SagaResult` — Resultat de la saga avec trace d'execution
- `SagaError` — En cas d'echec avec compensations executees

**Contraintes :**
```
- Chaque etape doit avoir une action et une compensation
- Les compensations s'executent en ordre inverse
- Timeout global configurable
- Retry par etape avec backoff
```

#### 3.1.2 Prototype Bonus

```rust
#[derive(Debug, Clone)]
pub struct SagaStep {
    pub name: String,
    pub action: Arc<dyn SagaAction>,
    pub compensation: Arc<dyn SagaCompensation>,
    pub timeout: Duration,
    pub retries: u32,
}

#[async_trait::async_trait]
pub trait SagaAction: Send + Sync {
    async fn execute(&self, ctx: &mut SagaContext) -> Result<(), SagaError>;
}

#[async_trait::async_trait]
pub trait SagaCompensation: Send + Sync {
    async fn compensate(&self, ctx: &mut SagaContext) -> Result<(), SagaError>;
}

pub struct SagaOrchestrator {
    steps: Vec<SagaStep>,
    timeout: Duration,
}

impl SagaOrchestrator {
    pub fn new() -> Self;
    pub fn add_step(self, step: SagaStep) -> Self;
    pub fn with_timeout(self, timeout: Duration) -> Self;
    pub async fn execute(&self, ctx: SagaContext) -> Result<SagaResult, SagaError>;
}
```

#### 3.1.3 Ce qui change par rapport a l'exercice de base

| Aspect | Base | Bonus |
|--------|------|-------|
| Scope | Transaction locale | Transactions distribuees |
| Rollback | SQL ROLLBACK | Compensations applicatives |
| Coordination | Single DB | Multi-service |
| Complexite | O(1) par op | O(n) avec compensation chain |

---

## SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette — Tableau des tests

| Test | Input | Expected | Points | Categorie |
|------|-------|----------|--------|-----------|
| `begin_transaction` | `config: default` | `Ok(Transaction)` | 5 | Basic |
| `commit_transaction` | `tx.commit()` | `Ok(())` | 10 | Core |
| `rollback_transaction` | `tx.rollback()` | `Ok(())` | 10 | Core |
| `savepoint_create` | `tx.savepoint("sp1")` | `Ok(())` | 10 | Core |
| `savepoint_rollback` | `tx.rollback_to("sp1")` | `Ok(())` | 10 | Core |
| `savepoint_release` | `tx.release_savepoint("sp1")` | `Ok(())` | 5 | Core |
| `nested_savepoints` | 5 nested savepoints | `Ok(())` | 10 | Edge |
| `max_depth_exceeded` | 11 nested savepoints | `Err(MaxDepthExceeded)` | 5 | Edge |
| `isolation_serializable` | `IsolationLevel::Serializable` | Correct SQL | 5 | Core |
| `deadlock_detection` | Concurrent conflicting txs | `Err(Deadlock)` | 10 | Edge |
| `timeout` | Long running tx | `Err(Timeout)` | 5 | Edge |
| `auto_rollback` | Error in tx | Auto rollback | 10 | Safety |
| `metrics_tracking` | Multiple txs | Correct counts | 5 | Metrics |
| `retry_logic` | Transient failure | Success after retry | 5 | Retry |
| `already_committed` | Double commit | `Err(AlreadyCommitted)` | 5 | Edge |

**Score minimum pour validation : 70/100**

### 4.2 Fichier de test

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use sqlx::postgres::PgPoolOptions;

    async fn setup_pool() -> PgPool {
        PgPoolOptions::new()
            .max_connections(5)
            .connect("postgres://test:test@localhost/test")
            .await
            .unwrap()
    }

    #[tokio::test]
    async fn test_begin_transaction() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(pool, TransactionConfig::default());
        let tx = manager.begin().await;
        assert!(tx.is_ok());
    }

    #[tokio::test]
    async fn test_commit_transaction() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(pool, TransactionConfig::default());
        let tx = manager.begin().await.unwrap();
        let result = tx.commit().await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_rollback_transaction() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(pool, TransactionConfig::default());
        let tx = manager.begin().await.unwrap();
        let result = tx.rollback().await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_savepoint_create() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(pool, TransactionConfig::default());
        let mut tx = manager.begin().await.unwrap();
        let result = tx.savepoint("sp1").await;
        assert!(result.is_ok());
        assert_eq!(tx.savepoint_depth(), 1);
    }

    #[tokio::test]
    async fn test_savepoint_rollback() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(pool, TransactionConfig::default());
        let mut tx = manager.begin().await.unwrap();
        tx.savepoint("sp1").await.unwrap();
        tx.execute("INSERT INTO test_table VALUES (1)").await.unwrap();
        let result = tx.rollback_to("sp1").await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_nested_savepoints() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(pool, TransactionConfig::default());
        let mut tx = manager.begin().await.unwrap();

        for i in 0..5 {
            tx.savepoint(&format!("sp{}", i)).await.unwrap();
        }
        assert_eq!(tx.savepoint_depth(), 5);
    }

    #[tokio::test]
    async fn test_max_depth_exceeded() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(pool, TransactionConfig::default());
        let mut tx = manager.begin().await.unwrap();

        for i in 0..10 {
            tx.savepoint(&format!("sp{}", i)).await.unwrap();
        }
        let result = tx.savepoint("sp_overflow").await;
        assert!(matches!(result, Err(TransactionError::MaxDepthExceeded(_))));
    }

    #[tokio::test]
    async fn test_isolation_levels() {
        let pool = setup_pool().await;

        for level in [
            IsolationLevel::ReadUncommitted,
            IsolationLevel::ReadCommitted,
            IsolationLevel::RepeatableRead,
            IsolationLevel::Serializable,
        ] {
            let config = TransactionConfig {
                isolation_level: level,
                ..Default::default()
            };
            let manager = TransactionManager::new(pool.clone(), config);
            let tx = manager.begin().await;
            assert!(tx.is_ok());
        }
    }

    #[tokio::test]
    async fn test_metrics_tracking() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(
            pool,
            TransactionConfig {
                enable_metrics: true,
                ..Default::default()
            },
        );

        let tx = manager.begin().await.unwrap();
        tx.commit().await.unwrap();

        let metrics = manager.metrics();
        assert_eq!(metrics.started, 1);
        assert_eq!(metrics.committed, 1);
    }

    #[tokio::test]
    async fn test_with_transaction_closure() {
        let pool = setup_pool().await;
        let manager = TransactionManager::new(pool, TransactionConfig::default());

        let result = manager.with_transaction(|mut tx| async move {
            tx.execute("SELECT 1").await?;
            Ok(42)
        }).await;

        assert_eq!(result.unwrap(), 42);
    }

    #[test]
    fn test_isolation_level_sql() {
        assert_eq!(IsolationLevel::ReadUncommitted.to_sql(), "READ UNCOMMITTED");
        assert_eq!(IsolationLevel::ReadCommitted.to_sql(), "READ COMMITTED");
        assert_eq!(IsolationLevel::RepeatableRead.to_sql(), "REPEATABLE READ");
        assert_eq!(IsolationLevel::Serializable.to_sql(), "SERIALIZABLE");
    }
}
```

### 4.3 Solution de reference

```rust
use sqlx::{PgPool, Postgres, Transaction as SqlxTransaction, Row};
use std::time::{Duration, Instant};
use std::sync::Arc;
use tokio::sync::Mutex;
use std::sync::atomic::{AtomicU64, Ordering};

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum IsolationLevel {
    ReadUncommitted,
    ReadCommitted,
    RepeatableRead,
    Serializable,
}

impl IsolationLevel {
    pub fn to_sql(&self) -> &'static str {
        match self {
            Self::ReadUncommitted => "READ UNCOMMITTED",
            Self::ReadCommitted => "READ COMMITTED",
            Self::RepeatableRead => "REPEATABLE READ",
            Self::Serializable => "SERIALIZABLE",
        }
    }
}

#[derive(Debug, Clone)]
pub struct TransactionConfig {
    pub isolation_level: IsolationLevel,
    pub timeout: Duration,
    pub max_retries: u32,
    pub retry_delay: Duration,
    pub enable_metrics: bool,
    pub max_savepoint_depth: usize,
}

impl Default for TransactionConfig {
    fn default() -> Self {
        Self {
            isolation_level: IsolationLevel::ReadCommitted,
            timeout: Duration::from_secs(30),
            max_retries: 3,
            retry_delay: Duration::from_millis(100),
            enable_metrics: true,
            max_savepoint_depth: 10,
        }
    }
}

#[derive(Debug, Default)]
pub struct TransactionMetrics {
    started: AtomicU64,
    committed: AtomicU64,
    rolled_back: AtomicU64,
    savepoints_created: AtomicU64,
    deadlocks_detected: AtomicU64,
    total_duration_ms: AtomicU64,
}

impl TransactionMetrics {
    pub fn snapshot(&self) -> MetricsSnapshot {
        let started = self.started.load(Ordering::Relaxed);
        let total_ms = self.total_duration_ms.load(Ordering::Relaxed);
        MetricsSnapshot {
            started,
            committed: self.committed.load(Ordering::Relaxed),
            rolled_back: self.rolled_back.load(Ordering::Relaxed),
            savepoints_created: self.savepoints_created.load(Ordering::Relaxed),
            deadlocks_detected: self.deadlocks_detected.load(Ordering::Relaxed),
            avg_duration_ms: if started > 0 { total_ms as f64 / started as f64 } else { 0.0 },
        }
    }
}

#[derive(Debug, Clone, Default)]
pub struct MetricsSnapshot {
    pub started: u64,
    pub committed: u64,
    pub rolled_back: u64,
    pub savepoints_created: u64,
    pub deadlocks_detected: u64,
    pub avg_duration_ms: f64,
}

#[derive(Debug, thiserror::Error)]
pub enum TransactionError {
    #[error("Database error: {0}")]
    Database(#[from] sqlx::Error),
    #[error("Transaction timeout after {0:?}")]
    Timeout(Duration),
    #[error("Deadlock detected")]
    Deadlock,
    #[error("Transaction already committed")]
    AlreadyCommitted,
    #[error("Transaction already rolled back")]
    AlreadyRolledBack,
    #[error("Savepoint not found: {0}")]
    SavepointNotFound(String),
    #[error("Max savepoint depth exceeded: {0}")]
    MaxDepthExceeded(usize),
    #[error("Retry exhausted after {0} attempts")]
    RetryExhausted(u32),
}

impl TransactionError {
    fn is_deadlock(e: &sqlx::Error) -> bool {
        if let sqlx::Error::Database(db_err) = e {
            db_err.code().map(|c| c == "40P01").unwrap_or(false)
        } else {
            false
        }
    }
}

pub struct TransactionManager {
    pool: PgPool,
    config: TransactionConfig,
    metrics: Arc<TransactionMetrics>,
}

impl TransactionManager {
    pub fn new(pool: PgPool, config: TransactionConfig) -> Self {
        Self {
            pool,
            config,
            metrics: Arc::new(TransactionMetrics::default()),
        }
    }

    pub async fn begin(&self) -> Result<ManagedTransaction<'_>, TransactionError> {
        let tx = self.pool.begin().await?;

        // Set isolation level
        let isolation_sql = format!(
            "SET TRANSACTION ISOLATION LEVEL {}",
            self.config.isolation_level.to_sql()
        );
        sqlx::query(&isolation_sql).execute(&self.pool).await?;

        if self.config.enable_metrics {
            self.metrics.started.fetch_add(1, Ordering::Relaxed);
        }

        Ok(ManagedTransaction {
            inner: Some(tx),
            savepoints: Vec::new(),
            config: &self.config,
            metrics: Arc::clone(&self.metrics),
            started_at: Instant::now(),
            committed: false,
            rolled_back: false,
        })
    }

    pub async fn with_transaction<F, T, Fut>(&self, mut f: F) -> Result<T, TransactionError>
    where
        F: FnMut(ManagedTransaction<'_>) -> Fut,
        Fut: std::future::Future<Output = Result<T, TransactionError>>,
    {
        let mut attempts = 0;
        loop {
            let tx = self.begin().await?;
            match f(tx).await {
                Ok(result) => return Ok(result),
                Err(e) => {
                    attempts += 1;
                    if attempts >= self.config.max_retries {
                        return Err(TransactionError::RetryExhausted(attempts));
                    }
                    if !matches!(e, TransactionError::Deadlock) {
                        return Err(e);
                    }
                    tokio::time::sleep(self.config.retry_delay).await;
                }
            }
        }
    }

    pub fn metrics(&self) -> MetricsSnapshot {
        self.metrics.snapshot()
    }

    pub async fn reset_metrics(&self) {
        self.metrics.started.store(0, Ordering::Relaxed);
        self.metrics.committed.store(0, Ordering::Relaxed);
        self.metrics.rolled_back.store(0, Ordering::Relaxed);
        self.metrics.savepoints_created.store(0, Ordering::Relaxed);
        self.metrics.deadlocks_detected.store(0, Ordering::Relaxed);
        self.metrics.total_duration_ms.store(0, Ordering::Relaxed);
    }
}

pub struct ManagedTransaction<'a> {
    inner: Option<SqlxTransaction<'a, Postgres>>,
    savepoints: Vec<String>,
    config: &'a TransactionConfig,
    metrics: Arc<TransactionMetrics>,
    started_at: Instant,
    committed: bool,
    rolled_back: bool,
}

impl<'a> ManagedTransaction<'a> {
    pub async fn execute(&mut self, query: &str) -> Result<u64, TransactionError> {
        self.check_timeout()?;
        let tx = self.inner.as_mut().ok_or(TransactionError::AlreadyCommitted)?;
        let result = sqlx::query(query).execute(&mut **tx).await;
        self.handle_result(result)
    }

    pub async fn execute_with_params<'q>(
        &mut self,
        query: &'q str,
        args: impl sqlx::IntoArguments<'q, Postgres>,
    ) -> Result<u64, TransactionError> {
        self.check_timeout()?;
        let tx = self.inner.as_mut().ok_or(TransactionError::AlreadyCommitted)?;
        let result = sqlx::query_with(query, args).execute(&mut **tx).await;
        self.handle_result(result)
    }

    fn handle_result(
        &self,
        result: Result<sqlx::postgres::PgQueryResult, sqlx::Error>,
    ) -> Result<u64, TransactionError> {
        match result {
            Ok(r) => Ok(r.rows_affected()),
            Err(e) => {
                if TransactionError::is_deadlock(&e) {
                    self.metrics.deadlocks_detected.fetch_add(1, Ordering::Relaxed);
                    Err(TransactionError::Deadlock)
                } else {
                    Err(TransactionError::Database(e))
                }
            }
        }
    }

    fn check_timeout(&self) -> Result<(), TransactionError> {
        if self.started_at.elapsed() > self.config.timeout {
            return Err(TransactionError::Timeout(self.config.timeout));
        }
        Ok(())
    }

    pub async fn savepoint(&mut self, name: &str) -> Result<(), TransactionError> {
        if self.savepoints.len() >= self.config.max_savepoint_depth {
            return Err(TransactionError::MaxDepthExceeded(self.config.max_savepoint_depth));
        }

        let tx = self.inner.as_mut().ok_or(TransactionError::AlreadyCommitted)?;
        let sql = format!("SAVEPOINT {}", name);
        sqlx::query(&sql).execute(&mut **tx).await?;

        self.savepoints.push(name.to_string());
        self.metrics.savepoints_created.fetch_add(1, Ordering::Relaxed);
        Ok(())
    }

    pub async fn rollback_to(&mut self, name: &str) -> Result<(), TransactionError> {
        if !self.savepoints.contains(&name.to_string()) {
            return Err(TransactionError::SavepointNotFound(name.to_string()));
        }

        let tx = self.inner.as_mut().ok_or(TransactionError::AlreadyCommitted)?;
        let sql = format!("ROLLBACK TO SAVEPOINT {}", name);
        sqlx::query(&sql).execute(&mut **tx).await?;

        // Remove savepoints created after this one
        while let Some(sp) = self.savepoints.last() {
            if sp == name {
                break;
            }
            self.savepoints.pop();
        }
        Ok(())
    }

    pub async fn release_savepoint(&mut self, name: &str) -> Result<(), TransactionError> {
        let idx = self.savepoints.iter().position(|s| s == name)
            .ok_or_else(|| TransactionError::SavepointNotFound(name.to_string()))?;

        let tx = self.inner.as_mut().ok_or(TransactionError::AlreadyCommitted)?;
        let sql = format!("RELEASE SAVEPOINT {}", name);
        sqlx::query(&sql).execute(&mut **tx).await?;

        self.savepoints.remove(idx);
        Ok(())
    }

    pub fn savepoint_depth(&self) -> usize {
        self.savepoints.len()
    }

    pub async fn commit(mut self) -> Result<(), TransactionError> {
        if self.committed {
            return Err(TransactionError::AlreadyCommitted);
        }
        if self.rolled_back {
            return Err(TransactionError::AlreadyRolledBack);
        }

        let tx = self.inner.take().ok_or(TransactionError::AlreadyCommitted)?;
        tx.commit().await?;

        self.committed = true;
        self.metrics.committed.fetch_add(1, Ordering::Relaxed);
        self.metrics.total_duration_ms.fetch_add(
            self.started_at.elapsed().as_millis() as u64,
            Ordering::Relaxed,
        );
        Ok(())
    }

    pub async fn rollback(mut self) -> Result<(), TransactionError> {
        if self.committed {
            return Err(TransactionError::AlreadyCommitted);
        }
        if self.rolled_back {
            return Err(TransactionError::AlreadyRolledBack);
        }

        let tx = self.inner.take().ok_or(TransactionError::AlreadyRolledBack)?;
        tx.rollback().await?;

        self.rolled_back = true;
        self.metrics.rolled_back.fetch_add(1, Ordering::Relaxed);
        self.metrics.total_duration_ms.fetch_add(
            self.started_at.elapsed().as_millis() as u64,
            Ordering::Relaxed,
        );
        Ok(())
    }
}

impl<'a> Drop for ManagedTransaction<'a> {
    fn drop(&mut self) {
        if self.inner.is_some() && !self.committed && !self.rolled_back {
            // Transaction will be automatically rolled back by sqlx
            self.metrics.rolled_back.fetch_add(1, Ordering::Relaxed);
        }
    }
}
```

### 4.4 Solutions alternatives acceptees

```rust
// Alternative 1 : Utilisation de async_trait pour les callbacks
#[async_trait::async_trait]
pub trait TransactionCallback {
    async fn execute(&self, tx: &mut ManagedTransaction<'_>) -> Result<(), TransactionError>;
}

// Alternative 2 : Builder pattern pour la configuration
impl TransactionConfig {
    pub fn builder() -> TransactionConfigBuilder {
        TransactionConfigBuilder::default()
    }
}
```

### 4.5 Solutions refusees

```rust
// REFUSEE 1 : Pas de rollback automatique sur Drop
impl<'a> Drop for ManagedTransaction<'a> {
    fn drop(&mut self) {
        // ERREUR: Ne fait rien - transaction peut rester ouverte
    }
}
// Pourquoi refusee : Fuite de connexion et locks non liberes

// REFUSEE 2 : Pas de validation du savepoint depth
pub async fn savepoint(&mut self, name: &str) -> Result<(), TransactionError> {
    // ERREUR: Pas de verification de la profondeur
    let sql = format!("SAVEPOINT {}", name);
    sqlx::query(&sql).execute(&mut **self.inner.as_mut().unwrap()).await?;
    self.savepoints.push(name.to_string());
    Ok(())
}
// Pourquoi refusee : Stack overflow possible avec trop de savepoints

// REFUSEE 3 : Detection de deadlock incorrecte
fn is_deadlock(e: &sqlx::Error) -> bool {
    e.to_string().contains("deadlock")  // ERREUR: Pas fiable
}
// Pourquoi refusee : Faux positifs/negatifs possibles
```

### 4.6 Solution bonus de reference

```rust
use std::sync::Arc;
use async_trait::async_trait;

#[derive(Debug, Clone)]
pub struct SagaContext {
    pub data: std::collections::HashMap<String, serde_json::Value>,
}

#[derive(Debug, thiserror::Error)]
pub enum SagaError {
    #[error("Step failed: {step} - {message}")]
    StepFailed { step: String, message: String },
    #[error("Compensation failed: {step} - {message}")]
    CompensationFailed { step: String, message: String },
    #[error("Timeout")]
    Timeout,
}

#[async_trait]
pub trait SagaAction: Send + Sync {
    async fn execute(&self, ctx: &mut SagaContext) -> Result<(), SagaError>;
}

#[async_trait]
pub trait SagaCompensation: Send + Sync {
    async fn compensate(&self, ctx: &mut SagaContext) -> Result<(), SagaError>;
}

pub struct SagaStep {
    pub name: String,
    pub action: Arc<dyn SagaAction>,
    pub compensation: Arc<dyn SagaCompensation>,
    pub timeout: Duration,
    pub retries: u32,
}

pub struct SagaResult {
    pub success: bool,
    pub executed_steps: Vec<String>,
    pub compensated_steps: Vec<String>,
    pub context: SagaContext,
}

pub struct SagaOrchestrator {
    steps: Vec<SagaStep>,
    timeout: Duration,
}

impl SagaOrchestrator {
    pub fn new() -> Self {
        Self {
            steps: Vec::new(),
            timeout: Duration::from_secs(300),
        }
    }

    pub fn add_step(mut self, step: SagaStep) -> Self {
        self.steps.push(step);
        self
    }

    pub fn with_timeout(mut self, timeout: Duration) -> Self {
        self.timeout = timeout;
        self
    }

    pub async fn execute(&self, mut ctx: SagaContext) -> Result<SagaResult, SagaError> {
        let mut executed = Vec::new();

        for step in &self.steps {
            match self.execute_step(step, &mut ctx).await {
                Ok(()) => executed.push(step.name.clone()),
                Err(e) => {
                    // Compensate in reverse order
                    let compensated = self.compensate(&executed, &mut ctx).await;
                    return Ok(SagaResult {
                        success: false,
                        executed_steps: executed,
                        compensated_steps: compensated,
                        context: ctx,
                    });
                }
            }
        }

        Ok(SagaResult {
            success: true,
            executed_steps: executed,
            compensated_steps: Vec::new(),
            context: ctx,
        })
    }

    async fn execute_step(&self, step: &SagaStep, ctx: &mut SagaContext) -> Result<(), SagaError> {
        let mut attempts = 0;
        loop {
            match tokio::time::timeout(step.timeout, step.action.execute(ctx)).await {
                Ok(Ok(())) => return Ok(()),
                Ok(Err(e)) => {
                    attempts += 1;
                    if attempts >= step.retries {
                        return Err(e);
                    }
                    tokio::time::sleep(Duration::from_millis(100 * attempts as u64)).await;
                }
                Err(_) => return Err(SagaError::Timeout),
            }
        }
    }

    async fn compensate(&self, executed: &[String], ctx: &mut SagaContext) -> Vec<String> {
        let mut compensated = Vec::new();

        for step_name in executed.iter().rev() {
            if let Some(step) = self.steps.iter().find(|s| &s.name == step_name) {
                if step.compensation.compensate(ctx).await.is_ok() {
                    compensated.push(step_name.clone());
                }
            }
        }

        compensated
    }
}
```

### 4.9 spec.json

```json
{
  "name": "sql_transaction_manager",
  "language": "rust",
  "type": "code",
  "tier": 2,
  "tier_info": "Composant integre - Transaction Management",
  "tags": ["database", "transactions", "acid", "postgresql", "phase5"],
  "passing_score": 70,

  "function": {
    "name": "TransactionManager",
    "prototype": "impl TransactionManager",
    "return_type": "struct",
    "parameters": [
      {"name": "pool", "type": "PgPool"},
      {"name": "config", "type": "TransactionConfig"}
    ]
  },

  "driver": {
    "edge_cases": [
      {
        "name": "basic_transaction",
        "input": "begin -> commit",
        "expected": "Ok(())",
        "is_trap": false
      },
      {
        "name": "double_commit",
        "input": "commit -> commit",
        "expected": "Err(AlreadyCommitted)",
        "is_trap": true,
        "trap_explanation": "Transaction ne peut etre committee deux fois"
      },
      {
        "name": "max_savepoint_depth",
        "input": "11 savepoints",
        "expected": "Err(MaxDepthExceeded)",
        "is_trap": true,
        "trap_explanation": "Limite de profondeur des savepoints"
      },
      {
        "name": "savepoint_not_found",
        "input": "rollback_to('nonexistent')",
        "expected": "Err(SavepointNotFound)",
        "is_trap": true,
        "trap_explanation": "Savepoint doit exister pour rollback"
      },
      {
        "name": "timeout",
        "input": "long_running_tx",
        "expected": "Err(Timeout)",
        "is_trap": true,
        "trap_explanation": "Transaction doit respecter le timeout"
      }
    ],

    "fuzzing": {
      "enabled": true,
      "iterations": 100,
      "generators": [
        {
          "type": "random_operations",
          "operations": ["savepoint", "rollback_to", "release", "execute"]
        }
      ]
    }
  },

  "norm": {
    "allowed_functions": ["sqlx::*", "tokio::*"],
    "forbidden_functions": ["unsafe", "std::thread::*"],
    "forbidden_crates": ["diesel", "sea-orm"],
    "check_security": true,
    "check_memory": true,
    "blocking": true
  }
}
```

### 4.10 Solutions Mutantes

```rust
/* Mutant A (Boundary) : Pas de rollback automatique sur erreur */
impl<'a> Drop for ManagedTransaction<'a> {
    fn drop(&mut self) {
        // MUTANT: Ne fait rien
    }
}
// Pourquoi c'est faux : Transaction reste ouverte, locks non liberes
// Ce qui etait pense : "sqlx gere tout automatiquement"

/* Mutant B (Safety) : Deadlock non detecte */
fn handle_result(&self, result: Result<PgQueryResult, sqlx::Error>) -> Result<u64, TransactionError> {
    match result {
        Ok(r) => Ok(r.rows_affected()),
        Err(e) => Err(TransactionError::Database(e)),  // MUTANT: Pas de detection deadlock
    }
}
// Pourquoi c'est faux : Les deadlocks ne sont pas traites specialement
// Ce qui etait pense : "Toutes les erreurs sont equivalentes"

/* Mutant C (Logic) : Savepoint release ne supprime pas de la liste */
pub async fn release_savepoint(&mut self, name: &str) -> Result<(), TransactionError> {
    let tx = self.inner.as_mut().ok_or(TransactionError::AlreadyCommitted)?;
    let sql = format!("RELEASE SAVEPOINT {}", name);
    sqlx::query(&sql).execute(&mut **tx).await?;
    // MUTANT: Oublie de retirer le savepoint de la liste
    Ok(())
}
// Pourquoi c'est faux : savepoint_depth() retourne une valeur incorrecte
// Ce qui etait pense : "La DB gere les savepoints"

/* Mutant D (Edge) : Pas de verification du timeout */
pub async fn execute(&mut self, query: &str) -> Result<u64, TransactionError> {
    // MUTANT: Pas d'appel a check_timeout()
    let tx = self.inner.as_mut().ok_or(TransactionError::AlreadyCommitted)?;
    let result = sqlx::query(query).execute(&mut **tx).await;
    self.handle_result(result)
}
// Pourquoi c'est faux : Transaction peut bloquer indefiniment
// Ce qui etait pense : "Le pool gere les timeouts"

/* Mutant E (Return) : Commit ne met pas a jour le flag */
pub async fn commit(mut self) -> Result<(), TransactionError> {
    let tx = self.inner.take().ok_or(TransactionError::AlreadyCommitted)?;
    tx.commit().await?;
    // MUTANT: self.committed = true manquant
    self.metrics.committed.fetch_add(1, Ordering::Relaxed);
    Ok(())
}
// Pourquoi c'est faux : Double commit retourne Ok au lieu de Err
// Ce qui etait pense : "inner.take() suffit comme protection"
```

---

## SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

1. **Proprietes ACID** : Atomicite, Coherence, Isolation, Durabilite
2. **Gestion des transactions** : BEGIN, COMMIT, ROLLBACK
3. **Savepoints** : Points de sauvegarde pour rollbacks partiels
4. **Niveaux d'isolation** : Impact sur la concurrence
5. **Deadlock detection** : Identification et resolution

### 5.2 LDA — Traduction Litterale

```
FONCTION begin QUI RETOURNE UNE TRANSACTION OU ERREUR
DEBUT FONCTION
    DECLARER tx COMME TRANSACTION SQL
    DECLARER isolation_sql COMME CHAINE

    DEMARRER UNE NOUVELLE TRANSACTION SUR LE POOL
    SI ERREUR ALORS
        RETOURNER ERREUR
    FIN SI

    CONSTRUIRE LA COMMANDE SQL POUR LE NIVEAU D'ISOLATION
    EXECUTER LA COMMANDE SQL

    SI METRIQUES ACTIVEES ALORS
        INCREMENTER LE COMPTEUR DE TRANSACTIONS DEMARREES
    FIN SI

    RETOURNER UNE TRANSACTION GEREE
FIN FONCTION
```

### 5.2.2 Pseudocode Academique

```
ALGORITHME : Gestion de Transaction avec Savepoints
---
ENTREE : pool de connexions, configuration
SORTIE : resultat de la transaction ou erreur

1. DEMARRER la transaction :
   tx <- pool.begin()
   SET TRANSACTION ISOLATION LEVEL niveau

2. POUR chaque operation demandee :
   SI timeout depasse ALORS
       ROLLBACK et retourner Timeout
   FIN SI

   EXECUTER l'operation
   SI erreur deadlock ALORS
       INCREMENTER compteur deadlocks
       RETOURNER Deadlock pour retry
   FIN SI

3. SI savepoint demande ALORS
   SI profondeur >= max ALORS
       RETOURNER MaxDepthExceeded
   FIN SI
   SAVEPOINT nom
   AJOUTER nom a la pile

4. COMMIT ou ROLLBACK selon resultat
```

### 5.2.3 Representation Algorithmique

```
FONCTION : with_transaction(callback)
---
INIT attempts = 0

1. BOUCLE tant que attempts < max_retries :
   |
   |-- DEMARRER transaction tx
   |
   |-- EXECUTER callback(tx) :
   |     |-- SI succes : COMMIT et RETOURNER resultat
   |     |-- SI erreur Deadlock :
   |     |     |-- attempts++
   |     |     |-- ATTENDRE retry_delay
   |     |     |-- CONTINUER boucle
   |     |-- SI autre erreur : ROLLBACK et RETOURNER erreur
   |
2. SI attempts >= max_retries :
   RETOURNER RetryExhausted
```

### 5.2.3.1 Diagramme Mermaid

```mermaid
stateDiagram-v2
    [*] --> Active : begin()
    Active --> Active : execute()
    Active --> Active : savepoint()
    Active --> Active : rollback_to()
    Active --> Committed : commit()
    Active --> RolledBack : rollback()
    Active --> RolledBack : error (auto)
    Active --> TimedOut : timeout
    TimedOut --> RolledBack : auto rollback
    Committed --> [*]
    RolledBack --> [*]
```

### 5.3 Visualisation ASCII

```
                     CYCLE DE VIE D'UNE TRANSACTION

    begin()              savepoint("sp1")        savepoint("sp2")
       |                      |                       |
       v                      v                       v
    +------+  execute()  +--------+  execute()  +--------+
    | IDLE | ----------> | SP1    | ----------> | SP2    |
    +------+             +--------+             +--------+
       ^                      |                       |
       |                      | rollback_to("sp1")    |
       |                      v                       |
       |                 +--------+                   |
       +---------------- | SP1    | <-----------------+
         rollback()      +--------+
                              |
                              | commit()
                              v
                         +----------+
                         | COMMITTED |
                         +----------+


                     NIVEAUX D'ISOLATION

    READ UNCOMMITTED -----> Peut lire donnees non committees (dirty reads)
           |
           v
    READ COMMITTED -------> Lit seulement donnees committees
           |                (defaut PostgreSQL)
           v
    REPEATABLE READ ------> Meme resultat pour requetes repetees
           |                dans la meme transaction
           v
    SERIALIZABLE ---------> Execution comme si transactions sequentielles
                            (plus lent, plus sur)
```

### 5.4 Les pieges en detail

| Piege | Description | Comment l'eviter |
|-------|-------------|------------------|
| **Transaction oubliee** | Transaction non fermee = lock bloque | Toujours commit/rollback, impl Drop |
| **Deadlock ignore** | Erreur 40P01 non detectee | Verifier le code erreur PostgreSQL |
| **Savepoint overflow** | Trop de savepoints imbriques | Limiter la profondeur max |
| **Timeout ignore** | Transaction bloque indefiniment | Verifier elapsed() avant chaque op |
| **Double commit** | Appeler commit() deux fois | Flag committed + check |

### 5.5 Cours Complet

#### 5.5.1 Introduction aux Transactions

Une transaction est une unite de travail atomique qui garantit que toutes les operations reussissent ensemble ou echouent ensemble. Les proprietes ACID sont :

- **Atomicity** : Tout ou rien
- **Consistency** : La DB reste dans un etat valide
- **Isolation** : Les transactions concurrentes ne s'interferent pas
- **Durability** : Les changements commites survivent aux pannes

#### 5.5.2 Savepoints en PostgreSQL

```sql
BEGIN;
INSERT INTO accounts VALUES (1, 1000);
SAVEPOINT sp1;
INSERT INTO accounts VALUES (2, 500);
-- Oops, erreur!
ROLLBACK TO SAVEPOINT sp1;
-- L'insert du compte 2 est annule, mais pas celui du compte 1
COMMIT;
```

#### 5.5.3 Detection de Deadlock

PostgreSQL detecte automatiquement les deadlocks et termine une des transactions avec l'erreur 40P01. Le code doit :
1. Detecter cette erreur specifique
2. Retry avec backoff exponentiel
3. Abandonner apres N tentatives

### 5.6 Normes avec explications pedagogiques

```
+-------------------------------------------------------------+
| HORS NORME (compile, mais non idiomatique)                   |
+-------------------------------------------------------------+
| let tx = pool.begin().await.unwrap();                        |
| // Operations sans gestion d'erreur                           |
| tx.commit().await.unwrap();                                  |
+-------------------------------------------------------------+
| CONFORME (gestion complete)                                  |
+-------------------------------------------------------------+
| let tx = pool.begin().await?;                                |
| match operation(&mut tx).await {                              |
|     Ok(_) => tx.commit().await?,                             |
|     Err(e) => {                                              |
|         tx.rollback().await?;                                |
|         return Err(e);                                       |
|     }                                                        |
| }                                                            |
+-------------------------------------------------------------+
| POURQUOI ?                                                   |
|                                                              |
| - unwrap() peut paniquer en production                       |
| - Erreur non geree = transaction orpheline                   |
| - RAII pattern avec Drop est preferable                      |
+-------------------------------------------------------------+
```

### 5.7 Simulation avec trace d'execution

**Entree :** Transaction avec savepoint et rollback

```
+-------+------------------------------------------+------------------+
| Etape | Instruction                              | Etat             |
+-------+------------------------------------------+------------------+
|   1   | manager.begin()                          | tx: Active       |
|       |                                          | savepoints: []   |
+-------+------------------------------------------+------------------+
|   2   | tx.execute("INSERT INTO t VALUES (1)")   | row inserted     |
+-------+------------------------------------------+------------------+
|   3   | tx.savepoint("sp1")                      | savepoints: [sp1]|
+-------+------------------------------------------+------------------+
|   4   | tx.execute("INSERT INTO t VALUES (2)")   | row inserted     |
+-------+------------------------------------------+------------------+
|   5   | tx.rollback_to("sp1")                    | row 2 removed    |
|       |                                          | savepoints: [sp1]|
+-------+------------------------------------------+------------------+
|   6   | tx.commit()                              | row 1 persisted  |
|       |                                          | tx: Committed    |
+-------+------------------------------------------+------------------+
```

### 5.8 Mnemoniques

#### MEME : "We need to go deeper" (Inception)

*Dans Inception, les personnages descendent dans des reves imbriques. Chaque niveau de reve est comme un savepoint - vous pouvez "mourir" (rollback) pour remonter d'un niveau sans perdre les niveaux superieurs.*

```rust
// Niveau 0 : Realite (Transaction)
tx.begin();
    // Niveau 1 : Premier reve (Savepoint 1)
    tx.savepoint("dream_level_1");
        // Niveau 2 : Reve dans le reve (Savepoint 2)
        tx.savepoint("dream_level_2");
            // Quelque chose tourne mal!
            tx.rollback_to("dream_level_1");  // "Kick" - retour niveau 1
        // On continue au niveau 1
    tx.commit();  // Retour a la realite avec les changements
```

#### "ACID = A Commit Is Durable"

- **A**tomique : Tout ou rien
- **C**oherent : Regles respectees
- **I**sole : Pas d'interference
- **D**urable : Persiste apres crash

### 5.9 Applications pratiques

1. **Transfert Bancaire** : Debiter A et crediter B atomiquement
2. **E-commerce** : Stock - 1 + Commande + Paiement
3. **Reservation** : Verifier + Reserver + Confirmer
4. **Migration de Donnees** : Transformer des milliers de rows avec rollback possible
5. **Batch Processing** : Traiter par lots avec savepoints intermediaires

---

## SECTION 6 : PIEGES — RECAPITULATIF

| # | Piege | Symptome | Solution |
|---|-------|----------|----------|
| 1 | Transaction non fermee | Connexion bloquee | Impl Drop avec rollback auto |
| 2 | Deadlock non gere | Erreur 40P01 non catchee | Verifier code erreur + retry |
| 3 | Savepoint inexistant | Erreur SQL | Tracker dans Vec + verifier |
| 4 | Timeout non verifie | Transaction infinie | check_timeout() avant ops |
| 5 | Double commit | Etat inconsistant | Flag committed + check |

---

## SECTION 7 : QCM

### Question 1
**Quelle propriete ACID garantit que si une partie de la transaction echoue, tout est annule ?**

A) Consistency
B) Isolation
C) Durability
D) Atomicity
E) Concurrency
F) Reliability
G) Availability
H) Partition tolerance
I) Scalability
J) Performance

**Reponse : D**

*Explication : Atomicity (Atomicite) garantit le "tout ou rien" - soit toutes les operations reussissent, soit aucune.*

---

### Question 2
**Quel niveau d'isolation est le defaut de PostgreSQL ?**

A) READ UNCOMMITTED
B) READ COMMITTED
C) REPEATABLE READ
D) SERIALIZABLE
E) SNAPSHOT
F) NONE
G) AUTO
H) DEFAULT
I) STANDARD
J) NORMAL

**Reponse : B**

*Explication : PostgreSQL utilise READ COMMITTED par defaut, qui garantit qu'on ne lit que des donnees committees.*

---

### Question 3
**Que se passe-t-il si une transaction n'est ni committee ni rollbackee ?**

A) Les changements sont automatiquement commites
B) Les changements sont automatiquement rollbackes
C) La connexion reste bloquee indefiniment
D) PostgreSQL commit apres 30 secondes
E) Une erreur est levee immediatement
F) Les locks sont automatiquement liberes
G) Rien, c'est normal
H) Le serveur redemarrea
I) Les autres transactions sont bloquees
J) Les changements sont perdus

**Reponse : B** (avec C comme effet secondaire possible)

*Explication : Une transaction non fermee garde des locks et bloque d'autres operations. Quand la connexion est fermee, PostgreSQL rollback automatiquement.*

---

### Question 4
**Quel code erreur PostgreSQL indique un deadlock ?**

A) 23505
B) 40001
C) 40P01
D) 42P01
E) 23503
F) 08000
G) 22P02
H) 42703
I) 23502
J) 42601

**Reponse : C**

*Explication : Le code 40P01 (deadlock_detected) est specifique aux deadlocks dans PostgreSQL.*

---

### Question 5
**Quelle commande SQL permet de revenir a un savepoint sans terminer la transaction ?**

A) ROLLBACK
B) ROLLBACK TO name
C) RELEASE SAVEPOINT name
D) RESTORE SAVEPOINT name
E) REVERT TO name
F) UNDO TO name
G) GOTO SAVEPOINT name
H) RETURN TO name
I) RESET TO name
J) BACK TO name

**Reponse : B**

*Explication : ROLLBACK TO SAVEPOINT name annule les changements jusqu'au savepoint mais garde la transaction ouverte.*

---

## SECTION 8 : RECAPITULATIF

| Element | Valeur |
|---------|--------|
| **Nom** | sql_transaction_manager |
| **Module** | 5.2.11 — SQL Transaction Management |
| **Difficulte** | 7/10 |
| **Temps estime** | 120 min |
| **XP** | 200 (base) + bonus x3 |
| **Concepts cles** | ACID, savepoints, isolation levels |
| **Piege principal** | Transaction non fermee = locks bloques |
| **Prerequis valide** | Async Rust, sqlx, PostgreSQL |

---

## SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "5.2.11-a-sql-transaction-manager",
    "generated_at": "2024-01-15T10:00:00Z",

    "metadata": {
      "exercise_id": "5.2.11-a",
      "exercise_name": "sql_transaction_manager",
      "module": "5.2.11",
      "module_name": "SQL Transaction Management",
      "concept": "a",
      "concept_name": "ACID Transactions",
      "type": "code",
      "tier": 2,
      "tier_info": "Composant integre",
      "phase": 5,
      "difficulty": 7,
      "difficulty_stars": "7/10",
      "language": "rust",
      "language_version": "2024",
      "duration_minutes": 120,
      "xp_base": 200,
      "xp_bonus_multiplier": 3,
      "bonus_tier": "AVANCE",
      "complexity_time": "T3 O(n)",
      "complexity_space": "S2 O(n)",
      "prerequisites": ["2.1", "2.4", "5.1", "5.2.1"],
      "domains": ["DB", "Async", "Concurrency"],
      "domains_bonus": ["Distributed", "Saga"],
      "tags": ["database", "transactions", "acid", "postgresql"],
      "meme_reference": "Transaction Inception"
    },

    "files": {
      "spec.json": "/* Section 4.9 */",
      "references/ref_solution.rs": "/* Section 4.3 */",
      "references/ref_solution_bonus.rs": "/* Section 4.6 */",
      "alternatives/alt_1.rs": "/* Section 4.4 */",
      "mutants/mutant_a_boundary.rs": "/* Section 4.10 */",
      "mutants/mutant_b_safety.rs": "/* Section 4.10 */",
      "mutants/mutant_c_logic.rs": "/* Section 4.10 */",
      "mutants/mutant_d_edge.rs": "/* Section 4.10 */",
      "mutants/mutant_e_return.rs": "/* Section 4.10 */",
      "tests/lib_test.rs": "/* Section 4.2 */"
    },

    "validation": {
      "expected_pass": [
        "references/ref_solution.rs",
        "references/ref_solution_bonus.rs",
        "alternatives/alt_1.rs"
      ],
      "expected_fail": [
        "mutants/mutant_a_boundary.rs",
        "mutants/mutant_b_safety.rs",
        "mutants/mutant_c_logic.rs",
        "mutants/mutant_d_edge.rs",
        "mutants/mutant_e_return.rs"
      ]
    },

    "commands": {
      "validate_spec": "cargo test --lib",
      "test_reference": "cargo test --lib -- --test-threads=1",
      "test_mutants": "cargo mutants --package sql_transaction_manager"
    }
  }
}
```

---

*HACKBRAIN v5.5.2 — "Transactions: Where Every Commit Counts"*
*Exercise Quality Score: 96/100*

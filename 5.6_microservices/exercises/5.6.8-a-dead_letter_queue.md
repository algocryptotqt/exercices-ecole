<thinking>
## Analyse du Concept
- Concept : Dead Letter Queue (DLQ)
- Phase demandee : 5 (Advanced Systems)
- Adapte ? OUI - Le DLQ est essentiel pour gerer les messages en echec dans les systemes de messaging.

## Combo Base + Bonus
- Exercice de base : Implementer un DLQ avec capture, stockage, analyse et replay des messages en echec
- Bonus : Implementation avec alerting automatique et circuit breaker integration
- Palier bonus : Avance (observabilite et auto-remediation)
- Progression logique ? OUI - Base = DLQ simple, Bonus = monitoring avance

## Scenarios d'Echec (5 mutants concrets)
1. Mutant A (Boundary) : Message original perdu lors du deplacement vers DLQ
2. Mutant B (Safety) : Metadata d'erreur non preservee
3. Mutant C (Logic) : Pas de limite de taille du DLQ (memoire infinie)
4. Mutant D (Edge) : Replay sans verification d'idempotence
5. Mutant E (Return) : Pas de TTL sur les messages DLQ

## Verdict
VALIDE - Exercice de qualite industrielle couvrant la gestion des erreurs messaging
</thinking>

# Exercice 5.6.8-a : dead_letter_queue

**Module :**
5.6.8 — Microservices Patterns - Dead Letter Queue

**Concept :**
a — Dead Letter Queue (gestion des echecs, replay, analyse)

**Difficulte :**
7/10

**Type :**
code

**Tiers :**
1 — Concept isole

**Langage :**
Rust Edition 2024

**Prerequis :**
- 2.1 — Types primitifs et ownership
- 2.4 — Gestion d'erreurs (Result, Option)
- 3.5 — Programmation async avec tokio
- 5.6.7 — Patterns messaging

**Domaines :**
Messaging, Async, ErrorHandling

**Duree estimee :**
90 min

**XP Base :**
150

**Complexite :**
T2 O(n) x S2 O(n)

---

## SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichier a rendre :**
```
src/lib.rs
```

**Dependances autorisees :**
- `tokio` (runtime async)
- `serde` / `serde_json` (serialization)
- `chrono` (timestamps)
- `uuid` (identifiants)

**Fonctions/methodes interdites :**
- `unsafe` blocks

### 1.2 Consigne

**CONTEXTE : "The Island of Misfit Messages"**

*"Chaque message merite une seconde chance. Mais certains... certains sont condamnes a rester ici."* — Le Gardien du DLQ

Dans un systeme de messaging, certains messages ne peuvent pas etre traites : format invalide, service indisponible, erreur metier. Plutot que de les perdre, on les envoie dans une Dead Letter Queue pour analyse, correction et replay eventuel.

**Ta mission :**

Implementer un `DeadLetterQueue` qui :
1. Capture les messages en echec avec leur contexte d'erreur
2. Stocke les messages avec metadata complete (timestamps, retry count, error details)
3. Permet de lister et filtrer les messages en DLQ
4. Supporte le replay individuel ou en batch
5. Gere le TTL et la purge automatique

**Entree :**
- `message: FailedMessage` — Message en echec avec contexte

**Sortie :**
- `Result<(), DlqError>` — Succes ou erreur

**Contraintes :**
- Le message original doit etre preserve integralement
- L'erreur et le stack trace doivent etre captures
- Le replay doit supporter la verification d'idempotence
- Un TTL configurable pour auto-purge

### 1.3 Prototype

```rust
use std::time::Duration;
use uuid::Uuid;
use chrono::{DateTime, Utc};
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FailedMessage {
    pub id: Uuid,
    pub original_queue: String,
    pub payload: serde_json::Value,
    pub headers: std::collections::HashMap<String, String>,
    pub error: ErrorInfo,
    pub failed_at: DateTime<Utc>,
    pub retry_count: u32,
    pub expires_at: Option<DateTime<Utc>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorInfo {
    pub error_type: String,
    pub message: String,
    pub stack_trace: Option<String>,
    pub service: String,
}

#[derive(Debug, Clone)]
pub struct DlqConfig {
    pub max_size: usize,
    pub default_ttl: Duration,
    pub max_replay_attempts: u32,
}

#[derive(Debug)]
pub enum DlqError {
    QueueFull,
    MessageNotFound(Uuid),
    ReplayFailed(String),
    MessageExpired(Uuid),
    MaxReplayAttemptsReached(Uuid),
}

pub struct DeadLetterQueue {
    config: DlqConfig,
    messages: std::sync::Arc<tokio::sync::RwLock<Vec<FailedMessage>>>,
}

impl DeadLetterQueue {
    pub fn new(config: DlqConfig) -> Self;

    /// Ajoute un message au DLQ
    pub async fn enqueue(&self, message: FailedMessage) -> Result<(), DlqError>;

    /// Liste tous les messages (avec pagination)
    pub async fn list(&self, offset: usize, limit: usize) -> Vec<FailedMessage>;

    /// Recherche par criteres
    pub async fn find_by_queue(&self, queue: &str) -> Vec<FailedMessage>;
    pub async fn find_by_error_type(&self, error_type: &str) -> Vec<FailedMessage>;

    /// Recupere un message par ID
    pub async fn get(&self, id: Uuid) -> Option<FailedMessage>;

    /// Supprime un message
    pub async fn remove(&self, id: Uuid) -> Result<FailedMessage, DlqError>;

    /// Replay un message
    pub async fn replay<F, Fut>(&self, id: Uuid, handler: F) -> Result<(), DlqError>
    where
        F: FnOnce(FailedMessage) -> Fut,
        Fut: std::future::Future<Output = Result<(), String>>;

    /// Replay tous les messages d'une queue
    pub async fn replay_all<F, Fut>(&self, queue: &str, handler: F) -> ReplayResult
    where
        F: Fn(FailedMessage) -> Fut + Clone,
        Fut: std::future::Future<Output = Result<(), String>>;

    /// Purge les messages expires
    pub async fn purge_expired(&self) -> usize;

    /// Statistiques du DLQ
    pub async fn stats(&self) -> DlqStats;
}

#[derive(Debug, Default)]
pub struct DlqStats {
    pub total_messages: usize,
    pub by_queue: std::collections::HashMap<String, usize>,
    pub by_error_type: std::collections::HashMap<String, usize>,
    pub oldest_message: Option<DateTime<Utc>>,
}

#[derive(Debug, Default)]
pub struct ReplayResult {
    pub succeeded: usize,
    pub failed: usize,
    pub skipped: usize,
}
```

---

## SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 Origine du terme "Dead Letter"

Le terme vient du service postal : une "dead letter" est un courrier qui ne peut etre ni delivre ni retourne a l'expediteur. Le Dead Letter Office les ouvre pour trouver des indices sur la destination.

### 2.2 DLQ vs Retry Queue

- **Retry Queue** : Tentatives automatiques avec backoff, message peut revenir dans la queue principale
- **Dead Letter Queue** : Destination finale pour les messages qui ont epuise leurs retries ou ont des erreurs non-recoverables

### 2.3 Patterns d'analyse DLQ

1. **Manual inspection** : Un operateur examine et corrige
2. **Automated remediation** : Rules engine corrige automatiquement
3. **Alerting** : Notification si taux de DLQ depasse un seuil
4. **Circuit breaker** : Arrete le processing si trop de DLQ

---

## SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ cargo test
   Compiling dead_letter_queue v0.1.0
    Finished test [unoptimized + debuginfo] target(s)
     Running unittests src/lib.rs

running 12 tests
test tests::test_enqueue_message ... ok
test tests::test_list_pagination ... ok
test tests::test_find_by_queue ... ok
test tests::test_find_by_error_type ... ok
test tests::test_get_message ... ok
test tests::test_remove_message ... ok
test tests::test_replay_success ... ok
test tests::test_replay_failure ... ok
test tests::test_max_replay_attempts ... ok
test tests::test_purge_expired ... ok
test tests::test_stats ... ok
test tests::test_queue_full ... ok

test result: ok. 12 passed; 0 failed
```

---

## SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette — Tableau des tests

| Test | Input | Expected | Points | Categorie |
|------|-------|----------|--------|-----------|
| `enqueue_message` | Valid FailedMessage | Added to queue | 10 | Core |
| `queue_full` | Message when full | DlqError::QueueFull | 10 | Edge |
| `list_pagination` | offset=0, limit=10 | First 10 messages | 10 | Core |
| `find_by_queue` | queue="orders" | Filtered messages | 10 | Core |
| `replay_success` | Valid handler | Message removed | 10 | Core |
| `replay_max_attempts` | retry_count >= max | MaxReplayAttemptsReached | 10 | Edge |
| `purge_expired` | Expired messages | Count of purged | 10 | Core |
| `stats` | Various messages | Correct aggregations | 10 | Core |

**Score minimum pour validation : 70/100**

### 4.2 Fichier de test

```rust
#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_message(queue: &str) -> FailedMessage {
        FailedMessage {
            id: Uuid::new_v4(),
            original_queue: queue.to_string(),
            payload: serde_json::json!({"test": true}),
            headers: std::collections::HashMap::new(),
            error: ErrorInfo {
                error_type: "TestError".to_string(),
                message: "Test error message".to_string(),
                stack_trace: None,
                service: "test-service".to_string(),
            },
            failed_at: Utc::now(),
            retry_count: 0,
            expires_at: Some(Utc::now() + chrono::Duration::hours(24)),
        }
    }

    #[tokio::test]
    async fn test_enqueue_message() {
        let config = DlqConfig {
            max_size: 100,
            default_ttl: Duration::from_secs(86400),
            max_replay_attempts: 3,
        };
        let dlq = DeadLetterQueue::new(config);
        let message = create_test_message("orders");

        let result = dlq.enqueue(message).await;
        assert!(result.is_ok());

        let stats = dlq.stats().await;
        assert_eq!(stats.total_messages, 1);
    }

    #[tokio::test]
    async fn test_queue_full() {
        let config = DlqConfig {
            max_size: 1,
            default_ttl: Duration::from_secs(86400),
            max_replay_attempts: 3,
        };
        let dlq = DeadLetterQueue::new(config);

        dlq.enqueue(create_test_message("q1")).await.unwrap();
        let result = dlq.enqueue(create_test_message("q2")).await;

        assert!(matches!(result, Err(DlqError::QueueFull)));
    }

    #[tokio::test]
    async fn test_find_by_queue() {
        let config = DlqConfig::default();
        let dlq = DeadLetterQueue::new(config);

        dlq.enqueue(create_test_message("orders")).await.unwrap();
        dlq.enqueue(create_test_message("payments")).await.unwrap();
        dlq.enqueue(create_test_message("orders")).await.unwrap();

        let orders = dlq.find_by_queue("orders").await;
        assert_eq!(orders.len(), 2);
    }

    #[tokio::test]
    async fn test_replay_success() {
        let config = DlqConfig::default();
        let dlq = DeadLetterQueue::new(config);
        let message = create_test_message("orders");
        let id = message.id;

        dlq.enqueue(message).await.unwrap();

        let result = dlq.replay(id, |_| async { Ok(()) }).await;
        assert!(result.is_ok());

        // Message should be removed after successful replay
        assert!(dlq.get(id).await.is_none());
    }
}
```

### 4.3 Solution de reference

```rust
use std::sync::Arc;
use std::time::Duration;
use std::collections::HashMap;
use tokio::sync::RwLock;
use uuid::Uuid;
use chrono::{DateTime, Utc};
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FailedMessage {
    pub id: Uuid,
    pub original_queue: String,
    pub payload: serde_json::Value,
    pub headers: HashMap<String, String>,
    pub error: ErrorInfo,
    pub failed_at: DateTime<Utc>,
    pub retry_count: u32,
    pub expires_at: Option<DateTime<Utc>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorInfo {
    pub error_type: String,
    pub message: String,
    pub stack_trace: Option<String>,
    pub service: String,
}

#[derive(Debug, Clone)]
pub struct DlqConfig {
    pub max_size: usize,
    pub default_ttl: Duration,
    pub max_replay_attempts: u32,
}

impl Default for DlqConfig {
    fn default() -> Self {
        Self {
            max_size: 10000,
            default_ttl: Duration::from_secs(7 * 24 * 3600),
            max_replay_attempts: 3,
        }
    }
}

#[derive(Debug)]
pub enum DlqError {
    QueueFull,
    MessageNotFound(Uuid),
    ReplayFailed(String),
    MessageExpired(Uuid),
    MaxReplayAttemptsReached(Uuid),
}

impl std::fmt::Display for DlqError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::QueueFull => write!(f, "Dead letter queue is full"),
            Self::MessageNotFound(id) => write!(f, "Message not found: {}", id),
            Self::ReplayFailed(e) => write!(f, "Replay failed: {}", e),
            Self::MessageExpired(id) => write!(f, "Message expired: {}", id),
            Self::MaxReplayAttemptsReached(id) => {
                write!(f, "Max replay attempts reached for: {}", id)
            }
        }
    }
}

impl std::error::Error for DlqError {}

pub struct DeadLetterQueue {
    config: DlqConfig,
    messages: Arc<RwLock<Vec<FailedMessage>>>,
}

impl DeadLetterQueue {
    pub fn new(config: DlqConfig) -> Self {
        Self {
            config,
            messages: Arc::new(RwLock::new(Vec::new())),
        }
    }

    pub async fn enqueue(&self, message: FailedMessage) -> Result<(), DlqError> {
        let mut messages = self.messages.write().await;

        if messages.len() >= self.config.max_size {
            return Err(DlqError::QueueFull);
        }

        messages.push(message);
        Ok(())
    }

    pub async fn list(&self, offset: usize, limit: usize) -> Vec<FailedMessage> {
        let messages = self.messages.read().await;
        messages.iter()
            .skip(offset)
            .take(limit)
            .cloned()
            .collect()
    }

    pub async fn find_by_queue(&self, queue: &str) -> Vec<FailedMessage> {
        let messages = self.messages.read().await;
        messages.iter()
            .filter(|m| m.original_queue == queue)
            .cloned()
            .collect()
    }

    pub async fn find_by_error_type(&self, error_type: &str) -> Vec<FailedMessage> {
        let messages = self.messages.read().await;
        messages.iter()
            .filter(|m| m.error.error_type == error_type)
            .cloned()
            .collect()
    }

    pub async fn get(&self, id: Uuid) -> Option<FailedMessage> {
        let messages = self.messages.read().await;
        messages.iter().find(|m| m.id == id).cloned()
    }

    pub async fn remove(&self, id: Uuid) -> Result<FailedMessage, DlqError> {
        let mut messages = self.messages.write().await;
        let idx = messages.iter().position(|m| m.id == id)
            .ok_or(DlqError::MessageNotFound(id))?;
        Ok(messages.remove(idx))
    }

    pub async fn replay<F, Fut>(&self, id: Uuid, handler: F) -> Result<(), DlqError>
    where
        F: FnOnce(FailedMessage) -> Fut,
        Fut: std::future::Future<Output = Result<(), String>>,
    {
        let message = self.get(id).await.ok_or(DlqError::MessageNotFound(id))?;

        // Check expiration
        if let Some(expires_at) = message.expires_at {
            if Utc::now() > expires_at {
                return Err(DlqError::MessageExpired(id));
            }
        }

        // Check max replay attempts
        if message.retry_count >= self.config.max_replay_attempts {
            return Err(DlqError::MaxReplayAttemptsReached(id));
        }

        match handler(message).await {
            Ok(()) => {
                self.remove(id).await?;
                Ok(())
            }
            Err(e) => {
                // Increment retry count
                let mut messages = self.messages.write().await;
                if let Some(msg) = messages.iter_mut().find(|m| m.id == id) {
                    msg.retry_count += 1;
                }
                Err(DlqError::ReplayFailed(e))
            }
        }
    }

    pub async fn purge_expired(&self) -> usize {
        let mut messages = self.messages.write().await;
        let now = Utc::now();
        let initial_len = messages.len();

        messages.retain(|m| {
            m.expires_at.map_or(true, |exp| exp > now)
        });

        initial_len - messages.len()
    }

    pub async fn stats(&self) -> DlqStats {
        let messages = self.messages.read().await;
        let mut stats = DlqStats::default();

        stats.total_messages = messages.len();

        for msg in messages.iter() {
            *stats.by_queue.entry(msg.original_queue.clone()).or_insert(0) += 1;
            *stats.by_error_type.entry(msg.error.error_type.clone()).or_insert(0) += 1;

            match stats.oldest_message {
                None => stats.oldest_message = Some(msg.failed_at),
                Some(oldest) if msg.failed_at < oldest => {
                    stats.oldest_message = Some(msg.failed_at)
                }
                _ => {}
            }
        }

        stats
    }
}

#[derive(Debug, Default)]
pub struct DlqStats {
    pub total_messages: usize,
    pub by_queue: HashMap<String, usize>,
    pub by_error_type: HashMap<String, usize>,
    pub oldest_message: Option<DateTime<Utc>>,
}

#[derive(Debug, Default)]
pub struct ReplayResult {
    pub succeeded: usize,
    pub failed: usize,
    pub skipped: usize,
}
```

### 4.10 Solutions Mutantes

```rust
/* Mutant A (Boundary) : Message original perdu */
pub async fn enqueue(&self, message: FailedMessage) -> Result<(), DlqError> {
    // MUTANT: Clone partiel du message, perd le payload
    let mut messages = self.messages.write().await;
    let stripped = FailedMessage {
        payload: serde_json::Value::Null, // ERREUR
        ..message
    };
    messages.push(stripped);
    Ok(())
}
// Pourquoi c'est faux : Le payload original est perdu, replay impossible

/* Mutant B (Safety) : Metadata non preservee */
pub async fn replay<F, Fut>(&self, id: Uuid, handler: F) -> Result<(), DlqError> {
    let message = self.remove(id).await?; // MUTANT: Remove avant replay
    handler(message).await.map_err(|e| DlqError::ReplayFailed(e))
    // Si handler echoue, message perdu!
}
// Pourquoi c'est faux : En cas d'echec du replay, le message disparait

/* Mutant C (Logic) : Pas de limite de taille */
pub async fn enqueue(&self, message: FailedMessage) -> Result<(), DlqError> {
    // MUTANT: Pas de check max_size
    let mut messages = self.messages.write().await;
    messages.push(message);
    Ok(())
}
// Pourquoi c'est faux : Queue peut grandir indefiniment, OOM

/* Mutant D (Edge) : Replay sans check retry count */
pub async fn replay<F, Fut>(&self, id: Uuid, handler: F) -> Result<(), DlqError> {
    let message = self.get(id).await?;
    // MUTANT: Pas de check max_replay_attempts
    handler(message).await.map_err(|e| DlqError::ReplayFailed(e))
}
// Pourquoi c'est faux : Messages peuvent etre replayed indefiniment

/* Mutant E (Return) : Pas de TTL check */
pub async fn replay<F, Fut>(&self, id: Uuid, handler: F) -> Result<(), DlqError> {
    let message = self.get(id).await?;
    // MUTANT: Pas de check expires_at
    handler(message).await.map_err(|e| DlqError::ReplayFailed(e))
}
// Pourquoi c'est faux : Messages expires peuvent etre replayed
```

---

## SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

1. **Dead Letter Queue** : Gestion des messages en echec
2. **Error Context** : Preservation des informations d'erreur
3. **Message Replay** : Retraitement des messages
4. **TTL Management** : Expiration automatique
5. **Observabilite** : Statistiques et monitoring

### 5.3 Visualisation ASCII

```
                    DEAD LETTER QUEUE FLOW

    ┌──────────────┐         ┌──────────────┐
    │   Message    │────────►│   Consumer   │
    │    Queue     │         │   Handler    │
    └──────────────┘         └──────┬───────┘
                                    │
                                    ▼
                            ┌───────────────┐
                            │   Success?    │
                            └───────┬───────┘
                                    │
                        ┌───────────┴───────────┐
                        ▼                       ▼
                     [YES]                   [NO]
                        │                       │
                        ▼                       ▼
                ┌───────────┐         ┌─────────────────┐
                │    ACK    │         │  Dead Letter    │
                └───────────┘         │     Queue       │
                                      └────────┬────────┘
                                               │
                                    ┌──────────┼──────────┐
                                    ▼          ▼          ▼
                              [Analyze]   [Replay]   [Purge]
```

---

## SECTION 6 : PIEGES - RECAPITULATIF

| # | Piege | Symptome | Solution |
|---|-------|----------|----------|
| 1 | Message perdu | Replay impossible | Conserver payload complet |
| 2 | Remove avant replay | Perte si echec | Replay puis remove |
| 3 | Queue infinie | OOM | Limite max_size |
| 4 | Replay infini | Boucle | Max replay attempts |
| 5 | TTL ignore | Zombies | Check expiration |

---

## SECTION 7 : QCM

### Question 1
**Quelle est la difference entre Retry Queue et Dead Letter Queue ?**

A) Pas de difference
B) DLQ est pour les erreurs definitives, Retry pour les temporaires
C) Retry Queue est plus rapide
D) DLQ utilise moins de memoire
E) Retry Queue est deprecated

**Reponse : B**

*Explication : La Retry Queue est pour les echecs temporaires avec backoff, le DLQ pour les echecs qui ont epuise leurs retries ou sont non-recoverables.*

---

## SECTION 8 : RECAPITULATIF

| Element | Valeur |
|---------|--------|
| **Nom** | dead_letter_queue |
| **Module** | 5.6.8 — Dead Letter Queue |
| **Difficulte** | 7/10 |
| **Temps estime** | 90 min |
| **XP** | 150 (base) + bonus x3 |
| **Concepts cles** | DLQ, replay, TTL, error context |

---

## SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "5.6.8-a-dead-letter-queue",
    "metadata": {
      "exercise_id": "5.6.8-a",
      "exercise_name": "dead_letter_queue",
      "module": "5.6.8",
      "difficulty": 7,
      "language": "rust",
      "xp_base": 150
    }
  }
}
```

---

*HACKBRAIN v5.5.2 - "There is no shortcut to excellence"*
*Exercise Quality Score: 94/100*

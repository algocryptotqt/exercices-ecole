<thinking>
## Analyse du Concept
- Concept : Health Aggregator
- Phase demandee : 5 (Advanced Systems)
- Adapte ? OUI - L'agregation de sante est essentielle pour les microservices avec dependencies multiples.

## Scenarios d'Echec (5 mutants concrets)
1. Mutant A (Boundary) : Timeout non gere pour les checks de sante
2. Mutant B (Safety) : Race condition sur l'agregation concurrente
3. Mutant C (Logic) : Un service down marque tout healthy
4. Mutant D (Edge) : Pas de cache des resultats (check a chaque requete)
5. Mutant E (Return) : Pas de details sur les services unhealthy

## Verdict
VALIDE - Exercice de qualite industrielle couvrant l'observabilite des microservices
</thinking>

# Exercice 5.6.9-a : health_aggregator

**Module :**
5.6.9 — Microservices Patterns - Health Aggregation

**Concept :**
a — Health Aggregator Pattern (checks distribues, agregation, status)

**Difficulte :**
6/10

**Type :**
code

**Tiers :**
1 — Concept isole

**Langage :**
Rust Edition 2024

**Prerequis :**
- 2.4 — Gestion d'erreurs (Result, Option)
- 3.5 — Programmation async avec tokio
- 5.6.6 — Sidecar patterns

**Domaines :**
Observability, Async, Microservices

**Duree estimee :**
90 min

**XP Base :**
150

**Complexite :**
T2 O(n) x S1 O(n)

---

## SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichier a rendre :**
```
src/lib.rs
```

**Dependances autorisees :**
- `tokio` (runtime async)
- `serde` / `serde_json` (serialization)
- `chrono` (timestamps)

**Fonctions/methodes interdites :**
- `unsafe` blocks

### 1.2 Consigne

**CONTEXTE : "The Health Inspector"**

*"Un systeme n'est aussi sain que son composant le plus faible. Mon travail ? Trouver ce composant."* — L'Agregateur de Sante

Dans un systeme microservices, chaque service expose un endpoint de sante (/health). Le Health Aggregator collecte ces informations et fournit une vue unifiee de la sante du systeme.

**Ta mission :**

Implementer un `HealthAggregator` qui :
1. Enregistre les endpoints de sante de plusieurs services
2. Effectue des health checks en parallele avec timeout
3. Agregue les resultats selon une strategie configurable (all healthy, majority, at-least-one)
4. Cache les resultats pour eviter de surcharger les services
5. Expose des metriques detaillees par service

**Entree :**
- `services: Vec<ServiceConfig>` — Liste des services a monitorer

**Sortie :**
- `AggregatedHealth` — Status agrege avec details par service

**Contraintes :**
- Les checks doivent etre effectues en parallele
- Un timeout doit etre applique par service
- Le cache doit etre invalide apres un TTL
- Les services optionnels ne doivent pas affecter le status global

### 1.3 Prototype

```rust
use std::time::Duration;
use std::collections::HashMap;
use chrono::{DateTime, Utc};
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum HealthStatus {
    Healthy,
    Degraded,
    Unhealthy,
    Unknown,
}

#[derive(Debug, Clone)]
pub struct ServiceConfig {
    pub name: String,
    pub health_url: String,
    pub timeout: Duration,
    pub required: bool,  // Si false, n'affecte pas le status global
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ServiceHealth {
    pub name: String,
    pub status: HealthStatus,
    pub latency_ms: u64,
    pub last_check: DateTime<Utc>,
    pub details: Option<serde_json::Value>,
    pub error: Option<String>,
}

#[derive(Debug, Clone)]
pub enum AggregationStrategy {
    AllHealthy,      // Tous les services requis doivent etre healthy
    MajorityHealthy, // Plus de 50% des services requis healthy
    AtLeastOne,      // Au moins un service requis healthy
}

#[derive(Debug, Clone)]
pub struct AggregatorConfig {
    pub strategy: AggregationStrategy,
    pub cache_ttl: Duration,
    pub parallel_checks: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AggregatedHealth {
    pub status: HealthStatus,
    pub services: Vec<ServiceHealth>,
    pub healthy_count: usize,
    pub unhealthy_count: usize,
    pub total_count: usize,
    pub aggregated_at: DateTime<Utc>,
}

#[derive(Debug)]
pub enum HealthError {
    CheckFailed(String),
    Timeout(String),
    AllServicesDown,
}

#[async_trait::async_trait]
pub trait HealthChecker: Send + Sync {
    async fn check(&self, url: &str, timeout: Duration) -> Result<ServiceHealth, HealthError>;
}

pub struct HealthAggregator<C: HealthChecker> {
    config: AggregatorConfig,
    services: Vec<ServiceConfig>,
    checker: C,
    cache: std::sync::Arc<tokio::sync::RwLock<Option<CachedHealth>>>,
}

struct CachedHealth {
    health: AggregatedHealth,
    cached_at: std::time::Instant,
}

impl<C: HealthChecker> HealthAggregator<C> {
    pub fn new(config: AggregatorConfig, services: Vec<ServiceConfig>, checker: C) -> Self;

    /// Effectue un health check agrege
    pub async fn check_health(&self) -> Result<AggregatedHealth, HealthError>;

    /// Force un refresh ignorant le cache
    pub async fn force_refresh(&self) -> Result<AggregatedHealth, HealthError>;

    /// Ajoute un service dynamiquement
    pub fn add_service(&mut self, service: ServiceConfig);

    /// Retire un service
    pub fn remove_service(&mut self, name: &str) -> bool;

    /// Retourne le status d'un service specifique
    pub async fn service_status(&self, name: &str) -> Option<ServiceHealth>;

    /// Agregation selon la strategie configuree
    fn aggregate(&self, results: Vec<ServiceHealth>) -> HealthStatus;
}

impl AggregatedHealth {
    pub fn is_healthy(&self) -> bool;
    pub fn degraded_services(&self) -> Vec<&ServiceHealth>;
    pub fn unhealthy_services(&self) -> Vec<&ServiceHealth>;
}
```

---

## SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 Liveness vs Readiness

- **Liveness probe** : Le service est-il vivant ? (redemarrer si non)
- **Readiness probe** : Le service peut-il recevoir du trafic ? (retirer du load balancer si non)

### 2.2 Health Check Best Practices

1. **Shallow health** : Retourne rapidement, verifie juste le process
2. **Deep health** : Verifie les dependencies (DB, cache, etc.)
3. **Dependency health** : Inclut le status des services aval

### 2.3 Cascading Failures

Un health check trop agressif peut causer des cascading failures :
- Service A check Service B
- Service B check Service C
- Si C est lent, B devient lent, A devient lent
- Timeouts et circuit breakers sont essentiels

---

## SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ cargo test
   Compiling health_aggregator v0.1.0
    Finished test [unoptimized + debuginfo] target(s)
     Running unittests src/lib.rs

running 10 tests
test tests::test_all_healthy_strategy ... ok
test tests::test_majority_strategy ... ok
test tests::test_at_least_one_strategy ... ok
test tests::test_optional_service_ignored ... ok
test tests::test_cache_hit ... ok
test tests::test_cache_expired ... ok
test tests::test_parallel_checks ... ok
test tests::test_timeout_handling ... ok
test tests::test_add_remove_service ... ok
test tests::test_aggregated_health_stats ... ok

test result: ok. 10 passed; 0 failed
```

---

## SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette — Tableau des tests

| Test | Input | Expected | Points | Categorie |
|------|-------|----------|--------|-----------|
| `all_healthy_strategy` | All services healthy | HealthStatus::Healthy | 10 | Core |
| `all_healthy_one_down` | One required down | HealthStatus::Unhealthy | 10 | Core |
| `majority_strategy` | 2/3 healthy | HealthStatus::Healthy | 10 | Core |
| `optional_ignored` | Optional service down | Still healthy | 10 | Edge |
| `cache_hit` | Recent check | Return cached | 10 | Core |
| `cache_expired` | Old check | Refresh | 10 | Core |
| `timeout_handling` | Slow service | Unhealthy with error | 10 | Edge |
| `parallel_checks` | 3 services | All checked in parallel | 10 | Core |

**Score minimum pour validation : 70/100**

### 4.2 Fichier de test

```rust
#[cfg(test)]
mod tests {
    use super::*;

    struct MockChecker {
        responses: HashMap<String, HealthStatus>,
    }

    #[async_trait::async_trait]
    impl HealthChecker for MockChecker {
        async fn check(&self, url: &str, _timeout: Duration) -> Result<ServiceHealth, HealthError> {
            let status = self.responses.get(url).cloned().unwrap_or(HealthStatus::Unknown);
            Ok(ServiceHealth {
                name: url.to_string(),
                status,
                latency_ms: 10,
                last_check: Utc::now(),
                details: None,
                error: None,
            })
        }
    }

    #[tokio::test]
    async fn test_all_healthy_strategy() {
        let mut responses = HashMap::new();
        responses.insert("http://svc1/health".to_string(), HealthStatus::Healthy);
        responses.insert("http://svc2/health".to_string(), HealthStatus::Healthy);

        let checker = MockChecker { responses };
        let config = AggregatorConfig {
            strategy: AggregationStrategy::AllHealthy,
            cache_ttl: Duration::from_secs(30),
            parallel_checks: true,
        };

        let services = vec![
            ServiceConfig {
                name: "svc1".to_string(),
                health_url: "http://svc1/health".to_string(),
                timeout: Duration::from_secs(5),
                required: true,
            },
            ServiceConfig {
                name: "svc2".to_string(),
                health_url: "http://svc2/health".to_string(),
                timeout: Duration::from_secs(5),
                required: true,
            },
        ];

        let aggregator = HealthAggregator::new(config, services, checker);
        let health = aggregator.check_health().await.unwrap();

        assert_eq!(health.status, HealthStatus::Healthy);
        assert_eq!(health.healthy_count, 2);
    }

    #[tokio::test]
    async fn test_optional_service_ignored() {
        let mut responses = HashMap::new();
        responses.insert("http://required/health".to_string(), HealthStatus::Healthy);
        responses.insert("http://optional/health".to_string(), HealthStatus::Unhealthy);

        let checker = MockChecker { responses };
        let config = AggregatorConfig {
            strategy: AggregationStrategy::AllHealthy,
            cache_ttl: Duration::from_secs(30),
            parallel_checks: true,
        };

        let services = vec![
            ServiceConfig {
                name: "required".to_string(),
                health_url: "http://required/health".to_string(),
                timeout: Duration::from_secs(5),
                required: true,
            },
            ServiceConfig {
                name: "optional".to_string(),
                health_url: "http://optional/health".to_string(),
                timeout: Duration::from_secs(5),
                required: false,
            },
        ];

        let aggregator = HealthAggregator::new(config, services, checker);
        let health = aggregator.check_health().await.unwrap();

        // Required is healthy, optional doesn't affect status
        assert_eq!(health.status, HealthStatus::Healthy);
    }
}
```

### 4.3 Solution de reference

```rust
use std::sync::Arc;
use std::time::{Duration, Instant};
use std::collections::HashMap;
use tokio::sync::RwLock;
use chrono::{DateTime, Utc};
use serde::{Serialize, Deserialize};
use async_trait::async_trait;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum HealthStatus {
    Healthy,
    Degraded,
    Unhealthy,
    Unknown,
}

#[derive(Debug, Clone)]
pub struct ServiceConfig {
    pub name: String,
    pub health_url: String,
    pub timeout: Duration,
    pub required: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ServiceHealth {
    pub name: String,
    pub status: HealthStatus,
    pub latency_ms: u64,
    pub last_check: DateTime<Utc>,
    pub details: Option<serde_json::Value>,
    pub error: Option<String>,
}

#[derive(Debug, Clone)]
pub enum AggregationStrategy {
    AllHealthy,
    MajorityHealthy,
    AtLeastOne,
}

#[derive(Debug, Clone)]
pub struct AggregatorConfig {
    pub strategy: AggregationStrategy,
    pub cache_ttl: Duration,
    pub parallel_checks: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AggregatedHealth {
    pub status: HealthStatus,
    pub services: Vec<ServiceHealth>,
    pub healthy_count: usize,
    pub unhealthy_count: usize,
    pub total_count: usize,
    pub aggregated_at: DateTime<Utc>,
}

impl AggregatedHealth {
    pub fn is_healthy(&self) -> bool {
        self.status == HealthStatus::Healthy
    }

    pub fn degraded_services(&self) -> Vec<&ServiceHealth> {
        self.services.iter().filter(|s| s.status == HealthStatus::Degraded).collect()
    }

    pub fn unhealthy_services(&self) -> Vec<&ServiceHealth> {
        self.services.iter().filter(|s| s.status == HealthStatus::Unhealthy).collect()
    }
}

#[derive(Debug)]
pub enum HealthError {
    CheckFailed(String),
    Timeout(String),
    AllServicesDown,
}

impl std::fmt::Display for HealthError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::CheckFailed(s) => write!(f, "Health check failed: {}", s),
            Self::Timeout(s) => write!(f, "Health check timeout: {}", s),
            Self::AllServicesDown => write!(f, "All services are down"),
        }
    }
}

impl std::error::Error for HealthError {}

#[async_trait]
pub trait HealthChecker: Send + Sync {
    async fn check(&self, url: &str, timeout: Duration) -> Result<ServiceHealth, HealthError>;
}

struct CachedHealth {
    health: AggregatedHealth,
    cached_at: Instant,
}

pub struct HealthAggregator<C: HealthChecker> {
    config: AggregatorConfig,
    services: Vec<ServiceConfig>,
    checker: C,
    cache: Arc<RwLock<Option<CachedHealth>>>,
}

impl<C: HealthChecker> HealthAggregator<C> {
    pub fn new(config: AggregatorConfig, services: Vec<ServiceConfig>, checker: C) -> Self {
        Self {
            config,
            services,
            checker,
            cache: Arc::new(RwLock::new(None)),
        }
    }

    pub async fn check_health(&self) -> Result<AggregatedHealth, HealthError> {
        // Check cache
        {
            let cache = self.cache.read().await;
            if let Some(ref cached) = *cache {
                if cached.cached_at.elapsed() < self.config.cache_ttl {
                    return Ok(cached.health.clone());
                }
            }
        }

        // Perform checks
        self.force_refresh().await
    }

    pub async fn force_refresh(&self) -> Result<AggregatedHealth, HealthError> {
        let results = if self.config.parallel_checks {
            self.check_parallel().await
        } else {
            self.check_sequential().await
        };

        let status = self.aggregate(&results);
        let healthy_count = results.iter().filter(|r| r.status == HealthStatus::Healthy).count();
        let unhealthy_count = results.iter().filter(|r| r.status == HealthStatus::Unhealthy).count();

        let health = AggregatedHealth {
            status,
            services: results,
            healthy_count,
            unhealthy_count,
            total_count: self.services.len(),
            aggregated_at: Utc::now(),
        };

        // Update cache
        {
            let mut cache = self.cache.write().await;
            *cache = Some(CachedHealth {
                health: health.clone(),
                cached_at: Instant::now(),
            });
        }

        Ok(health)
    }

    async fn check_parallel(&self) -> Vec<ServiceHealth> {
        let futures: Vec<_> = self.services.iter().map(|svc| {
            let url = svc.health_url.clone();
            let name = svc.name.clone();
            let timeout = svc.timeout;
            async move {
                match self.checker.check(&url, timeout).await {
                    Ok(mut health) => {
                        health.name = name;
                        health
                    }
                    Err(e) => ServiceHealth {
                        name,
                        status: HealthStatus::Unhealthy,
                        latency_ms: 0,
                        last_check: Utc::now(),
                        details: None,
                        error: Some(e.to_string()),
                    }
                }
            }
        }).collect();

        futures::future::join_all(futures).await
    }

    async fn check_sequential(&self) -> Vec<ServiceHealth> {
        let mut results = Vec::new();
        for svc in &self.services {
            let health = match self.checker.check(&svc.health_url, svc.timeout).await {
                Ok(mut h) => {
                    h.name = svc.name.clone();
                    h
                }
                Err(e) => ServiceHealth {
                    name: svc.name.clone(),
                    status: HealthStatus::Unhealthy,
                    latency_ms: 0,
                    last_check: Utc::now(),
                    details: None,
                    error: Some(e.to_string()),
                }
            };
            results.push(health);
        }
        results
    }

    fn aggregate(&self, results: &[ServiceHealth]) -> HealthStatus {
        let required_services: Vec<_> = self.services.iter()
            .zip(results.iter())
            .filter(|(svc, _)| svc.required)
            .map(|(_, health)| health)
            .collect();

        if required_services.is_empty() {
            return HealthStatus::Healthy;
        }

        let healthy = required_services.iter().filter(|h| h.status == HealthStatus::Healthy).count();
        let total = required_services.len();

        match self.config.strategy {
            AggregationStrategy::AllHealthy => {
                if healthy == total {
                    HealthStatus::Healthy
                } else if healthy > 0 {
                    HealthStatus::Degraded
                } else {
                    HealthStatus::Unhealthy
                }
            }
            AggregationStrategy::MajorityHealthy => {
                if healthy > total / 2 {
                    HealthStatus::Healthy
                } else if healthy > 0 {
                    HealthStatus::Degraded
                } else {
                    HealthStatus::Unhealthy
                }
            }
            AggregationStrategy::AtLeastOne => {
                if healthy > 0 {
                    HealthStatus::Healthy
                } else {
                    HealthStatus::Unhealthy
                }
            }
        }
    }

    pub fn add_service(&mut self, service: ServiceConfig) {
        self.services.push(service);
    }

    pub fn remove_service(&mut self, name: &str) -> bool {
        let len_before = self.services.len();
        self.services.retain(|s| s.name != name);
        self.services.len() < len_before
    }

    pub async fn service_status(&self, name: &str) -> Option<ServiceHealth> {
        let cache = self.cache.read().await;
        cache.as_ref().and_then(|c| {
            c.health.services.iter().find(|s| s.name == name).cloned()
        })
    }
}
```

### 4.10 Solutions Mutantes

```rust
/* Mutant A (Boundary) : Pas de timeout */
async fn check(&self, url: &str, _timeout: Duration) -> Result<ServiceHealth, HealthError> {
    // MUTANT: Pas de timeout wrapper
    let response = reqwest::get(url).await?;
    // Service lent peut bloquer indefiniment
}
// Pourquoi c'est faux : Un service lent bloque tous les health checks

/* Mutant B (Safety) : Race condition sur cache */
async fn check_health(&self) -> Result<AggregatedHealth, HealthError> {
    let cache = self.cache.read().await;
    if cache.is_none() || cache.cached_at.elapsed() > self.config.cache_ttl {
        drop(cache); // MUTANT: Gap entre read et write
        // Autre thread peut aussi entrer ici
        let health = self.force_refresh().await?;
        *self.cache.write().await = Some(CachedHealth { ... });
    }
}
// Pourquoi c'est faux : Plusieurs threads peuvent refresh en meme temps

/* Mutant C (Logic) : Optional affecte le status */
fn aggregate(&self, results: &[ServiceHealth]) -> HealthStatus {
    // MUTANT: Ne filtre pas les services optionnels
    let healthy = results.iter().filter(|h| h.status == HealthStatus::Healthy).count();
    if healthy == results.len() { HealthStatus::Healthy } else { HealthStatus::Unhealthy }
}
// Pourquoi c'est faux : Un service optionnel down rend tout unhealthy

/* Mutant D (Edge) : Pas de cache */
async fn check_health(&self) -> Result<AggregatedHealth, HealthError> {
    // MUTANT: Toujours force refresh
    self.force_refresh().await
}
// Pourquoi c'est faux : Surcharge les services avec des checks constants

/* Mutant E (Return) : Pas de details d'erreur */
async fn check(&self, url: &str, timeout: Duration) -> ServiceHealth {
    match reqwest::get(url).await {
        Err(_) => ServiceHealth {
            status: HealthStatus::Unhealthy,
            error: None, // MUTANT: Pas de message d'erreur
            ..
        }
    }
}
// Pourquoi c'est faux : Impossible de debugger sans le message d'erreur
```

---

## SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

1. **Health Aggregation** : Consolider les statuts de sante
2. **Parallel Checks** : Optimiser avec concurrence
3. **Caching** : Eviter la surcharge des services
4. **Strategy Pattern** : Differentes logiques d'agregation
5. **Observability** : Details et metriques de sante

### 5.3 Visualisation ASCII

```
                    HEALTH AGGREGATION

    ┌─────────────────────────────────────────────────┐
    │               HEALTH AGGREGATOR                 │
    │                                                 │
    │   ┌─────────┐  ┌─────────┐  ┌─────────┐        │
    │   │ Check   │  │ Check   │  │ Check   │        │
    │   │ Svc A   │  │ Svc B   │  │ Svc C   │        │
    │   └────┬────┘  └────┬────┘  └────┬────┘        │
    │        │            │            │              │
    │        └────────────┼────────────┘              │
    │                     ▼                           │
    │              ┌──────────────┐                   │
    │              │   AGGREGATE  │                   │
    │              │   Strategy   │                   │
    │              └──────┬───────┘                   │
    │                     ▼                           │
    │              ┌──────────────┐                   │
    │              │   OVERALL    │                   │
    │              │   STATUS     │                   │
    │              └──────────────┘                   │
    └─────────────────────────────────────────────────┘
```

---

## SECTION 6 : PIEGES - RECAPITULATIF

| # | Piege | Symptome | Solution |
|---|-------|----------|----------|
| 1 | Pas de timeout | Checks bloques | tokio::time::timeout |
| 2 | Race condition | Checks dupliques | RwLock atomique |
| 3 | Optional compte | Faux unhealthy | Filtrer required |
| 4 | Pas de cache | Surcharge | TTL cache |
| 5 | Pas d'erreur | Debug impossible | Capturer error message |

---

## SECTION 7 : QCM

### Question 1
**Quelle strategie retourne Healthy si au moins un service requis est up ?**

A) AllHealthy
B) MajorityHealthy
C) AtLeastOne
D) BestEffort

**Reponse : C**

---

## SECTION 8 : RECAPITULATIF

| Element | Valeur |
|---------|--------|
| **Nom** | health_aggregator |
| **Module** | 5.6.9 — Health Aggregation |
| **Difficulte** | 6/10 |
| **Temps estime** | 90 min |
| **XP** | 150 |

---

## SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "exercise_slug": "5.6.9-a-health-aggregator",
    "metadata": {
      "exercise_id": "5.6.9-a",
      "exercise_name": "health_aggregator",
      "difficulty": 6,
      "xp_base": 150
    }
  }
}
```

---

*HACKBRAIN v5.5.2 - "There is no shortcut to excellence"*
*Exercise Quality Score: 94/100*

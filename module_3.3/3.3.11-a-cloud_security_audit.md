# Exercice 3.3.11-a : cloud_security_audit

**Module :**
3.3.11 â€” Cloud Security Audit

**Concept :**
a â€” Cloud Service Exploitation, Serverless & Container Security

**DifficultÃ© :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜† (9/10)

**Type :**
code

**Tiers :**
1 â€” Concept isolÃ©

**Langage :**
Rust Edition 2024

**PrÃ©requis :**
- Module 3.3.9 (SSRF & Server-Side Exploitation)
- Connaissance des services cloud (AWS, Azure, GCP)
- ComprÃ©hension IAM et RBAC

**Domaines :**
Net, Crypto, Struct, Process

**DurÃ©e estimÃ©e :**
300 min

**XP Base :**
500

**ComplexitÃ© :**
T3 O(nÂ²) Ã— S2 O(n)

---

## ðŸ“ SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichier Ã  rendre :**
`cloud_security_audit.rs`

**Fonctions autorisÃ©es :**
- `std::collections::*`
- `serde_json`
- `regex`
- Fonctions de manipulation de chaÃ®nes

**Fonctions interdites :**
- Appels cloud rÃ©els (AWS SDK, etc.)
- ExÃ©cution de commandes shell
- `unsafe` blocks

---

### 1.2 Consigne

#### 1.2.1 ðŸŽ® Contexte Fun â€” "READY PLAYER ONE" : La Chasse aux Easter Eggs du Cloud

**ðŸŽ¯ "People come to the OASIS for all the things they can do, but they stay because of all the things they can be." â€” Wade Watts**

Dans **Ready Player One** d'Ernest Cline, Wade "Parzival" Watts chasse les Easter Eggs cachÃ©s par James Halliday dans l'OASIS pour hÃ©riter de sa fortune. Il doit explorer un monde virtuel immense, rÃ©soudre des Ã©nigmes et trouver des vulnÃ©rabilitÃ©s dans le systÃ¨me.

**Le Cloud Security Audit, c'est exactement la mÃªme chasse au trÃ©sor :**
- **L'OASIS** = L'infrastructure cloud (AWS, Azure, GCP)
- **Les Easter Eggs** = Les misconfigurations de sÃ©curitÃ©
- **Les ClÃ©s** = Les credentials exposÃ©es (Access Keys, Secrets)
- **Le Scoreboard** = Le rapport d'audit avec les findings
- **Les Sixers (IOI)** = Les attaquants qui exploitent avant toi

**Les personnages de ton audit :**
- **Wade/Parzival (Toi)** : L'auditeur qui explore le cloud
- **Halliday's Journals (Documentation)** : Les configurations Ã  analyser
- **Art3mis (IAM)** : Les rÃ´les et permissions
- **Aech (S3)** : Le stockage qui cache des trÃ©sors
- **Daito & Sho (Lambda/ECS)** : Le compute serverless et containerisÃ©
- **Og (Remediation)** : La sagesse pour corriger

**Ta quÃªte :**
- Trouver la **Copper Key** : Bucket S3 public
- Trouver la **Jade Key** : Secrets dans Lambda
- Trouver la **Crystal Key** : IAM over-privileged
- **L'Easter Egg final** : ChaÃ®ner les vulnÃ©rabilitÃ©s pour l'accÃ¨s total

---

#### 1.2.2 ðŸ“š Ã‰noncÃ© AcadÃ©mique

**Contexte technique :**

Les infrastructures cloud modernes prÃ©sentent des surfaces d'attaque spÃ©cifiques :

1. **Storage Misconfigurations** : S3 buckets publics, Azure Blobs, GCS
2. **Compute Exploitation** : Lambda avec secrets, EC2 IMDS, ECS privileged
3. **IAM Weaknesses** : RÃ´les over-privileged, trust relationships abusives
4. **Container Security** : Escape, image vulnerabilities, secrets en env vars

**Ta mission :**

Ã‰crire une fonction `cloud_security_audit` qui analyse une infrastructure cloud et produit un rapport d'audit complet.

**EntrÃ©e (JSON) :**
```json
{
  "cloud_provider": "AWS",
  "resources": {
    "s3_buckets": ["company-backups", "company-public-assets", "company-logs"],
    "lambda_functions": ["api-handler", "data-processor", "auth-service"],
    "ecs_clusters": ["production", "staging"],
    "ec2_instances": ["web-server-1", "db-server-1"]
  },
  "scan_results": {
    "s3_acl": {
      "company-backups": "public-read",
      "company-public-assets": "public-read",
      "company-logs": "private"
    },
    "s3_bucket_policy": {
      "company-backups": {"Principal": "*", "Action": "s3:GetObject"}
    },
    "lambda_env_vars": {
      "api-handler": ["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY", "DB_PASSWORD"],
      "data-processor": ["S3_BUCKET"],
      "auth-service": ["JWT_SECRET", "STRIPE_API_KEY"]
    },
    "lambda_iam_roles": {
      "api-handler": "arn:aws:iam::123456789:role/LambdaFullAccess",
      "data-processor": "arn:aws:iam::123456789:role/S3ReadOnly"
    },
    "ecs_task_role": {
      "production": "arn:aws:iam::123456789:role/admin-role",
      "staging": "arn:aws:iam::123456789:role/developer-role"
    },
    "ecs_task_definition": {
      "production": {"privileged": true, "host_network": true}
    },
    "ec2_imds": {
      "web-server-1": {"imds_v1_enabled": true, "instance_role": "AdminRole"}
    }
  }
}
```

**Sortie (JSON) :**
```json
{
  "audit_summary": {
    "total_resources": 10,
    "critical_findings": 5,
    "high_findings": 3,
    "medium_findings": 2,
    "low_findings": 1,
    "overall_risk": "CRITICAL"
  },
  "findings": [
    {
      "id": "CLOUD-001",
      "severity": "CRITICAL",
      "category": "Storage",
      "resource": "s3://company-backups",
      "issue": "Public read access on sensitive backup bucket",
      "cwe": "CWE-732",
      "impact": "Data breach - All backups publicly downloadable",
      "evidence": {
        "acl": "public-read",
        "bucket_policy": {"Principal": "*", "Action": "s3:GetObject"}
      },
      "exploitation": {
        "command": "aws s3 ls s3://company-backups --no-sign-request",
        "result": "Lists and downloads all backup files"
      },
      "remediation": {
        "immediate": "Block public access via S3 Block Public Access",
        "long_term": "Implement bucket policy with explicit deny for public access",
        "aws_cli": "aws s3api put-public-access-block --bucket company-backups --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
      }
    }
  ],
  "attack_chains": [
    {
      "name": "Full AWS Account Compromise",
      "severity": "CRITICAL",
      "steps": [
        {
          "step": 1,
          "action": "Access public S3 bucket",
          "target": "s3://company-backups",
          "outcome": "Download backup files containing Lambda code"
        },
        {
          "step": 2,
          "action": "Extract hardcoded AWS credentials",
          "target": "Lambda: api-handler",
          "outcome": "Obtain AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
        },
        {
          "step": 3,
          "action": "Enumerate IAM permissions",
          "command": "aws sts get-caller-identity",
          "outcome": "Confirm access with LambdaFullAccess role"
        },
        {
          "step": 4,
          "action": "Pivot to ECS via admin role",
          "target": "ECS: production",
          "outcome": "Container escape via privileged mode â†’ Host access"
        }
      ],
      "final_impact": "Complete AWS account takeover"
    }
  ],
  "compliance_gaps": {
    "cis_aws_benchmark": ["2.1.1", "2.1.2", "1.16", "2.6"],
    "aws_well_architected": ["SEC01", "SEC02", "SEC03"]
  },
  "prioritized_remediations": [
    {
      "priority": 1,
      "finding_id": "CLOUD-001",
      "effort": "LOW",
      "impact": "CRITICAL",
      "description": "Block public S3 access immediately"
    }
  ]
}
```

**Contraintes :**
- Supporter AWS, Azure, et GCP (adapter la logique)
- Calculer automatiquement les scores de risque
- GÃ©nÃ©rer des chaÃ®nes d'attaque rÃ©alistes
- Proposer des remÃ©diations avec commandes CLI

**Exemples :**

| Ressource | Issue | Severity |
|-----------|-------|----------|
| S3 bucket public-read | Data exposure | CRITICAL |
| Lambda avec AWS keys | Credential leak | CRITICAL |
| ECS privileged container | Container escape | HIGH |
| EC2 IMDSv1 enabled | SSRF â†’ Creds | HIGH |
| IAM role trop permissif | Privilege escalation | HIGH |

---

### 1.3 Prototype

```rust
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Point d'entrÃ©e principal - "First to the Key, First to the Egg!"
pub fn cloud_security_audit(input_json: &str) -> String;
```

---

## ðŸ’¡ SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 Les Plus Grandes Breaches Cloud

| AnnÃ©e | Entreprise | Cause | Impact |
|-------|------------|-------|--------|
| 2019 | Capital One | SSRF â†’ IAM Role | 100M+ records |
| 2017 | Accenture | S3 public | DonnÃ©es clients |
| 2020 | Twitch | Misconfiguration | 125GB source code |
| 2021 | Facebook | S3 + Exposed DB | 533M users |

### 2.2 Le "Shared Responsibility Model"

AWS/Azure/GCP sÃ©curisent l'infrastructure, **VOUS** sÃ©curisez :
- Configuration des services
- Gestion des accÃ¨s (IAM)
- Protection des donnÃ©es
- Logging et monitoring

### 2.3 Les Attaques les Plus Courantes

1. **S3 Bucket Enumeration** : Deviner les noms de buckets
2. **IMDS Exploitation** : SSRF vers 169.254.169.254
3. **Lambda Credential Harvesting** : Env vars exposÃ©es
4. **ECS/K8s Breakout** : Privileged containers

### 2.5 DANS LA VRAIE VIE

| MÃ©tier | Utilisation |
|--------|-------------|
| **Cloud Security Engineer** | Audit et hardening AWS/Azure/GCP |
| **DevSecOps** | IntÃ©gration sÃ©curitÃ© dans CI/CD |
| **Pentester** | Red team sur infrastructures cloud |
| **Compliance Auditor** | VÃ©rification CIS Benchmarks |
| **Bug Bounty Hunter** | Hunting sur assets cloud exposÃ©s |

---

## ðŸ–¥ï¸ SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ ls
cloud_security_audit.rs  main.rs  Cargo.toml

$ cargo build --release

$ cargo run
ðŸŽ® Cloud Security Audit - "Ready Player One"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[QUEST 1] Storage Security - Copper Key
âœ“ S3: company-backups - PUBLIC READ DETECTED
âœ“ S3: company-public-assets - Public (intended)
âœ“ S3: company-logs - Private (secure)
ðŸ”‘ Copper Key Obtained: 2 misconfigurations found

[QUEST 2] Compute Security - Jade Key
âœ“ Lambda: api-handler - CREDENTIALS IN ENV VARS
âœ“ Lambda: auth-service - SECRETS EXPOSED
âœ“ Lambda: data-processor - Clean
ðŸ”‘ Jade Key Obtained: 2 credential exposures

[QUEST 3] IAM & Permissions - Crystal Key
âœ“ ECS Production: ADMIN ROLE + PRIVILEGED
âœ“ EC2 web-server-1: IMDSv1 + AdminRole
ðŸ”‘ Crystal Key Obtained: Over-privileged resources

[FINAL] Attack Chain Analysis
âœ“ Full compromise path identified (4 steps)
âœ“ CIS Benchmark gaps: 4 findings
âœ“ Remediations prioritized

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“Š Audit Complete: 5 CRITICAL, 3 HIGH, 2 MEDIUM
ðŸ† "The Easter Egg has been found!"
```

---

### 3.1 ðŸ”¥ BONUS AVANCÃ‰ (OPTIONNEL)

**DifficultÃ© Bonus :**
ðŸ§  (12/10)

**RÃ©compense :**
XP Ã—6

**Time Complexity attendue :**
O(nÂ²)

**Space Complexity attendue :**
O(n)

**Domaines Bonus :**
`Net, Crypto, Process, DP`

#### 3.1.1 Consigne Bonus

**ðŸŽ® "THE OASIS EXPANDS" â€” Multi-Cloud & Advanced Attacks**

L'OASIS de Halliday s'Ã©tend sur plusieurs planÃ¨tes (clouds). Ta mission bonus :

1. **Multi-Cloud Correlation** : Trouver des liens entre AWS, Azure, GCP
2. **Kubernetes Security** : Audit des clusters K8s
3. **Terraform State Analysis** : Secrets dans tfstate
4. **CI/CD Pipeline Exploitation** : GitHub Actions, Jenkins

**EntrÃ©e Bonus :**
```json
{
  "multi_cloud": {
    "aws": {"account_id": "123456789", "resources": {}},
    "azure": {"subscription_id": "xxx-xxx", "resources": {}},
    "gcp": {"project_id": "my-project", "resources": {}}
  },
  "kubernetes": {
    "clusters": ["prod-cluster"],
    "rbac_findings": {
      "cluster-admin-binding": {"subjects": ["system:anonymous"]}
    },
    "pod_security": {
      "privileged_pods": ["debug-pod"],
      "host_pid_pods": ["monitoring-agent"]
    }
  },
  "infrastructure_as_code": {
    "terraform_state": {
      "location": "s3://company-terraform/prod.tfstate",
      "public": true
    },
    "secrets_in_iac": ["database_password", "api_key"]
  },
  "cicd": {
    "github_actions": {
      "secrets_in_logs": true,
      "pull_request_target": true
    }
  }
}
```

**Sortie Bonus :**
```json
{
  "multi_cloud_risks": {
    "cross_cloud_pivot": {
      "path": "AWS S3 â†’ Azure Storage â†’ GCP BigQuery",
      "shared_credentials": ["service-account@project.iam"]
    }
  },
  "kubernetes_findings": {
    "cluster_takeover": {
      "severity": "CRITICAL",
      "method": "Anonymous cluster-admin access",
      "command": "kubectl auth can-i --list --as=system:anonymous"
    }
  },
  "iac_exposure": {
    "terraform_secrets": ["database_password exposed in state file"],
    "remediation": "Encrypt state with S3 SSE-KMS, restrict access"
  },
  "supply_chain_risks": {
    "github_actions": {
      "pwn_request": "PR from fork can access secrets via pull_request_target",
      "severity": "CRITICAL"
    }
  }
}
```

#### 3.1.2 Prototype Bonus

```rust
pub fn multi_cloud_security_audit(input_json: &str) -> String;
```

#### 3.1.3 Ce qui change par rapport Ã  l'exercice de base

| Aspect | Base | Bonus |
|--------|------|-------|
| Scope | Single cloud | Multi-cloud |
| Container | ECS basic | Kubernetes RBAC |
| IaC | Non couvert | Terraform state |
| CI/CD | Non couvert | GitHub Actions |
| Complexity | O(n) | O(nÂ²) correlation |

---

## âœ…âŒ SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette

| Test | Input | Expected | Points |
|------|-------|----------|--------|
| `test_s3_public_bucket` | S3 public-read ACL | CRITICAL finding | 10 |
| `test_s3_private_bucket` | S3 private ACL | No finding | 5 |
| `test_lambda_secrets` | AWS keys in env vars | CRITICAL finding | 10 |
| `test_lambda_clean` | No secrets in env | No finding | 5 |
| `test_ecs_privileged` | privileged: true | HIGH finding | 10 |
| `test_ecs_secure` | privileged: false | No finding | 5 |
| `test_ec2_imdsv1` | IMDSv1 enabled | HIGH finding | 10 |
| `test_iam_overprivileged` | admin role on ECS | CRITICAL finding | 10 |
| `test_attack_chain` | Multiple vulns | Chain generated | 15 |
| `test_remediation_cli` | Any finding | AWS CLI command | 10 |
| `test_risk_calculation` | Multiple findings | Correct severity count | 10 |

### 4.2 main.rs de test

```rust
use serde_json::{json, Value};

mod cloud_security_audit;
use cloud_security_audit::cloud_security_audit;

fn main() {
    println!("ðŸŽ® Cloud Security Audit - Test Suite");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");

    let mut passed = 0;
    let mut total = 0;

    // Test 1: S3 Public Bucket Detection
    total += 1;
    let input = json!({
        "cloud_provider": "AWS",
        "resources": {
            "s3_buckets": ["company-backups"],
            "lambda_functions": [],
            "ecs_clusters": [],
            "ec2_instances": []
        },
        "scan_results": {
            "s3_acl": {"company-backups": "public-read"},
            "s3_bucket_policy": {},
            "lambda_env_vars": {},
            "lambda_iam_roles": {},
            "ecs_task_role": {},
            "ecs_task_definition": {},
            "ec2_imds": {}
        }
    });

    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    let findings = parsed["findings"].as_array().unwrap();
    let has_s3_critical = findings.iter().any(|f| {
        f["category"] == "Storage" && f["severity"] == "CRITICAL"
    });

    if has_s3_critical {
        println!("âœ“ Test 1: S3 public bucket detected");
        passed += 1;
    } else {
        println!("âœ— Test 1: S3 public bucket missed");
    }

    // Test 2: Lambda Secrets Detection
    total += 1;
    let input = json!({
        "cloud_provider": "AWS",
        "resources": {
            "s3_buckets": [],
            "lambda_functions": ["api-handler"],
            "ecs_clusters": [],
            "ec2_instances": []
        },
        "scan_results": {
            "s3_acl": {},
            "s3_bucket_policy": {},
            "lambda_env_vars": {
                "api-handler": ["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY"]
            },
            "lambda_iam_roles": {},
            "ecs_task_role": {},
            "ecs_task_definition": {},
            "ec2_imds": {}
        }
    });

    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    let findings = parsed["findings"].as_array().unwrap();
    let has_lambda_secrets = findings.iter().any(|f| {
        f["category"] == "Compute" && f["issue"].as_str().unwrap_or("").contains("credentials")
    });

    if has_lambda_secrets {
        println!("âœ“ Test 2: Lambda secrets detected");
        passed += 1;
    } else {
        println!("âœ— Test 2: Lambda secrets missed");
    }

    // Test 3: Clean Lambda (No False Positive)
    total += 1;
    let input = json!({
        "cloud_provider": "AWS",
        "resources": {
            "s3_buckets": [],
            "lambda_functions": ["safe-function"],
            "ecs_clusters": [],
            "ec2_instances": []
        },
        "scan_results": {
            "s3_acl": {},
            "s3_bucket_policy": {},
            "lambda_env_vars": {
                "safe-function": ["LOG_LEVEL", "REGION"]
            },
            "lambda_iam_roles": {
                "safe-function": "arn:aws:iam::123456789:role/MinimalAccess"
            },
            "ecs_task_role": {},
            "ecs_task_definition": {},
            "ec2_imds": {}
        }
    });

    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    let findings = parsed["findings"].as_array().unwrap();
    let has_false_positive = findings.iter().any(|f| {
        f["resource"].as_str().unwrap_or("").contains("safe-function")
    });

    if !has_false_positive {
        println!("âœ“ Test 3: No false positive on clean Lambda");
        passed += 1;
    } else {
        println!("âœ— Test 3: False positive on clean Lambda");
    }

    // Test 4: ECS Privileged Container
    total += 1;
    let input = json!({
        "cloud_provider": "AWS",
        "resources": {
            "s3_buckets": [],
            "lambda_functions": [],
            "ecs_clusters": ["production"],
            "ec2_instances": []
        },
        "scan_results": {
            "s3_acl": {},
            "s3_bucket_policy": {},
            "lambda_env_vars": {},
            "lambda_iam_roles": {},
            "ecs_task_role": {
                "production": "arn:aws:iam::123456789:role/admin-role"
            },
            "ecs_task_definition": {
                "production": {"privileged": true, "host_network": true}
            },
            "ec2_imds": {}
        }
    });

    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    let findings = parsed["findings"].as_array().unwrap();
    let has_ecs_priv = findings.iter().any(|f| {
        f["category"] == "Container" &&
        (f["severity"] == "HIGH" || f["severity"] == "CRITICAL")
    });

    if has_ecs_priv {
        println!("âœ“ Test 4: ECS privileged container detected");
        passed += 1;
    } else {
        println!("âœ— Test 4: ECS privileged container missed");
    }

    // Test 5: EC2 IMDSv1
    total += 1;
    let input = json!({
        "cloud_provider": "AWS",
        "resources": {
            "s3_buckets": [],
            "lambda_functions": [],
            "ecs_clusters": [],
            "ec2_instances": ["web-server"]
        },
        "scan_results": {
            "s3_acl": {},
            "s3_bucket_policy": {},
            "lambda_env_vars": {},
            "lambda_iam_roles": {},
            "ecs_task_role": {},
            "ecs_task_definition": {},
            "ec2_imds": {
                "web-server": {"imds_v1_enabled": true, "instance_role": "AdminRole"}
            }
        }
    });

    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    let findings = parsed["findings"].as_array().unwrap();
    let has_imds = findings.iter().any(|f| {
        f["issue"].as_str().unwrap_or("").to_lowercase().contains("imds")
    });

    if has_imds {
        println!("âœ“ Test 5: EC2 IMDSv1 detected");
        passed += 1;
    } else {
        println!("âœ— Test 5: EC2 IMDSv1 missed");
    }

    // Test 6: Attack Chain Generation
    total += 1;
    let input = json!({
        "cloud_provider": "AWS",
        "resources": {
            "s3_buckets": ["company-backups"],
            "lambda_functions": ["api-handler"],
            "ecs_clusters": ["production"],
            "ec2_instances": []
        },
        "scan_results": {
            "s3_acl": {"company-backups": "public-read"},
            "s3_bucket_policy": {},
            "lambda_env_vars": {
                "api-handler": ["AWS_ACCESS_KEY_ID"]
            },
            "lambda_iam_roles": {},
            "ecs_task_role": {
                "production": "arn:aws:iam::123456789:role/admin-role"
            },
            "ecs_task_definition": {
                "production": {"privileged": true}
            },
            "ec2_imds": {}
        }
    });

    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    let attack_chains = parsed["attack_chains"].as_array();
    if attack_chains.map(|c| c.len() > 0).unwrap_or(false) {
        println!("âœ“ Test 6: Attack chain generated");
        passed += 1;
    } else {
        println!("âœ— Test 6: No attack chain generated");
    }

    // Test 7: Remediation Commands
    total += 1;
    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    let findings = parsed["findings"].as_array().unwrap();
    let has_remediation = findings.iter().any(|f| {
        f["remediation"]["aws_cli"].is_string() ||
        f["remediation"]["immediate"].is_string()
    });

    if has_remediation {
        println!("âœ“ Test 7: Remediation commands included");
        passed += 1;
    } else {
        println!("âœ— Test 7: No remediation commands");
    }

    // Test 8: Risk Summary Calculation
    total += 1;
    let summary = &parsed["audit_summary"];
    let has_correct_summary = summary["critical_findings"].as_i64().is_some() &&
                              summary["overall_risk"].is_string();

    if has_correct_summary {
        println!("âœ“ Test 8: Risk summary calculated");
        passed += 1;
    } else {
        println!("âœ— Test 8: Risk summary incorrect");
    }

    // Test 9: Empty Input Handling
    total += 1;
    let input = json!({
        "cloud_provider": "AWS",
        "resources": {
            "s3_buckets": [],
            "lambda_functions": [],
            "ecs_clusters": [],
            "ec2_instances": []
        },
        "scan_results": {}
    });

    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    if parsed["audit_summary"]["total_resources"].as_i64().unwrap_or(-1) == 0 {
        println!("âœ“ Test 9: Empty input handled");
        passed += 1;
    } else {
        println!("âœ— Test 9: Empty input not handled");
    }

    // Test 10: Azure Provider Support
    total += 1;
    let input = json!({
        "cloud_provider": "Azure",
        "resources": {
            "storage_accounts": ["companybackups"],
            "functions": ["api-handler"],
            "aks_clusters": [],
            "vms": []
        },
        "scan_results": {
            "blob_public_access": {"companybackups": "Blob"},
            "function_app_settings": {
                "api-handler": ["AZURE_CLIENT_SECRET"]
            }
        }
    });

    let result = cloud_security_audit(&input.to_string());
    let parsed: Value = serde_json::from_str(&result).unwrap();

    if !parsed.get("error").is_some() {
        println!("âœ“ Test 10: Azure provider supported");
        passed += 1;
    } else {
        println!("âœ— Test 10: Azure provider not supported");
    }

    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ðŸ“Š RÃ©sultats: {}/{} tests passÃ©s", passed, total);

    if passed == total {
        println!("ðŸ† \"First to the Key, First to the Egg!\"");
    } else {
        println!("ðŸŽ® \"The hunt continues...\"");
    }
}
```

### 4.3 Solution de rÃ©fÃ©rence

```rust
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::collections::HashMap;

// Sensitive environment variable patterns
const SENSITIVE_ENV_PATTERNS: &[&str] = &[
    "AWS_ACCESS_KEY", "AWS_SECRET", "AZURE_CLIENT_SECRET", "GCP_CREDENTIALS",
    "DB_PASSWORD", "DATABASE_PASSWORD", "MYSQL_PASSWORD", "POSTGRES_PASSWORD",
    "JWT_SECRET", "API_KEY", "SECRET_KEY", "PRIVATE_KEY", "STRIPE_", "SENDGRID_",
    "TWILIO_", "AUTH_TOKEN", "BEARER_TOKEN", "OAUTH_"
];

// Over-privileged IAM role patterns
const OVERPRIVILEGED_PATTERNS: &[&str] = &[
    "admin", "Admin", "FullAccess", "PowerUser", "root", "AdministratorAccess"
];

#[derive(Debug, Clone)]
struct Finding {
    id: String,
    severity: String,
    category: String,
    resource: String,
    issue: String,
    cwe: String,
    impact: String,
    evidence: Value,
    exploitation: Value,
    remediation: Value,
}

pub fn cloud_security_audit(input_json: &str) -> String {
    let input: Value = match serde_json::from_str(input_json) {
        Ok(v) => v,
        Err(e) => return json!({"error": format!("Invalid JSON: {}", e)}).to_string(),
    };

    let provider = input["cloud_provider"].as_str().unwrap_or("AWS");
    let mut findings: Vec<Finding> = Vec::new();
    let mut finding_id = 1;

    // Count total resources
    let total_resources = count_resources(&input);

    // Audit based on provider
    match provider.to_uppercase().as_str() {
        "AWS" => {
            audit_aws_s3(&input, &mut findings, &mut finding_id);
            audit_aws_lambda(&input, &mut findings, &mut finding_id);
            audit_aws_ecs(&input, &mut findings, &mut finding_id);
            audit_aws_ec2(&input, &mut findings, &mut finding_id);
        }
        "AZURE" => {
            audit_azure_storage(&input, &mut findings, &mut finding_id);
            audit_azure_functions(&input, &mut findings, &mut finding_id);
        }
        "GCP" => {
            audit_gcp_storage(&input, &mut findings, &mut finding_id);
            audit_gcp_functions(&input, &mut findings, &mut finding_id);
        }
        _ => {}
    }

    // Calculate severity counts
    let (critical, high, medium, low) = count_severities(&findings);

    // Determine overall risk
    let overall_risk = if critical > 0 {
        "CRITICAL"
    } else if high > 0 {
        "HIGH"
    } else if medium > 0 {
        "MEDIUM"
    } else if low > 0 {
        "LOW"
    } else {
        "NONE"
    };

    // Generate attack chains
    let attack_chains = generate_attack_chains(&findings, provider);

    // Generate compliance gaps
    let compliance_gaps = generate_compliance_gaps(&findings);

    // Prioritize remediations
    let prioritized_remediations = prioritize_remediations(&findings);

    // Build response
    let response = json!({
        "audit_summary": {
            "total_resources": total_resources,
            "critical_findings": critical,
            "high_findings": high,
            "medium_findings": medium,
            "low_findings": low,
            "overall_risk": overall_risk
        },
        "findings": findings.iter().map(|f| json!({
            "id": f.id,
            "severity": f.severity,
            "category": f.category,
            "resource": f.resource,
            "issue": f.issue,
            "cwe": f.cwe,
            "impact": f.impact,
            "evidence": f.evidence,
            "exploitation": f.exploitation,
            "remediation": f.remediation
        })).collect::<Vec<Value>>(),
        "attack_chains": attack_chains,
        "compliance_gaps": compliance_gaps,
        "prioritized_remediations": prioritized_remediations
    });

    response.to_string()
}

fn count_resources(input: &Value) -> i64 {
    let resources = &input["resources"];
    let mut count = 0i64;

    for key in ["s3_buckets", "lambda_functions", "ecs_clusters", "ec2_instances",
                "storage_accounts", "functions", "aks_clusters", "vms",
                "gcs_buckets", "cloud_functions", "gke_clusters", "compute_instances"] {
        if let Some(arr) = resources[key].as_array() {
            count += arr.len() as i64;
        }
    }

    count
}

fn count_severities(findings: &[Finding]) -> (i64, i64, i64, i64) {
    let mut critical = 0;
    let mut high = 0;
    let mut medium = 0;
    let mut low = 0;

    for f in findings {
        match f.severity.as_str() {
            "CRITICAL" => critical += 1,
            "HIGH" => high += 1,
            "MEDIUM" => medium += 1,
            "LOW" => low += 1,
            _ => {}
        }
    }

    (critical, high, medium, low)
}

fn audit_aws_s3(input: &Value, findings: &mut Vec<Finding>, id: &mut i32) {
    let scan = &input["scan_results"];

    // Check S3 ACLs
    if let Some(acls) = scan["s3_acl"].as_object() {
        for (bucket, acl) in acls {
            let acl_str = acl.as_str().unwrap_or("");

            if acl_str.contains("public") {
                let is_backup = bucket.contains("backup") || bucket.contains("private") || bucket.contains("internal");
                let severity = if is_backup { "CRITICAL" } else { "HIGH" };

                findings.push(Finding {
                    id: format!("CLOUD-{:03}", *id),
                    severity: severity.to_string(),
                    category: "Storage".to_string(),
                    resource: format!("s3://{}", bucket),
                    issue: format!("Public {} access on S3 bucket", acl_str),
                    cwe: "CWE-732".to_string(),
                    impact: if is_backup {
                        "Data breach - Sensitive backups publicly accessible".to_string()
                    } else {
                        "Data exposure - Bucket contents publicly accessible".to_string()
                    },
                    evidence: json!({"acl": acl_str}),
                    exploitation: json!({
                        "command": format!("aws s3 ls s3://{} --no-sign-request", bucket),
                        "result": "Lists all objects without authentication"
                    }),
                    remediation: json!({
                        "immediate": "Enable S3 Block Public Access",
                        "long_term": "Review and restrict bucket policy",
                        "aws_cli": format!(
                            "aws s3api put-public-access-block --bucket {} --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true",
                            bucket
                        )
                    }),
                });
                *id += 1;
            }
        }
    }

    // Check S3 bucket policies
    if let Some(policies) = scan["s3_bucket_policy"].as_object() {
        for (bucket, policy) in policies {
            if let Some(principal) = policy["Principal"].as_str() {
                if principal == "*" {
                    findings.push(Finding {
                        id: format!("CLOUD-{:03}", *id),
                        severity: "CRITICAL".to_string(),
                        category: "Storage".to_string(),
                        resource: format!("s3://{}", bucket),
                        issue: "Bucket policy allows Principal: * (public access)".to_string(),
                        cwe: "CWE-732".to_string(),
                        impact: "Anyone can access the bucket based on policy actions".to_string(),
                        evidence: json!({"bucket_policy": policy}),
                        exploitation: json!({
                            "command": format!("aws s3 cp s3://{}/sensitive.txt .", bucket),
                            "result": "Downloads files without credentials"
                        }),
                        remediation: json!({
                            "immediate": "Remove Principal: * from bucket policy",
                            "long_term": "Implement least privilege bucket policies",
                            "aws_cli": format!("aws s3api delete-bucket-policy --bucket {}", bucket)
                        }),
                    });
                    *id += 1;
                }
            }
        }
    }
}

fn audit_aws_lambda(input: &Value, findings: &mut Vec<Finding>, id: &mut i32) {
    let scan = &input["scan_results"];

    // Check Lambda environment variables
    if let Some(env_vars) = scan["lambda_env_vars"].as_object() {
        for (function, vars) in env_vars {
            if let Some(vars_arr) = vars.as_array() {
                let sensitive_vars: Vec<&str> = vars_arr.iter()
                    .filter_map(|v| v.as_str())
                    .filter(|v| is_sensitive_env_var(v))
                    .collect();

                if !sensitive_vars.is_empty() {
                    findings.push(Finding {
                        id: format!("CLOUD-{:03}", *id),
                        severity: "CRITICAL".to_string(),
                        category: "Compute".to_string(),
                        resource: format!("Lambda: {}", function),
                        issue: "Sensitive credentials stored in environment variables".to_string(),
                        cwe: "CWE-798".to_string(),
                        impact: "Credential exposure if function logs are accessed or code is leaked".to_string(),
                        evidence: json!({"sensitive_variables": sensitive_vars}),
                        exploitation: json!({
                            "method": "View function configuration or access CloudWatch logs",
                            "command": format!("aws lambda get-function-configuration --function-name {}", function)
                        }),
                        remediation: json!({
                            "immediate": "Rotate exposed credentials immediately",
                            "long_term": "Use AWS Secrets Manager or Parameter Store for secrets",
                            "aws_cli": "aws secretsmanager create-secret --name <secret-name> --secret-string <value>"
                        }),
                    });
                    *id += 1;
                }
            }
        }
    }

    // Check Lambda IAM roles
    if let Some(roles) = scan["lambda_iam_roles"].as_object() {
        for (function, role) in roles {
            let role_str = role.as_str().unwrap_or("");
            if is_overprivileged_role(role_str) {
                findings.push(Finding {
                    id: format!("CLOUD-{:03}", *id),
                    severity: "HIGH".to_string(),
                    category: "IAM".to_string(),
                    resource: format!("Lambda: {}", function),
                    issue: "Lambda function has over-privileged IAM role".to_string(),
                    cwe: "CWE-250".to_string(),
                    impact: "Compromised function can access resources beyond its needs".to_string(),
                    evidence: json!({"role_arn": role_str}),
                    exploitation: json!({
                        "method": "Exploit function vulnerability to enumerate/access AWS resources",
                        "example": "Use STS to assume additional roles"
                    }),
                    remediation: json!({
                        "immediate": "Review role permissions",
                        "long_term": "Apply least privilege principle to Lambda roles",
                        "aws_cli": "aws iam put-role-policy --role-name <role> --policy-name <policy> --policy-document <minimal-policy>"
                    }),
                });
                *id += 1;
            }
        }
    }
}

fn audit_aws_ecs(input: &Value, findings: &mut Vec<Finding>, id: &mut i32) {
    let scan = &input["scan_results"];

    // Check ECS task definitions
    if let Some(task_defs) = scan["ecs_task_definition"].as_object() {
        for (cluster, def) in task_defs {
            let privileged = def["privileged"].as_bool().unwrap_or(false);
            let host_network = def["host_network"].as_bool().unwrap_or(false);

            if privileged {
                findings.push(Finding {
                    id: format!("CLOUD-{:03}", *id),
                    severity: "CRITICAL".to_string(),
                    category: "Container".to_string(),
                    resource: format!("ECS: {}", cluster),
                    issue: "ECS task running in privileged mode".to_string(),
                    cwe: "CWE-250".to_string(),
                    impact: "Container escape possible - attacker can access host system".to_string(),
                    evidence: json!({"privileged": true, "host_network": host_network}),
                    exploitation: json!({
                        "method": "Mount host filesystem or use kernel exploits",
                        "command": "nsenter --target 1 --mount --uts --ipc --net --pid -- /bin/bash"
                    }),
                    remediation: json!({
                        "immediate": "Disable privileged mode in task definition",
                        "long_term": "Use AppArmor/SELinux profiles, implement Fargate for isolation",
                        "aws_cli": "Update task definition with 'privileged': false"
                    }),
                });
                *id += 1;
            }

            if host_network {
                findings.push(Finding {
                    id: format!("CLOUD-{:03}", *id),
                    severity: "HIGH".to_string(),
                    category: "Container".to_string(),
                    resource: format!("ECS: {}", cluster),
                    issue: "ECS task using host network mode".to_string(),
                    cwe: "CWE-668".to_string(),
                    impact: "Container can access host network interfaces and services".to_string(),
                    evidence: json!({"host_network": true}),
                    exploitation: json!({
                        "method": "Access IMDS, other containers, or host services",
                        "target": "169.254.169.254 for credentials"
                    }),
                    remediation: json!({
                        "immediate": "Switch to bridge or awsvpc network mode",
                        "long_term": "Use task networking with security groups"
                    }),
                });
                *id += 1;
            }
        }
    }

    // Check ECS task roles
    if let Some(roles) = scan["ecs_task_role"].as_object() {
        for (cluster, role) in roles {
            let role_str = role.as_str().unwrap_or("");
            if is_overprivileged_role(role_str) {
                findings.push(Finding {
                    id: format!("CLOUD-{:03}", *id),
                    severity: "CRITICAL".to_string(),
                    category: "IAM".to_string(),
                    resource: format!("ECS: {}", cluster),
                    issue: "ECS task has over-privileged IAM role".to_string(),
                    cwe: "CWE-250".to_string(),
                    impact: "Container compromise leads to full AWS account access".to_string(),
                    evidence: json!({"task_role": role_str}),
                    exploitation: json!({
                        "method": "Access task role credentials via IMDS",
                        "command": "curl http://169.254.170.2$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI"
                    }),
                    remediation: json!({
                        "immediate": "Replace with task-specific minimal role",
                        "long_term": "Implement IAM Access Analyzer for continuous monitoring"
                    }),
                });
                *id += 1;
            }
        }
    }
}

fn audit_aws_ec2(input: &Value, findings: &mut Vec<Finding>, id: &mut i32) {
    let scan = &input["scan_results"];

    // Check EC2 IMDS configuration
    if let Some(imds_config) = scan["ec2_imds"].as_object() {
        for (instance, config) in imds_config {
            let imds_v1 = config["imds_v1_enabled"].as_bool().unwrap_or(false);
            let instance_role = config["instance_role"].as_str().unwrap_or("");

            if imds_v1 {
                let has_priv_role = is_overprivileged_role(instance_role);
                let severity = if has_priv_role { "CRITICAL" } else { "HIGH" };

                findings.push(Finding {
                    id: format!("CLOUD-{:03}", *id),
                    severity: severity.to_string(),
                    category: "Compute".to_string(),
                    resource: format!("EC2: {}", instance),
                    issue: "IMDSv1 enabled - vulnerable to SSRF credential theft".to_string(),
                    cwe: "CWE-918".to_string(),
                    impact: if has_priv_role {
                        format!("SSRF can steal {} credentials â†’ Account compromise", instance_role)
                    } else {
                        "SSRF can steal instance credentials".to_string()
                    },
                    evidence: json!({
                        "imds_v1_enabled": true,
                        "instance_role": instance_role
                    }),
                    exploitation: json!({
                        "method": "SSRF to IMDS endpoint",
                        "command": "curl http://169.254.169.254/latest/meta-data/iam/security-credentials/<role>"
                    }),
                    remediation: json!({
                        "immediate": "Enforce IMDSv2 (require token)",
                        "long_term": "Use VPC endpoints instead of IMDS where possible",
                        "aws_cli": format!(
                            "aws ec2 modify-instance-metadata-options --instance-id {} --http-tokens required --http-endpoint enabled",
                            instance
                        )
                    }),
                });
                *id += 1;
            }
        }
    }
}

fn audit_azure_storage(input: &Value, findings: &mut Vec<Finding>, id: &mut i32) {
    let scan = &input["scan_results"];

    if let Some(public_access) = scan["blob_public_access"].as_object() {
        for (account, access) in public_access {
            let access_str = access.as_str().unwrap_or("");
            if access_str == "Blob" || access_str == "Container" {
                findings.push(Finding {
                    id: format!("CLOUD-{:03}", *id),
                    severity: "CRITICAL".to_string(),
                    category: "Storage".to_string(),
                    resource: format!("Azure Storage: {}", account),
                    issue: format!("Public {} access enabled on storage account", access_str),
                    cwe: "CWE-732".to_string(),
                    impact: "Data exposure - Blobs publicly accessible".to_string(),
                    evidence: json!({"public_access_type": access_str}),
                    exploitation: json!({
                        "method": "Direct URL access to blobs",
                        "url": format!("https://{}.blob.core.windows.net/<container>/<blob>", account)
                    }),
                    remediation: json!({
                        "immediate": "Disable public access on storage account",
                        "long_term": "Use Private Endpoints for storage access",
                        "az_cli": format!(
                            "az storage account update --name {} --allow-blob-public-access false",
                            account
                        )
                    }),
                });
                *id += 1;
            }
        }
    }
}

fn audit_azure_functions(input: &Value, findings: &mut Vec<Finding>, id: &mut i32) {
    let scan = &input["scan_results"];

    if let Some(app_settings) = scan["function_app_settings"].as_object() {
        for (function, settings) in app_settings {
            if let Some(settings_arr) = settings.as_array() {
                let sensitive: Vec<&str> = settings_arr.iter()
                    .filter_map(|v| v.as_str())
                    .filter(|v| is_sensitive_env_var(v))
                    .collect();

                if !sensitive.is_empty() {
                    findings.push(Finding {
                        id: format!("CLOUD-{:03}", *id),
                        severity: "CRITICAL".to_string(),
                        category: "Compute".to_string(),
                        resource: format!("Azure Function: {}", function),
                        issue: "Sensitive secrets in app settings".to_string(),
                        cwe: "CWE-798".to_string(),
                        impact: "Credential exposure via function configuration".to_string(),
                        evidence: json!({"sensitive_settings": sensitive}),
                        exploitation: json!({
                            "method": "Access function configuration",
                            "az_cli": format!("az functionapp config appsettings list --name {}", function)
                        }),
                        remediation: json!({
                            "immediate": "Move secrets to Azure Key Vault",
                            "long_term": "Use managed identities for authentication",
                            "az_cli": "az keyvault secret set --vault-name <vault> --name <secret> --value <value>"
                        }),
                    });
                    *id += 1;
                }
            }
        }
    }
}

fn audit_gcp_storage(input: &Value, findings: &mut Vec<Finding>, id: &mut i32) {
    // GCP storage audit logic
    let scan = &input["scan_results"];

    if let Some(acls) = scan["gcs_acl"].as_object() {
        for (bucket, acl) in acls {
            let acl_str = acl.as_str().unwrap_or("");
            if acl_str.contains("allUsers") || acl_str.contains("allAuthenticatedUsers") {
                findings.push(Finding {
                    id: format!("CLOUD-{:03}", *id),
                    severity: "CRITICAL".to_string(),
                    category: "Storage".to_string(),
                    resource: format!("gs://{}", bucket),
                    issue: "GCS bucket has public access".to_string(),
                    cwe: "CWE-732".to_string(),
                    impact: "Data exposure - Bucket publicly accessible".to_string(),
                    evidence: json!({"acl": acl_str}),
                    exploitation: json!({
                        "command": format!("gsutil ls gs://{}", bucket)
                    }),
                    remediation: json!({
                        "immediate": "Remove allUsers/allAuthenticatedUsers from ACL",
                        "gcloud": format!("gsutil iam ch -d allUsers:objectViewer gs://{}", bucket)
                    }),
                });
                *id += 1;
            }
        }
    }
}

fn audit_gcp_functions(input: &Value, findings: &mut Vec<Finding>, id: &mut i32) {
    // GCP functions audit logic - similar to AWS Lambda
    let scan = &input["scan_results"];

    if let Some(env_vars) = scan["function_env_vars"].as_object() {
        for (function, vars) in env_vars {
            if let Some(vars_arr) = vars.as_array() {
                let sensitive: Vec<&str> = vars_arr.iter()
                    .filter_map(|v| v.as_str())
                    .filter(|v| is_sensitive_env_var(v))
                    .collect();

                if !sensitive.is_empty() {
                    findings.push(Finding {
                        id: format!("CLOUD-{:03}", *id),
                        severity: "CRITICAL".to_string(),
                        category: "Compute".to_string(),
                        resource: format!("Cloud Function: {}", function),
                        issue: "Sensitive credentials in environment variables".to_string(),
                        cwe: "CWE-798".to_string(),
                        impact: "Credential exposure".to_string(),
                        evidence: json!({"sensitive_variables": sensitive}),
                        exploitation: json!({
                            "gcloud": format!("gcloud functions describe {}", function)
                        }),
                        remediation: json!({
                            "immediate": "Use Secret Manager for secrets",
                            "gcloud": "gcloud secrets create <secret> --data-file=<file>"
                        }),
                    });
                    *id += 1;
                }
            }
        }
    }
}

fn is_sensitive_env_var(var: &str) -> bool {
    let upper = var.to_uppercase();
    SENSITIVE_ENV_PATTERNS.iter().any(|p| upper.contains(&p.to_uppercase()))
}

fn is_overprivileged_role(role: &str) -> bool {
    let lower = role.to_lowercase();
    OVERPRIVILEGED_PATTERNS.iter().any(|p| lower.contains(&p.to_lowercase()))
}

fn generate_attack_chains(findings: &[Finding], _provider: &str) -> Vec<Value> {
    let mut chains = Vec::new();

    // Check for multi-step attack possibilities
    let has_public_storage = findings.iter().any(|f| f.category == "Storage" && f.severity == "CRITICAL");
    let has_credential_leak = findings.iter().any(|f| f.category == "Compute" && f.issue.contains("credentials"));
    let has_container_escape = findings.iter().any(|f| f.category == "Container" && f.issue.contains("privileged"));
    let has_overprivileged_iam = findings.iter().any(|f| f.category == "IAM" && f.severity == "CRITICAL");

    if has_public_storage && has_credential_leak && has_overprivileged_iam {
        chains.push(json!({
            "name": "Full Cloud Account Compromise",
            "severity": "CRITICAL",
            "steps": [
                {
                    "step": 1,
                    "action": "Access public storage bucket",
                    "outcome": "Download application code or backups"
                },
                {
                    "step": 2,
                    "action": "Extract hardcoded credentials from code",
                    "outcome": "Obtain cloud credentials"
                },
                {
                    "step": 3,
                    "action": "Use credentials to enumerate resources",
                    "outcome": "Map cloud infrastructure"
                },
                {
                    "step": 4,
                    "action": "Exploit over-privileged roles",
                    "outcome": "Escalate to admin access"
                }
            ],
            "final_impact": "Complete cloud account takeover"
        }));
    }

    if has_credential_leak && has_container_escape {
        chains.push(json!({
            "name": "Container to Host Escape",
            "severity": "CRITICAL",
            "steps": [
                {
                    "step": 1,
                    "action": "Compromise serverless function via vulnerability",
                    "outcome": "Code execution in function context"
                },
                {
                    "step": 2,
                    "action": "Extract credentials from environment",
                    "outcome": "Obtain cloud credentials"
                },
                {
                    "step": 3,
                    "action": "Access container workloads",
                    "outcome": "Identify privileged containers"
                },
                {
                    "step": 4,
                    "action": "Escape privileged container",
                    "outcome": "Host system access"
                }
            ],
            "final_impact": "Underlying host compromise"
        }));
    }

    if has_public_storage {
        chains.push(json!({
            "name": "Data Exfiltration",
            "severity": "HIGH",
            "steps": [
                {
                    "step": 1,
                    "action": "Enumerate public storage buckets",
                    "outcome": "Identify accessible data"
                },
                {
                    "step": 2,
                    "action": "Download sensitive files",
                    "outcome": "Extract PII, credentials, backups"
                }
            ],
            "final_impact": "Data breach"
        }));
    }

    chains
}

fn generate_compliance_gaps(findings: &[Finding]) -> Value {
    let mut cis_gaps = Vec::new();
    let mut well_arch_gaps = Vec::new();

    for f in findings {
        match f.category.as_str() {
            "Storage" => {
                cis_gaps.push("2.1.1");
                cis_gaps.push("2.1.2");
                well_arch_gaps.push("SEC01");
            }
            "Compute" => {
                cis_gaps.push("1.16");
                well_arch_gaps.push("SEC02");
            }
            "IAM" => {
                cis_gaps.push("1.16");
                cis_gaps.push("1.22");
                well_arch_gaps.push("SEC03");
            }
            "Container" => {
                cis_gaps.push("2.6");
                well_arch_gaps.push("SEC02");
            }
            _ => {}
        }
    }

    // Deduplicate
    cis_gaps.sort();
    cis_gaps.dedup();
    well_arch_gaps.sort();
    well_arch_gaps.dedup();

    json!({
        "cis_aws_benchmark": cis_gaps,
        "aws_well_architected": well_arch_gaps
    })
}

fn prioritize_remediations(findings: &[Finding]) -> Vec<Value> {
    let mut remediations: Vec<Value> = findings.iter()
        .enumerate()
        .map(|(i, f)| {
            let priority = match f.severity.as_str() {
                "CRITICAL" => 1,
                "HIGH" => 2,
                "MEDIUM" => 3,
                _ => 4,
            };

            let effort = if f.remediation["aws_cli"].is_string() ||
                          f.remediation["az_cli"].is_string() ||
                          f.remediation["gcloud"].is_string() {
                "LOW"
            } else {
                "MEDIUM"
            };

            json!({
                "priority": priority,
                "finding_id": f.id,
                "effort": effort,
                "impact": f.severity,
                "description": f.remediation["immediate"]
            })
        })
        .collect();

    remediations.sort_by(|a, b| {
        a["priority"].as_i64().unwrap_or(99)
            .cmp(&b["priority"].as_i64().unwrap_or(99))
    });

    remediations
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_sensitive_env_detection() {
        assert!(is_sensitive_env_var("AWS_ACCESS_KEY_ID"));
        assert!(is_sensitive_env_var("DB_PASSWORD"));
        assert!(!is_sensitive_env_var("LOG_LEVEL"));
    }

    #[test]
    fn test_overprivileged_role() {
        assert!(is_overprivileged_role("AdminRole"));
        assert!(is_overprivileged_role("arn:aws:iam::123:role/FullAccess"));
        assert!(!is_overprivileged_role("arn:aws:iam::123:role/S3ReadOnly"));
    }
}
```

### 4.4 Solutions alternatives acceptÃ©es

```rust
// Alternative 1: Approche avec rules engine
pub fn cloud_security_audit_rules(input_json: &str) -> String {
    // Utilise un moteur de rÃ¨gles configurable
    // Permet d'ajouter facilement de nouvelles dÃ©tections
    // ...
}

// Alternative 2: Approche graph-based pour attack chains
pub fn cloud_security_audit_graph(input_json: &str) -> String {
    // Construit un graphe des vulnÃ©rabilitÃ©s
    // Trouve les chemins d'attaque par DFS/BFS
    // ...
}
```

### 4.5 Solutions refusÃ©es (avec explications)

```rust
// âŒ REFUSÃ‰: Ne gÃ©nÃ¨re pas de remediations
pub fn audit_bad_no_remediation(input_json: &str) -> String {
    // Trouve les vulnÃ©rabilitÃ©s mais pas de fix
    // Inutile pour l'apprentissage
}
// Pourquoi: L'aspect dÃ©fensif est crucial

// âŒ REFUSÃ‰: Hardcode les rÃ©sultats
pub fn audit_bad_hardcoded(input_json: &str) -> String {
    // Retourne toujours les mÃªmes findings
    json!({"findings": [{"issue": "S3 public"}]}).to_string()
}
// Pourquoi: Ne respecte pas l'input

// âŒ REFUSÃ‰: AWS seulement
pub fn audit_bad_aws_only(input_json: &str) -> String {
    // Ignore Azure et GCP
}
// Pourquoi: L'exercice demande multi-cloud
```

### 4.6 Solution bonus de rÃ©fÃ©rence

```rust
pub fn multi_cloud_security_audit(input_json: &str) -> String {
    // Solution bonus avec:
    // - Multi-cloud correlation
    // - Kubernetes RBAC audit
    // - Terraform state analysis
    // - CI/CD pipeline security
    // ...
}
```

### 4.7-4.8 Solutions alternatives/refusÃ©es bonus

*(Similaires au format prÃ©cÃ©dent)*

### 4.9 spec.json

```json
{
  "name": "cloud_security_audit",
  "language": "rust",
  "version": "edition2024",
  "type": "code",
  "tier": 1,
  "tier_info": "Concept isolÃ© - Cloud Security Audit",
  "tags": ["security", "cloud", "aws", "azure", "gcp", "phase3"],
  "passing_score": 70,

  "function": {
    "name": "cloud_security_audit",
    "prototype": "pub fn cloud_security_audit(input_json: &str) -> String",
    "return_type": "String",
    "parameters": [
      {"name": "input_json", "type": "&str"}
    ]
  },

  "driver": {
    "reference": "pub fn ref_cloud_security_audit(input_json: &str) -> String { /* see section 4.3 */ }",

    "edge_cases": [
      {
        "name": "s3_public_bucket",
        "args": ["{\"cloud_provider\":\"AWS\",\"resources\":{\"s3_buckets\":[\"test-bucket\"]},\"scan_results\":{\"s3_acl\":{\"test-bucket\":\"public-read\"}}}"],
        "expected_contains": "CRITICAL",
        "is_trap": false
      },
      {
        "name": "lambda_credentials",
        "args": ["{\"cloud_provider\":\"AWS\",\"resources\":{\"lambda_functions\":[\"api\"]},\"scan_results\":{\"lambda_env_vars\":{\"api\":[\"AWS_SECRET_ACCESS_KEY\"]}}}"],
        "expected_contains": "credentials",
        "is_trap": false
      },
      {
        "name": "clean_environment",
        "args": ["{\"cloud_provider\":\"AWS\",\"resources\":{\"s3_buckets\":[\"secure\"]},\"scan_results\":{\"s3_acl\":{\"secure\":\"private\"}}}"],
        "expected_not_contains": "CRITICAL",
        "is_trap": true,
        "trap_explanation": "Private bucket should not trigger finding"
      },
      {
        "name": "empty_resources",
        "args": ["{\"cloud_provider\":\"AWS\",\"resources\":{},\"scan_results\":{}}"],
        "expected_contains": "total_resources",
        "is_trap": true,
        "trap_explanation": "Empty input should return zero resources"
      }
    ],

    "fuzzing": {
      "enabled": true,
      "iterations": 500
    }
  },

  "norm": {
    "allowed_functions": ["serde_json::*", "std::collections::*", "regex::*"],
    "forbidden_functions": ["aws_sdk::*", "azure_sdk::*", "std::process::*"],
    "check_security": true,
    "blocking": true
  },

  "security_checks": {
    "cwe_mapping": ["CWE-732", "CWE-798", "CWE-250", "CWE-918"],
    "owasp_category": "A05:2021-Security Misconfiguration"
  }
}
```

### 4.10 Solutions Mutantes

```rust
// Mutant A (Boundary): Ne dÃ©tecte pas les buckets "public-read-write"
pub fn mutant_a_boundary(input_json: &str) -> String {
    // BUG: VÃ©rifie seulement "public-read", pas "public-read-write"
    let acl = "...";
    if acl == "public-read" {  // ERREUR: missing public-read-write
        // finding
    }
}
// Pourquoi c'est faux: public-read-write est aussi dangereux

// Mutant B (Safety): Panic sur JSON invalide
pub fn mutant_b_safety(input_json: &str) -> String {
    let input: Value = serde_json::from_str(input_json).unwrap();  // PANIC!
}
// Pourquoi c'est faux: Doit gÃ©rer les erreurs gracieusement

// Mutant C (Resource): Ne compte pas les findings correctement
pub fn mutant_c_resource(input_json: &str) -> String {
    // BUG: critical_findings toujours 0
    json!({"audit_summary": {"critical_findings": 0}}).to_string()
}
// Pourquoi c'est faux: Summary doit reflÃ©ter les vrais counts

// Mutant D (Logic): Inverse la logique public/private
pub fn mutant_d_logic(input_json: &str) -> String {
    // BUG: Alerte sur "private" au lieu de "public"
    if acl == "private" {
        findings.push(...)  // ERREUR!
    }
}
// Pourquoi c'est faux: Private est sÃ©curisÃ©, pas une vulnÃ©rabilitÃ©

// Mutant E (Return): Mauvais format de sortie
pub fn mutant_e_return(input_json: &str) -> String {
    json!({"vulnerabilities": []}).to_string()  // ERREUR: devrait Ãªtre "findings"
}
// Pourquoi c'est faux: Le format de sortie doit matcher la spec

// Mutant F (Edge Case): Ne supporte qu'AWS
pub fn mutant_f_edge_case(input_json: &str) -> String {
    // BUG: Ignore Azure et GCP
    if provider != "AWS" {
        return json!({"error": "Unsupported"}).to_string();
    }
}
// Pourquoi c'est faux: Multi-cloud requis
```

---

## ðŸ§  SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

| Concept | Description |
|---------|-------------|
| **Cloud Misconfigurations** | S3 public, IAM over-privileged |
| **Shared Responsibility** | Ce que le cloud provider vs vous sÃ©curisez |
| **IMDS Exploitation** | SSRF vers metadata pour voler credentials |
| **Container Security** | Privileged mode, host networking |
| **Attack Chaining** | Combiner plusieurs vulnÃ©rabilitÃ©s |
| **Compliance** | CIS Benchmarks, Well-Architected |

### 5.2 LDA â€” Traduction en franÃ§ais

```
FONCTION cloud_security_audit QUI RETOURNE UNE CHAÃŽNE ET PREND EN PARAMÃˆTRE input_json QUI EST UNE RÃ‰FÃ‰RENCE VERS UNE CHAÃŽNE
DÃ‰BUT FONCTION
    DÃ‰CLARER input COMME RÃ‰SULTAT DU PARSING JSON DE input_json
    DÃ‰CLARER findings COMME LISTE VIDE DE FINDINGS
    DÃ‰CLARER provider COMME input.cloud_provider

    SELON provider FAIRE
        CAS "AWS" :
            APPELER audit_aws_s3(input, findings)
            APPELER audit_aws_lambda(input, findings)
            APPELER audit_aws_ecs(input, findings)
            APPELER audit_aws_ec2(input, findings)
        CAS "Azure" :
            APPELER audit_azure_storage(input, findings)
            APPELER audit_azure_functions(input, findings)
        CAS "GCP" :
            APPELER audit_gcp_storage(input, findings)
            APPELER audit_gcp_functions(input, findings)
    FIN SELON

    DÃ‰CLARER attack_chains COMME RÃ‰SULTAT DE generate_attack_chains(findings)
    DÃ‰CLARER compliance COMME RÃ‰SULTAT DE generate_compliance_gaps(findings)
    DÃ‰CLARER remediations COMME RÃ‰SULTAT DE prioritize_remediations(findings)

    RETOURNER LE JSON AVEC audit_summary, findings, attack_chains, compliance, remediations
FIN FONCTION
```

### 5.3 Visualisation ASCII

```
                     CLOUD SECURITY AUDIT FLOW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     INPUT ANALYSIS      â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Cloud Provider    â”‚  â”‚
                    â”‚  â”‚ Resources List    â”‚  â”‚
                    â”‚  â”‚ Scan Results      â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     AWS       â”‚     â”‚    AZURE      â”‚     â”‚     GCP       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ S3 Buckets    â”‚     â”‚ Storage Accts â”‚     â”‚ GCS Buckets   â”‚
â”‚ Lambda Funcs  â”‚     â”‚ Functions     â”‚     â”‚ Cloud Funcs   â”‚
â”‚ ECS Tasks     â”‚     â”‚ AKS Clusters  â”‚     â”‚ GKE Clusters  â”‚
â”‚ EC2 IMDS      â”‚     â”‚ VMs           â”‚     â”‚ Compute VMs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    FINDINGS ENGINE      â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Public Storage    â”‚â”€â”€â”¼â”€â”€ CRITICAL
                    â”‚  â”‚ Credential Leak   â”‚â”€â”€â”¼â”€â”€ CRITICAL
                    â”‚  â”‚ IAM Over-Priv     â”‚â”€â”€â”¼â”€â”€ HIGH
                    â”‚  â”‚ Container Escape  â”‚â”€â”€â”¼â”€â”€ HIGH
                    â”‚  â”‚ IMDS Exposure     â”‚â”€â”€â”¼â”€â”€ HIGH
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ATTACK CHAINS â”‚     â”‚  COMPLIANCE   â”‚     â”‚ REMEDIATIONS  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ S3 â†’ Lambda   â”‚     â”‚ CIS Benchmark â”‚     â”‚ Priority 1    â”‚
â”‚  â†’ IAM        â”‚     â”‚ Well-Arch     â”‚     â”‚ Priority 2    â”‚
â”‚   â†’ Admin     â”‚     â”‚ SOC2/HIPAA    â”‚     â”‚ Priority N    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      OUTPUT JSON        â”‚
                    â”‚  {                      â”‚
                    â”‚    audit_summary,       â”‚
                    â”‚    findings,            â”‚
                    â”‚    attack_chains,       â”‚
                    â”‚    compliance_gaps,     â”‚
                    â”‚    remediations         â”‚
                    â”‚  }                      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.4-5.9 *(Sections similaires aux exercices prÃ©cÃ©dents)*

---

## âš ï¸ SECTION 6 : PIÃˆGES â€” RÃ‰CAPITULATIF

| # | PiÃ¨ge | ConsÃ©quence | Solution |
|---|-------|-------------|----------|
| 1 | Ignorer bucket policy | Rater des vulnÃ©rabilitÃ©s | VÃ©rifier ACL ET policy |
| 2 | Faux positifs sur "public-assets" | Alertes inutiles | Contextualiser le nom |
| 3 | Oublier IMDSv1 | Rater SSRF â†’ creds | Toujours vÃ©rifier IMDS |
| 4 | Ignorer IAM roles | Rater privilege escalation | Analyser les rÃ´les |
| 5 | Un seul cloud | Solution incomplÃ¨te | Support multi-cloud |
| 6 | Pas d'attack chain | Sous-estimer le risque | ChaÃ®ner les findings |

---

## ðŸ“ SECTION 7 : QCM

### Question 1
**Qu'est-ce que le "Shared Responsibility Model" dans le cloud ?**

- A) AWS est responsable de tout
- B) Le client est responsable de tout
- C) AWS sÃ©curise l'infrastructure, le client sÃ©curise ses configurations/donnÃ©es
- D) ResponsabilitÃ© partagÃ©e entre AWS et les autres clouds
- E) Un modÃ¨le de facturation
- F) Un type de contrat SLA
- G) Une architecture multi-tenant
- H) Un protocole de communication
- I) Un standard de chiffrement
- J) Un framework de compliance uniquement

**RÃ©ponse : C**

---

### Question 2
**Comment un attaquant peut-il exploiter un bucket S3 avec ACL "public-read" ?**

- A) Impossible sans credentials
- B) Lister et tÃ©lÃ©charger tous les objets avec `--no-sign-request`
- C) Seulement voir les noms de fichiers
- D) Uniquement via la console AWS
- E) NÃ©cessite un VPN
- F) Requiert MFA
- G) Seulement en mode admin
- H) Via SSH uniquement
- I) Avec une clÃ© API
- J) En brute-forÃ§ant le bucket name

**RÃ©ponse : B**

---

### Question 3
**Pourquoi IMDSv1 est-il dangereux ?**

- A) Il n'est pas chiffrÃ©
- B) Il permet de voler les credentials via SSRF sans token
- C) Il ralentit les instances
- D) Il coÃ»te plus cher
- E) Il n'est pas compatible HTTP/2
- F) Il expose les logs
- G) Il dÃ©sactive le firewall
- H) Il permet le bruteforce
- I) Il rÃ©vÃ¨le les clÃ©s SSH
- J) Il expose le code source

**RÃ©ponse : B**

---

### Question 4
**Qu'est-ce qu'un container "privileged" peut faire ?**

- A) Rien de plus qu'un container normal
- B) AccÃ©der Ã  plus de mÃ©moire
- C) AccÃ©der au systÃ¨me hÃ´te et potentiellement s'Ã©chapper
- D) Se connecter Ã  internet plus vite
- E) Utiliser plus de CPU
- F) Avoir plus de storage
- G) AccÃ©der Ã  d'autres containers uniquement
- H) Rien, c'est juste un label
- I) Seulement lire les logs
- J) Envoyer des emails

**RÃ©ponse : C**

---

### Question 5
**OÃ¹ doivent Ãªtre stockÃ©s les secrets dans AWS Lambda ?**

- A) Dans les variables d'environnement en clair
- B) Dans le code source hardcodÃ©
- C) Dans AWS Secrets Manager ou Parameter Store
- D) Dans un fichier .env
- E) Dans les commentaires du code
- F) Dans les tags de la fonction
- G) Dans CloudWatch Logs
- H) Dans le bucket public
- I) Nulle part, Lambda est sÃ©curisÃ© par dÃ©faut
- J) Dans le nom de la fonction

**RÃ©ponse : C**

---

*(Questions 6-10 similaires sur ECS, RBAC, attack chains, CIS Benchmarks, multi-cloud)*

---

## ðŸ“Š SECTION 8 : RÃ‰CAPITULATIF

| Ã‰lÃ©ment | Valeur |
|---------|--------|
| **Exercice** | 3.3.11-a Cloud Security Audit |
| **DifficultÃ©** | â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜† (9/10) |
| **XP Base** | 500 |
| **XP Bonus (ðŸ§ )** | Ã—6 = 3000 |
| **Concepts clÃ©s** | S3, Lambda, ECS, IAM, IMDS, Multi-cloud |
| **CWE** | CWE-732, CWE-798, CWE-250, CWE-918 |
| **OWASP** | A05:2021 Security Misconfiguration |
| **Temps** | ~5h |

---

## ðŸ“¦ SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "3.3.11-a-cloud_security_audit",
    "generated_at": "2026-01-11T00:00:00Z",

    "metadata": {
      "exercise_id": "3.3.11-a",
      "exercise_name": "cloud_security_audit",
      "module": "3.3.11",
      "module_name": "Cloud Security Audit",
      "concept": "a",
      "concept_name": "Cloud Service Exploitation & Container Security",
      "type": "code",
      "tier": 1,
      "phase": 3,
      "difficulty": 9,
      "language": "rust",
      "language_version": "Edition 2024",
      "duration_minutes": 300,
      "xp_base": 500,
      "meme_reference": "Ready Player One"
    }
  }
}
```

---

*"First to the Key, First to the Egg!" â€” La chasse aux Easter Eggs du cloud n'attend pas.*

*HACKBRAIN v5.5.2 â€” L'excellence n'a pas de raccourcis*

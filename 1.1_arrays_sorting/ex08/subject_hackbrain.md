<thinking>
## Analyse du Concept
- Concept : Complexity Analysis & Recurrences - Master Theorem, Amortized Analysis, Cache Behavior
- Phase demand√©e : 1 (Interm√©diaire)
- Adapt√© ? OUI - Ce concept est avanc√© mais Phase 1 peut g√©rer O(n log n) et th√©orie algorithmique

## Combo Base + Bonus
- Exercice de base : Impl√©menter analyse de complexit√©, Master Theorem, analyse amortie, simulation cache
- Bonus : Analyse cache-oblivious, preuves formelles automatis√©es, Akra-Bazzi g√©n√©ralis√©
- Palier bonus : üî• Avanc√© (analyse de complexit√© avanc√©e)
- Progression logique ? OUI - base = outils d'analyse, bonus = techniques avanc√©es

## Pr√©requis & Difficult√©
- Pr√©requis r√©els : Structures de donn√©es, r√©cursivit√©, notion de complexit√© O(n)
- Difficult√© estim√©e : 6/10
- Coh√©rent avec phase ? OUI (Phase 1: 3-5/10, cet exercice est au sommet)

## Aspect Fun/Culture
- Contexte choisi : Steins;Gate (anime sur les voyages temporels, lignes du monde, divergence)
- MEME mn√©motechnique : "El Psy Kongroo" - La phrase myst√©rieuse d'Okabe, comme les patterns cach√©s de complexit√©
- Pourquoi c'est fun :
  * Les "world lines" = classes de complexit√© (chaque algorithme suit une trajectoire)
  * Le "divergence meter" = estimation de complexit√© (mesure de d√©viation)
  * Les "time leaps" = appels r√©cursifs (T(n) = a*T(n/b) + f(n))
  * L'analyse de SERN = benchmarking syst√©matique
  * Reading Steiner = amortized analysis (m√©moire cumulative)
  * L'Attractor Field = invariant de complexit√©

## Sc√©narios d'√âchec (5 mutants concrets)
1. Mutant A (Boundary) : `if sizes.len() < 2` au lieu de `<= 2` dans estimate_complexity
2. Mutant B (Math) : `log_b(a)` calcul√© comme `log(a) * log(b)` au lieu de `log(a) / log(b)`
3. Mutant C (Logic) : Master Theorem Case 2 retourne "n log n" au lieu de "n^c log^(k+1) n"
4. Mutant D (Overflow) : Co√ªt amortis√© calcul√© sans g√©rer le cas total_cost = 0
5. Mutant E (Cache) : Cache hits/misses invers√©s dans simulate_cache_behavior

## Verdict
VALIDE - Excellent exercice de th√©orie algorithmique avec analogie parfaite Steins;Gate
Note qualit√© : 97/100
</thinking>

---

# Exercice 1.1.8 : worldline_analyzer

**Module :**
1.1.8 ‚Äî Complexity Analysis & Recurrences

**Concept :**
h ‚Äî Master Theorem, Amortized Analysis, Cache Effects

**Difficult√© :**
‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ (6/10)

**Type :**
complet

**Tiers :**
3 ‚Äî Synth√®se (tous concepts: benchmarking, Master Theorem, amortized, cache, proofs)

**Langage :**
Rust Edition 2024 / C17

**Pr√©requis :**
- R√©cursivit√© et structures de donn√©es (Module 1.1.0-1.1.3)
- Notation Big-O de base
- Logarithmes et exponentielles

**Domaines :**
Tri, MD, CPU, Mem

**Dur√©e estim√©e :**
60 min

**XP Base :**
150

**Complexit√© :**
T[variable] O(?) √ó S[variable] O(?)

---

## üìê SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichiers √† rendre :**
- Rust : `src/lib.rs`, `Cargo.toml`
- C : `worldline_analyzer.c`, `worldline_analyzer.h`

**Fonctions autoris√©es :**
- Rust : `std::time::*`, op√©rations math√©matiques, `Vec`, `HashMap`
- C : `<time.h>`, `<math.h>`, `<stdlib.h>`, `<stdio.h>`, `clock()`, `log()`, `pow()`

**Fonctions interdites :**
- Biblioth√®ques d'analyse de complexit√© externes
- Appels syst√®me directs (sauf timing)

### 1.2 Consigne

**üéÆ STEINS;GATE ‚Äî L'Organisation a besoin de ton aide, assistant de labo #003**

*"El Psy Kongroo."*

Tu es Rintaro Okabe, le scientifique fou auto-proclam√©. Le Future Gadget Laboratory a d√©couvert que chaque algorithme existe sur une **World Line** diff√©rente ‚Äî une trajectoire de complexit√© qui d√©termine son destin computationnel.

Le **Divergence Meter** du labo peut maintenant mesurer la complexit√© d'un algorithme en observant son comportement temporel. Mais SERN surveille... Tu dois impl√©menter un syst√®me d'analyse complet pour :

1. **Mesurer le temps d'ex√©cution** (comme le D-Mail enregistre les transmissions)
2. **Estimer la classe de complexit√©** (identifier la World Line: O(1), O(n), O(n¬≤)...)
3. **R√©soudre les r√©currences avec le Master Theorem** (calculer l'Attractor Field)
4. **Analyser le co√ªt amorti** (Reading Steiner ‚Äî la m√©moire cumulative)
5. **Simuler le comportement cache** (les timelines parall√®les de la m√©moire)

**Ta mission :**

Impl√©menter le module `worldline_analyzer` qui analyse la complexit√© algorithmique √† travers le temps et l'espace.

### 1.2.2 Version Acad√©mique

Impl√©menter un syst√®me complet d'analyse de complexit√© algorithmique comprenant :

1. **Benchmarking** : Mesure du temps d'ex√©cution pour diff√©rentes tailles d'entr√©e
2. **Estimation de complexit√©** : D√©duction de la classe O() √† partir des mesures
3. **Master Theorem** : R√©solution de r√©currences T(n) = a¬∑T(n/b) + f(n)
4. **Analyse amortie** : Calcul du co√ªt amorti par op√©ration
5. **Simulation cache** : Mod√©lisation des hits/misses pour diff√©rents patterns d'acc√®s

**Entr√©e :**
- `measure_time<F, R>(f: F)` : Fonction √† chronom√©trer
- `benchmark(sizes, generator, algorithm)` : Tailles, g√©n√©rateur de donn√©es, algorithme
- `master_theorem(a, b, k, p)` : Param√®tres de r√©currence
- `analyze_dynamic_array(operations)` : Nombre d'op√©rations push
- `simulate_cache_behavior(pattern, cache_size, block_size)` : Pattern d'acc√®s

**Sortie :**
- Temps d'ex√©cution en Duration/nanosecondes
- Classe de complexit√© estim√©e (enum `Complexity`)
- Formule de complexit√© (String)
- Co√ªts amortis (f64)
- Hits/Misses cache (usize, usize)

**Contraintes :**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  sizes.len() ‚â• 3 (besoin de points pour regression)    ‚îÇ
‚îÇ  a > 0, b > 1 (contraintes Master Theorem)             ‚îÇ
‚îÇ  cache_size > 0, block_size > 0, block_size ‚â§ cache    ‚îÇ
‚îÇ  Pr√©cision estimation : ¬±1 classe de complexit√©        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Exemples :**

| Appel | Retour | Explication |
|-------|--------|-------------|
| `master_theorem(2.0, 2.0, 1.0, 0.0)` | `"Œò(n log n)"` | Merge Sort: log‚ÇÇ(2)=1=k ‚Üí Case 2 |
| `master_theorem(1.0, 2.0, 0.0, 0.0)` | `"Œò(log n)"` | Binary Search: a=1, Case 2 |
| `master_theorem(7.0, 2.0, 2.0, 0.0)` | `"Œò(n^2.807)"` | Strassen: log‚ÇÇ(7)>2 ‚Üí Case 1 |
| `analyze_binary_counter(1024)` | `(2046, 1.999)` | ~2 flips amortis par incr√©mentation |

### 1.3 Prototype

**Rust (Edition 2024) :**

```rust
pub mod worldline_analyzer {
    use std::time::{Duration, Instant};
    use std::collections::HashMap;

    /// World Lines = Classes de complexit√© (comme Steins;Gate)
    #[derive(Debug, Clone, Copy, PartialEq, Eq)]
    pub enum WorldLine {
        Alpha,      // O(1) - Constant - La ligne parfaite
        Beta,       // O(log n) - Logarithmique
        Gamma,      // O(n) - Lin√©aire
        Delta,      // O(n log n) - Lin√©arithmique
        Epsilon,    // O(n¬≤) - Quadratique
        Zeta,       // O(n¬≥) - Cubique
        Omega,      // O(2^n) - Exponentielle - World Line de destruction
        Ragnarok,   // O(n!) - Factorielle - Fin du monde
    }

    /// R√©sultat du Divergence Meter (benchmark)
    #[derive(Debug)]
    pub struct DivergenceReading {
        pub input_sizes: Vec<usize>,
        pub temporal_readings: Vec<Duration>,
        pub detected_worldline: WorldLine,
        pub divergence_ratio: f64,  // Confiance de l'estimation
    }

    // === MESURE TEMPORELLE (D-Mail Recording) ===

    /// Chronom√©trer une fonction (comme enregistrer un D-Mail)
    pub fn record_dmail<F, R>(transmission: F) -> (R, Duration)
    where
        F: FnOnce() -> R;

    /// Benchmark complet avec le Divergence Meter
    pub fn divergence_meter<F, R>(
        input_sizes: &[usize],
        timeline_generator: impl Fn(usize) -> Vec<i32>,
        algorithm: F,
    ) -> DivergenceReading
    where
        F: Fn(&[i32]) -> R;

    /// Identifier la World Line √† partir des mesures
    pub fn identify_worldline(
        sizes: &[usize],
        times: &[Duration]
    ) -> WorldLine;

    // === MASTER THEOREM (Attractor Field Calculator) ===

    /// R√©soudre T(n) = a¬∑T(n/b) + f(n) o√π f(n) = O(n^k ¬∑ log^p(n))
    /// Retourne la formule de complexit√©
    pub fn attractor_field(
        a: f64,      // Nombre de sous-probl√®mes (time leaps)
        b: f64,      // Facteur de r√©duction
        k: f64,      // Exposant de f(n)
        p: f64,      // Exposant logarithmique
    ) -> String;

    /// D√©terminer le Case du Master Theorem (1, 2, ou 3)
    pub fn master_case(a: f64, b: f64, k: f64) -> u8;

    /// Calculer log_b(a) avec pr√©cision
    pub fn critical_exponent(a: f64, b: f64) -> f64;

    // === ANALYSE AMORTIE (Reading Steiner Memory) ===

    /// Analyse du tableau dynamique (push amortis√© O(1))
    /// Retourne (co√ªt total, co√ªt amorti par op√©ration)
    pub fn reading_steiner_array(operations: usize) -> (usize, f64);

    /// Analyse du compteur binaire (incr√©mentation amortie O(1))
    pub fn reading_steiner_counter(increments: usize) -> (usize, f64);

    /// M√©thode du potentiel pour file √† deux piles
    pub fn reading_steiner_queue(operations: &[(bool, i32)]) -> f64;

    // === SIMULATION CACHE (Parallel Timelines) ===

    /// R√©sultat de simulation cache
    #[derive(Debug)]
    pub struct CacheTimeline {
        pub hits: usize,
        pub misses: usize,
        pub hit_ratio: f64,
    }

    /// Simuler le comportement cache avec LRU
    pub fn simulate_timeline(
        access_pattern: &[usize],
        cache_lines: usize,
        block_size: usize,
    ) -> CacheTimeline;

    /// G√©n√©rer pattern row-major (cache-friendly)
    pub fn alpha_pattern(rows: usize, cols: usize) -> Vec<usize>;

    /// G√©n√©rer pattern column-major (cache-unfriendly)
    pub fn omega_pattern(rows: usize, cols: usize) -> Vec<usize>;

    /// Comparer deux impl√©mentations de multiplication matricielle
    pub fn compare_matrix_worldlines(size: usize) -> (Duration, Duration);

    // === PREUVES (Lab Notes) ===

    /// G√©n√©rer les √©tapes de preuve pour binary search O(log n)
    pub fn prove_binary_search() -> Vec<String>;

    /// G√©n√©rer les √©tapes de preuve pour merge sort O(n log n)
    pub fn prove_merge_sort() -> Vec<String>;

    /// G√©n√©rer les √©tapes de preuve pour quicksort average O(n log n)
    pub fn prove_quicksort_average() -> Vec<String>;
}
```

**C (C17) :**

```c
#ifndef WORLDLINE_ANALYZER_H
#define WORLDLINE_ANALYZER_H

#include <stddef.h>
#include <time.h>

// World Lines = Classes de complexit√©
typedef enum {
    WORLDLINE_ALPHA,      // O(1)
    WORLDLINE_BETA,       // O(log n)
    WORLDLINE_GAMMA,      // O(n)
    WORLDLINE_DELTA,      // O(n log n)
    WORLDLINE_EPSILON,    // O(n¬≤)
    WORLDLINE_ZETA,       // O(n¬≥)
    WORLDLINE_OMEGA,      // O(2^n)
    WORLDLINE_RAGNAROK    // O(n!)
} WorldLine;

// R√©sultat de benchmark
typedef struct {
    size_t *input_sizes;
    double *temporal_readings_ns;
    size_t count;
    WorldLine detected_worldline;
    double divergence_ratio;
} DivergenceReading;

// R√©sultat simulation cache
typedef struct {
    size_t hits;
    size_t misses;
    double hit_ratio;
} CacheTimeline;

// === MESURE TEMPORELLE ===

// Chronom√©trer une fonction (retourne nanosecondes)
double record_dmail(void (*func)(void *), void *arg);

// Identifier World Line √† partir des mesures
WorldLine identify_worldline(
    const size_t *sizes,
    const double *times_ns,
    size_t count
);

// === MASTER THEOREM ===

// R√©soudre r√©currence, √©crit r√©sultat dans buffer
void attractor_field(
    double a,
    double b,
    double k,
    double p,
    char *result,
    size_t result_size
);

// D√©terminer le case du Master Theorem
int master_case(double a, double b, double k);

// Calculer log_b(a)
double critical_exponent(double a, double b);

// === ANALYSE AMORTIE ===

// Tableau dynamique: retourne co√ªt total et amorti
void reading_steiner_array(
    size_t operations,
    size_t *total_cost,
    double *amortized_cost
);

// Compteur binaire: retourne flips total et amorti
void reading_steiner_counter(
    size_t increments,
    size_t *total_flips,
    double *amortized_cost
);

// === SIMULATION CACHE ===

// Simuler cache LRU
CacheTimeline simulate_timeline(
    const size_t *access_pattern,
    size_t pattern_length,
    size_t cache_lines,
    size_t block_size
);

// G√©n√©rer patterns d'acc√®s (alloue m√©moire, appelant doit free)
size_t *alpha_pattern(size_t rows, size_t cols);  // row-major
size_t *omega_pattern(size_t rows, size_t cols);  // column-major

// === PREUVES ===

// Retourne nombre d'√©tapes, √©crit dans steps (max_steps entr√©es allou√©es)
size_t prove_binary_search(char **steps, size_t max_steps);
size_t prove_merge_sort(char **steps, size_t max_steps);

#endif // WORLDLINE_ANALYZER_H
```

---

## üí° SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 L'origine du Master Theorem

Le **Master Theorem** a √©t√© formalis√© par Jon Bentley, Dorothea Haken et James B. Saxe en 1980. Il permet de r√©soudre automatiquement une grande classe de r√©currences de la forme T(n) = a¬∑T(n/b) + f(n), √©vitant ainsi des preuves par induction fastidieuses.

Le nom "Master" vient du fait qu'il "ma√Ætrise" une famille enti√®re de r√©currences en un seul th√©or√®me.

### 2.2 Pourquoi l'analyse amortie change tout

L'**analyse amortie** est brillante : au lieu de s'inqui√©ter du pire cas d'une op√©ration isol√©e, on regarde le co√ªt *total* sur une s√©quence.

Exemple concret : `std::vector::push_back()` en C++ a un pire cas O(n) (quand il faut r√©allouer). Mais sur n op√©rations, le co√ªt total est O(n), donc le co√ªt **amorti** est O(1) par op√©ration.

### 2.3 Le secret du cache : la localit√©

Les processeurs modernes ont des caches L1 (~32KB), L2 (~256KB), L3 (~8MB). Un acc√®s cache L1 prend ~1 cycle, un acc√®s RAM prend ~100 cycles. **C'est 100√ó plus lent !**

Parcourir une matrice en row-major (ligne par ligne) est cache-friendly car les √©l√©ments cons√©cutifs sont en m√©moire cons√©cutive. Column-major d√©truit les performances.

### 2.5 DANS LA VRAIE VIE

| M√©tier | Utilisation |
|--------|-------------|
| **Performance Engineer** | Analyse de complexit√© pour optimiser les hotspots |
| **System Architect** | Dimensionnement des syst√®mes selon la croissance attendue |
| **Game Developer** | Analyse cache pour les moteurs de rendu (data-oriented design) |
| **Database Engineer** | Choix des index selon les patterns d'acc√®s |
| **Compiler Writer** | Optimisation des boucles pour la localit√© cache |
| **Quantitative Analyst** | Analyse de complexit√© des algorithmes de trading HFT |

---

## üñ•Ô∏è SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ ls
worldline_analyzer.rs  main.rs  Cargo.toml

$ cargo build --release

$ cargo run --release
[Divergence Meter] Testing linear scan...
Input sizes: [1000, 2000, 4000, 8000, 16000]
Times (¬µs): [45, 90, 181, 362, 724]
Detected World Line: Gamma (O(n))
Divergence ratio: 0.98

[Attractor Field] Merge Sort recurrence:
T(n) = 2¬∑T(n/2) + O(n)
log‚ÇÇ(2) = 1.0, k = 1.0
Case 2 applies: Œò(n log n)

[Reading Steiner] Dynamic array (1000 pushes):
Total cost: 2046 copy operations
Amortized: 2.046 per push

[Cache Timeline] Matrix 100√ó100:
Alpha pattern (row-major): 9876 hits, 124 misses, ratio=98.76%
Omega pattern (col-major): 2451 hits, 7549 misses, ratio=24.51%

All World Lines analyzed successfully!
```

### 3.1 üî• BONUS AVANC√â (OPTIONNEL)

**Difficult√© Bonus :**
‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ (8/10)

**R√©compense :**
XP √ó3

**Time Complexity attendue :**
Variable (selon algorithme analys√©)

**Space Complexity attendue :**
O(n) pour simulation cache, O(1) pour calculs

**Domaines Bonus :**
`MD, CPU, Calcul`

#### 3.1.1 Consigne Bonus

**üéÆ STEINS;GATE ‚Äî Op√©ration Skuld : La convergence finale**

*"Cette fois, nous atteindrons Steins Gate."*

Mayuri est en danger. Pour la sauver, tu dois impl√©menter les **fonctionnalit√©s avanc√©es** du Future Gadget #8 :

1. **Akra-Bazzi g√©n√©ralis√©** : R√©soudre les r√©currences non-standard que le Master Theorem ne couvre pas
2. **Cache-oblivious analysis** : Algorithmes optimaux sans conna√Ætre les param√®tres cache
3. **Preuves automatis√©es** : G√©n√©ration formelle des √©tapes de preuve par substitution

**Ta mission bonus :**

```rust
/// Akra-Bazzi: T(n) = Œ£ a·µ¢¬∑T(n/b·µ¢) + f(n)
pub fn akra_bazzi(
    subproblems: &[(f64, f64)],  // (a·µ¢, b·µ¢) pairs
    f_growth: f64,                // f(n) = Œò(n^f_growth)
) -> String;

/// Algorithme cache-oblivious de transposition matricielle
pub fn cache_oblivious_transpose(matrix: &mut [Vec<i32>]);

/// G√©n√©ration de preuve formelle par substitution
pub fn prove_by_substitution(
    recurrence: &str,
    hypothesis: &str,
) -> Vec<String>;
```

**Contraintes :**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Akra-Bazzi: Œ£ a·µ¢/b·µ¢^p = 1 pour trouver p         ‚îÇ
‚îÇ  Cache-oblivious: O(n¬≤/B) transfers (B = block)    ‚îÇ
‚îÇ  Preuves: Induction math√©matique formelle          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 3.1.2 Prototype Bonus

```rust
// Akra-Bazzi g√©n√©ralis√©
pub fn akra_bazzi(subproblems: &[(f64, f64)], f_growth: f64) -> String;

// Cache-oblivious transpose (divide & conquer)
pub fn cache_oblivious_transpose<T: Copy>(matrix: &mut Vec<Vec<T>>);

// Preuve par substitution
pub fn prove_by_substitution(recurrence: &str, hypothesis: &str) -> Vec<String>;

// Analyse de working set
pub fn analyze_working_set(accesses: &[usize], window_size: usize) -> Vec<usize>;
```

#### 3.1.3 Ce qui change par rapport √† l'exercice de base

| Aspect | Base | Bonus |
|--------|------|-------|
| Master Theorem | 3 cases standard | Akra-Bazzi g√©n√©ralis√© |
| Cache simulation | LRU explicite | Cache-oblivious algorithms |
| Preuves | √âtapes pr√©-√©crites | G√©n√©ration par substitution |
| Complexit√© | O(1) calcul | O(n) analyse num√©rique |

---

## ‚úÖ‚ùå SECTION 4 : ZONE CORRECTION

### 4.1 Moulinette (Tests)

| # | Test | Input | Expected | Points |
|---|------|-------|----------|--------|
| 1 | `identify_worldline` lin√©aire | sizes=[100..6400√ó2], times‚àùn | `Gamma` | 5 |
| 2 | `identify_worldline` quadratique | times‚àùn¬≤ | `Epsilon` | 5 |
| 3 | `identify_worldline` logarithmique | times‚àùlog n | `Beta` | 5 |
| 4 | `master_case` Merge Sort | a=2, b=2, k=1 | 2 | 5 |
| 5 | `master_case` Binary Search | a=1, b=2, k=0 | 2 | 5 |
| 6 | `master_case` Strassen | a=7, b=2, k=2 | 1 | 5 |
| 7 | `attractor_field` Merge Sort | 2,2,1,0 | contains "n log n" | 5 |
| 8 | `attractor_field` Binary Search | 1,2,0,0 | contains "log n" | 5 |
| 9 | `reading_steiner_array` | 1000 | amortized < 3.0 | 10 |
| 10 | `reading_steiner_counter` | 1024 | amortized < 2.0 | 10 |
| 11 | `simulate_timeline` row-major | 100√ó100, cache=1024, block=64 | hits > misses | 10 |
| 12 | `simulate_timeline` col-major | 100√ó100, cache=1024, block=64 | misses > hits | 10 |
| 13 | `alpha_pattern` vs `omega_pattern` | 50√ó50 | Œ±.misses < œâ.misses | 10 |
| 14 | `prove_binary_search` | ‚Äî | ‚â•5 √©tapes valides | 5 |
| 15 | `prove_merge_sort` | ‚Äî | ‚â•5 √©tapes valides | 5 |

### 4.2 main.rs de test

```rust
use worldline_analyzer::*;
use std::time::Duration;

fn main() {
    println!("=== Future Gadget Lab #8: Divergence Meter ===\n");

    // Test 1: Identification de World Line
    let sizes: Vec<usize> = vec![1000, 2000, 4000, 8000, 16000];

    // Simulation temps lin√©aire (O(n))
    let times_linear: Vec<Duration> = vec![
        Duration::from_micros(100),
        Duration::from_micros(200),
        Duration::from_micros(400),
        Duration::from_micros(800),
        Duration::from_micros(1600),
    ];

    let worldline = identify_worldline(&sizes, &times_linear);
    assert_eq!(worldline, WorldLine::Gamma, "Linear should be Gamma");
    println!("[OK] Linear ‚Üí World Line Gamma (O(n))");

    // Simulation temps quadratique (O(n¬≤))
    let times_quad: Vec<Duration> = vec![
        Duration::from_micros(100),
        Duration::from_micros(400),
        Duration::from_micros(1600),
        Duration::from_micros(6400),
        Duration::from_micros(25600),
    ];

    let worldline = identify_worldline(&sizes, &times_quad);
    assert_eq!(worldline, WorldLine::Epsilon, "Quadratic should be Epsilon");
    println!("[OK] Quadratic ‚Üí World Line Epsilon (O(n¬≤))");

    // Test 2: Master Theorem
    println!("\n=== Attractor Field Calculator ===");

    // Merge Sort: T(n) = 2T(n/2) + O(n)
    assert_eq!(master_case(2.0, 2.0, 1.0), 2);
    let result = attractor_field(2.0, 2.0, 1.0, 0.0);
    assert!(result.contains("n log n") || result.contains("n¬∑log(n)"));
    println!("[OK] Merge Sort: {}", result);

    // Binary Search: T(n) = T(n/2) + O(1)
    assert_eq!(master_case(1.0, 2.0, 0.0), 2);
    let result = attractor_field(1.0, 2.0, 0.0, 0.0);
    assert!(result.contains("log n") || result.contains("log(n)"));
    println!("[OK] Binary Search: {}", result);

    // Strassen: T(n) = 7T(n/2) + O(n¬≤)
    assert_eq!(master_case(7.0, 2.0, 2.0), 1);
    let result = attractor_field(7.0, 2.0, 2.0, 0.0);
    println!("[OK] Strassen: {}", result);

    // Test 3: Analyse amortie
    println!("\n=== Reading Steiner Analysis ===");

    let (total, amortized) = reading_steiner_array(1000);
    assert!(amortized < 3.0, "Amortized cost should be < 3");
    println!("[OK] Dynamic array: total={}, amortized={:.3}", total, amortized);

    let (total, amortized) = reading_steiner_counter(1024);
    assert!(amortized < 2.0, "Amortized bit flips should be < 2");
    println!("[OK] Binary counter: total={}, amortized={:.3}", total, amortized);

    // Test 4: Simulation cache
    println!("\n=== Cache Timeline Simulation ===");

    let alpha = alpha_pattern(100, 100);
    let omega = omega_pattern(100, 100);

    let cache_alpha = simulate_timeline(&alpha, 16, 64);
    let cache_omega = simulate_timeline(&omega, 16, 64);

    assert!(cache_alpha.hit_ratio > cache_omega.hit_ratio);
    println!("[OK] Alpha (row-major): {:.2}% hits", cache_alpha.hit_ratio * 100.0);
    println!("[OK] Omega (col-major): {:.2}% hits", cache_omega.hit_ratio * 100.0);

    // Test 5: Preuves
    println!("\n=== Lab Notes (Proofs) ===");

    let proof = prove_binary_search();
    assert!(proof.len() >= 5);
    println!("[OK] Binary search proof: {} steps", proof.len());

    let proof = prove_merge_sort();
    assert!(proof.len() >= 5);
    println!("[OK] Merge sort proof: {} steps", proof.len());

    println!("\n‚úì El Psy Kongroo. All tests passed!");
}
```

### 4.3 Solution de r√©f√©rence (Rust)

```rust
pub mod worldline_analyzer {
    use std::time::{Duration, Instant};
    use std::collections::{HashMap, VecDeque};

    #[derive(Debug, Clone, Copy, PartialEq, Eq)]
    pub enum WorldLine {
        Alpha,      // O(1)
        Beta,       // O(log n)
        Gamma,      // O(n)
        Delta,      // O(n log n)
        Epsilon,    // O(n¬≤)
        Zeta,       // O(n¬≥)
        Omega,      // O(2^n)
        Ragnarok,   // O(n!)
    }

    #[derive(Debug)]
    pub struct DivergenceReading {
        pub input_sizes: Vec<usize>,
        pub temporal_readings: Vec<Duration>,
        pub detected_worldline: WorldLine,
        pub divergence_ratio: f64,
    }

    #[derive(Debug)]
    pub struct CacheTimeline {
        pub hits: usize,
        pub misses: usize,
        pub hit_ratio: f64,
    }

    pub fn record_dmail<F, R>(transmission: F) -> (R, Duration)
    where
        F: FnOnce() -> R,
    {
        let start = Instant::now();
        let result = transmission();
        let elapsed = start.elapsed();
        (result, elapsed)
    }

    pub fn divergence_meter<F, R>(
        input_sizes: &[usize],
        timeline_generator: impl Fn(usize) -> Vec<i32>,
        algorithm: F,
    ) -> DivergenceReading
    where
        F: Fn(&[i32]) -> R,
    {
        let mut times = Vec::with_capacity(input_sizes.len());

        for &size in input_sizes {
            let data = timeline_generator(size);
            let (_, duration) = record_dmail(|| algorithm(&data));
            times.push(duration);
        }

        let worldline = identify_worldline(input_sizes, &times);

        DivergenceReading {
            input_sizes: input_sizes.to_vec(),
            temporal_readings: times,
            detected_worldline: worldline,
            divergence_ratio: 0.95, // Simplified
        }
    }

    pub fn identify_worldline(sizes: &[usize], times: &[Duration]) -> WorldLine {
        if sizes.len() < 2 || times.len() < 2 {
            return WorldLine::Alpha;
        }

        // Calculer les ratios de croissance
        let mut ratios = Vec::new();
        for i in 1..sizes.len() {
            let size_ratio = sizes[i] as f64 / sizes[i - 1] as f64;
            let time_ratio = times[i].as_nanos() as f64 / times[i - 1].as_nanos().max(1) as f64;
            ratios.push(time_ratio / size_ratio);
        }

        let avg_ratio: f64 = ratios.iter().sum::<f64>() / ratios.len() as f64;

        // Classifier selon le ratio moyen
        if avg_ratio < 0.2 {
            WorldLine::Beta  // O(log n): ratio d√©cro√Æt
        } else if avg_ratio < 0.6 {
            WorldLine::Alpha // O(1): ratio ~0
        } else if avg_ratio < 1.3 {
            WorldLine::Gamma // O(n): ratio ~1
        } else if avg_ratio < 1.8 {
            WorldLine::Delta // O(n log n): ratio l√©g√®rement > 1
        } else if avg_ratio < 2.5 {
            WorldLine::Epsilon // O(n¬≤): ratio ~2
        } else if avg_ratio < 3.5 {
            WorldLine::Zeta // O(n¬≥): ratio ~3
        } else {
            WorldLine::Omega // O(2^n): ratio explose
        }
    }

    pub fn critical_exponent(a: f64, b: f64) -> f64 {
        a.ln() / b.ln()
    }

    pub fn master_case(a: f64, b: f64, k: f64) -> u8 {
        let log_b_a = critical_exponent(a, b);
        let epsilon = 0.0001;

        if k < log_b_a - epsilon {
            1 // Case 1: f(n) dominated by recursion
        } else if (k - log_b_a).abs() < epsilon {
            2 // Case 2: f(n) matches recursion
        } else {
            3 // Case 3: f(n) dominates
        }
    }

    pub fn attractor_field(a: f64, b: f64, k: f64, p: f64) -> String {
        let log_b_a = critical_exponent(a, b);
        let case = master_case(a, b, k);

        match case {
            1 => format!("Œò(n^{:.3})", log_b_a),
            2 => {
                if p >= 0.0 {
                    if k < 0.0001 {
                        format!("Œò(log^{} n)", (p + 1.0) as i32)
                    } else {
                        format!("Œò(n^{:.0} ¬∑ log^{} n)", k, (p + 1.0) as i32)
                    }
                } else {
                    format!("Œò(n^{:.0} ¬∑ log log n)", k)
                }
            }
            3 => format!("Œò(n^{:.0})", k),
            _ => "Unknown".to_string(),
        }
    }

    pub fn reading_steiner_array(operations: usize) -> (usize, f64) {
        let mut total_cost: usize = 0;
        let mut capacity: usize = 1;
        let mut size: usize = 0;

        for _ in 0..operations {
            if size == capacity {
                total_cost += size; // Copy all elements
                capacity *= 2;
            }
            total_cost += 1; // Insert operation
            size += 1;
        }

        let amortized = total_cost as f64 / operations as f64;
        (total_cost, amortized)
    }

    pub fn reading_steiner_counter(increments: usize) -> (usize, f64) {
        let mut total_flips: usize = 0;
        let mut counter: u64 = 0;

        for _ in 0..increments {
            let old = counter;
            counter += 1;
            // Count bit flips (XOR gives changed bits)
            total_flips += (old ^ counter).count_ones() as usize;
        }

        let amortized = total_flips as f64 / increments as f64;
        (total_flips, amortized)
    }

    pub fn reading_steiner_queue(operations: &[(bool, i32)]) -> f64 {
        let mut inbox: Vec<i32> = Vec::new();
        let mut outbox: Vec<i32> = Vec::new();
        let mut total_cost: usize = 0;

        for &(is_push, value) in operations {
            if is_push {
                inbox.push(value);
                total_cost += 1;
            } else {
                if outbox.is_empty() {
                    total_cost += inbox.len();
                    while let Some(v) = inbox.pop() {
                        outbox.push(v);
                    }
                }
                if !outbox.is_empty() {
                    outbox.pop();
                    total_cost += 1;
                }
            }
        }

        total_cost as f64 / operations.len() as f64
    }

    pub fn simulate_timeline(
        access_pattern: &[usize],
        cache_lines: usize,
        block_size: usize,
    ) -> CacheTimeline {
        let mut cache: VecDeque<usize> = VecDeque::with_capacity(cache_lines);
        let mut hits: usize = 0;
        let mut misses: usize = 0;

        for &addr in access_pattern {
            let block = addr / block_size;

            if cache.contains(&block) {
                hits += 1;
                // Move to front (LRU)
                cache.retain(|&x| x != block);
                cache.push_front(block);
            } else {
                misses += 1;
                if cache.len() >= cache_lines {
                    cache.pop_back();
                }
                cache.push_front(block);
            }
        }

        let total = hits + misses;
        let hit_ratio = if total > 0 { hits as f64 / total as f64 } else { 0.0 };

        CacheTimeline { hits, misses, hit_ratio }
    }

    pub fn alpha_pattern(rows: usize, cols: usize) -> Vec<usize> {
        let mut pattern = Vec::with_capacity(rows * cols);
        for r in 0..rows {
            for c in 0..cols {
                pattern.push(r * cols + c);
            }
        }
        pattern
    }

    pub fn omega_pattern(rows: usize, cols: usize) -> Vec<usize> {
        let mut pattern = Vec::with_capacity(rows * cols);
        for c in 0..cols {
            for r in 0..rows {
                pattern.push(r * cols + c);
            }
        }
        pattern
    }

    pub fn compare_matrix_worldlines(size: usize) -> (Duration, Duration) {
        let alpha = alpha_pattern(size, size);
        let omega = omega_pattern(size, size);

        let (_, t1) = record_dmail(|| {
            let _sum: usize = alpha.iter().sum();
        });

        let (_, t2) = record_dmail(|| {
            let _sum: usize = omega.iter().sum();
        });

        (t1, t2)
    }

    pub fn prove_binary_search() -> Vec<String> {
        vec![
            "1. R√©currence: T(n) = T(n/2) + O(1)".to_string(),
            "2. √Ä chaque √©tape, l'espace de recherche est divis√© par 2".to_string(),
            "3. Apr√®s k √©tapes: n/2^k = 1, donc k = log‚ÇÇ(n)".to_string(),
            "4. Chaque √©tape co√ªte O(1) (une comparaison)".to_string(),
            "5. Co√ªt total: O(log n) comparaisons".to_string(),
            "6. QED: T(n) = O(log n)".to_string(),
        ]
    }

    pub fn prove_merge_sort() -> Vec<String> {
        vec![
            "1. R√©currence: T(n) = 2¬∑T(n/2) + O(n)".to_string(),
            "2. Application du Master Theorem:".to_string(),
            "   a = 2, b = 2, f(n) = O(n)".to_string(),
            "3. log_b(a) = log‚ÇÇ(2) = 1".to_string(),
            "4. f(n) = O(n^1) o√π k = 1 = log_b(a)".to_string(),
            "5. Case 2 du Master Theorem s'applique".to_string(),
            "6. T(n) = Œò(n^1 ¬∑ log n) = Œò(n log n)".to_string(),
            "7. QED: Merge Sort est O(n log n)".to_string(),
        ]
    }

    pub fn prove_quicksort_average() -> Vec<String> {
        vec![
            "1. R√©currence moyenne: T(n) = (1/n) ¬∑ Œ£[T(k) + T(n-1-k)] + O(n)".to_string(),
            "2. En moyenne, le pivot divise en deux parties √©gales".to_string(),
            "3. R√©currence simplifi√©e: T(n) ‚âà 2¬∑T(n/2) + O(n)".to_string(),
            "4. Identique √† Merge Sort par Master Theorem".to_string(),
            "5. Analyse formelle par indicateurs de Iverson:".to_string(),
            "   E[comparaisons] = 2n¬∑ln(n) + O(n) ‚âà 1.39¬∑n¬∑log‚ÇÇ(n)".to_string(),
            "6. QED: Quicksort average case est O(n log n)".to_string(),
        ]
    }
}
```

### 4.4 Solutions alternatives accept√©es

```rust
// Alternative 1: R√©gression lin√©aire pour estimation de complexit√©
pub fn identify_worldline_regression(sizes: &[usize], times: &[Duration]) -> WorldLine {
    // Transformer en log-log space et faire r√©gression lin√©aire
    let log_sizes: Vec<f64> = sizes.iter().map(|&s| (s as f64).ln()).collect();
    let log_times: Vec<f64> = times.iter()
        .map(|t| (t.as_nanos() as f64).ln())
        .collect();

    // Pente de la r√©gression = exposant de la complexit√©
    let n = log_sizes.len() as f64;
    let sum_x: f64 = log_sizes.iter().sum();
    let sum_y: f64 = log_times.iter().sum();
    let sum_xy: f64 = log_sizes.iter().zip(&log_times).map(|(x, y)| x * y).sum();
    let sum_x2: f64 = log_sizes.iter().map(|x| x * x).sum();

    let slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x);

    match slope {
        s if s < 0.1 => WorldLine::Alpha,
        s if s < 0.5 => WorldLine::Beta,
        s if s < 1.2 => WorldLine::Gamma,
        s if s < 1.5 => WorldLine::Delta,
        s if s < 2.3 => WorldLine::Epsilon,
        s if s < 3.3 => WorldLine::Zeta,
        _ => WorldLine::Omega,
    }
}

// Alternative 2: Cache simulation avec HashSet au lieu de VecDeque
pub fn simulate_timeline_hashset(
    access_pattern: &[usize],
    cache_lines: usize,
    block_size: usize,
) -> CacheTimeline {
    use std::collections::HashSet;

    let mut cache: HashSet<usize> = HashSet::with_capacity(cache_lines);
    let mut lru_order: Vec<usize> = Vec::with_capacity(cache_lines);
    let mut hits = 0;
    let mut misses = 0;

    for &addr in access_pattern {
        let block = addr / block_size;

        if cache.contains(&block) {
            hits += 1;
            lru_order.retain(|&x| x != block);
            lru_order.push(block);
        } else {
            misses += 1;
            if cache.len() >= cache_lines {
                if let Some(&evict) = lru_order.first() {
                    cache.remove(&evict);
                    lru_order.remove(0);
                }
            }
            cache.insert(block);
            lru_order.push(block);
        }
    }

    CacheTimeline {
        hits,
        misses,
        hit_ratio: hits as f64 / (hits + misses) as f64,
    }
}
```

### 4.5 Solutions refus√©es (avec explications)

```rust
// ‚ùå REFUS√â: Master Theorem sans v√©rification des conditions
pub fn attractor_field_wrong(a: f64, b: f64, k: f64, _p: f64) -> String {
    // ERREUR: Ne v√©rifie pas que b > 1 et a > 0
    let log_b_a = a.ln() / b.ln();  // Crash si b = 1 ou n√©gatifs
    format!("Œò(n^{:.3})", log_b_a)
}
// Pourquoi refus√©: Pas de gestion des edge cases, pas de distinction entre les 3 cases

// ‚ùå REFUS√â: Analyse amortie incorrecte
pub fn reading_steiner_array_wrong(operations: usize) -> (usize, f64) {
    // ERREUR: Ne compte pas les copies lors de r√©allocation
    let total_cost = operations;  // Juste les insertions
    (total_cost, 1.0)
}
// Pourquoi refus√©: Ignore compl√®tement le co√ªt de r√©allocation

// ‚ùå REFUS√â: Cache simulation sans LRU
pub fn simulate_timeline_wrong(
    access_pattern: &[usize],
    cache_lines: usize,
    block_size: usize,
) -> CacheTimeline {
    let mut cache: Vec<usize> = Vec::new();
    let mut hits = 0;
    let mut misses = 0;

    for &addr in access_pattern {
        let block = addr / block_size;
        if cache.contains(&block) {
            hits += 1;
            // ERREUR: Pas de mise √† jour LRU
        } else {
            misses += 1;
            if cache.len() >= cache_lines {
                cache.remove(0);  // ERREUR: FIFO au lieu de LRU
            }
            cache.push(block);
        }
    }

    CacheTimeline { hits, misses, hit_ratio: hits as f64 / (hits + misses) as f64 }
}
// Pourquoi refus√©: Impl√©mente FIFO au lieu de LRU
```

### 4.6 Solution bonus de r√©f√©rence

```rust
pub fn akra_bazzi(subproblems: &[(f64, f64)], f_growth: f64) -> String {
    // Trouver p tel que Œ£ a·µ¢/b·µ¢^p = 1
    // Par m√©thode de Newton-Raphson

    let mut p = 1.0;
    for _ in 0..100 {
        let sum: f64 = subproblems.iter()
            .map(|&(a, b)| a / b.powf(p))
            .sum();

        let derivative: f64 = subproblems.iter()
            .map(|&(a, b)| -a * b.ln() / b.powf(p))
            .sum();

        let diff = sum - 1.0;
        if diff.abs() < 1e-10 {
            break;
        }

        p -= diff / derivative;
    }

    // Comparer p avec f_growth
    if f_growth < p - 0.001 {
        format!("Œò(n^{:.3})", p)
    } else if f_growth > p + 0.001 {
        format!("Œò(n^{:.3})", f_growth)
    } else {
        format!("Œò(n^{:.3} ¬∑ log n)", p)
    }
}

pub fn cache_oblivious_transpose<T: Copy>(matrix: &mut Vec<Vec<T>>) {
    fn transpose_block<T: Copy>(
        m: &mut Vec<Vec<T>>,
        r1: usize, r2: usize,
        c1: usize, c2: usize,
    ) {
        if r2 - r1 <= 1 && c2 - c1 <= 1 {
            if r1 < c1 && r1 < m.len() && c1 < m[0].len() {
                let tmp = m[r1][c1];
                m[r1][c1] = m[c1][r1];
                m[c1][r1] = tmp;
            }
            return;
        }

        if r2 - r1 >= c2 - c1 {
            let mid = (r1 + r2) / 2;
            transpose_block(m, r1, mid, c1, c2);
            transpose_block(m, mid, r2, c1, c2);
        } else {
            let mid = (c1 + c2) / 2;
            transpose_block(m, r1, r2, c1, mid);
            transpose_block(m, r1, r2, mid, c2);
        }
    }

    let n = matrix.len();
    if n > 0 {
        let m = matrix[0].len();
        transpose_block(matrix, 0, n, 0, m);
    }
}

pub fn prove_by_substitution(recurrence: &str, hypothesis: &str) -> Vec<String> {
    vec![
        format!("1. Hypoth√®se: {}", hypothesis),
        "2. Base: V√©rifier pour n = 1".to_string(),
        format!("3. Induction: Supposer vrai pour k < n"),
        format!("4. Substitution dans: {}", recurrence),
        "5. D√©veloppement alg√©brique...".to_string(),
        "6. Simplification et v√©rification des constantes".to_string(),
        "7. QED: L'hypoth√®se est prouv√©e".to_string(),
    ]
}

pub fn analyze_working_set(accesses: &[usize], window_size: usize) -> Vec<usize> {
    use std::collections::HashSet;

    accesses.windows(window_size)
        .map(|window| {
            let set: HashSet<_> = window.iter().collect();
            set.len()
        })
        .collect()
}
```

### 4.9 spec.json

```json
{
  "name": "worldline_analyzer",
  "language": "rust",
  "type": "code",
  "tier": 3,
  "tier_info": "Synth√®se (benchmarking + Master Theorem + amortized + cache)",
  "tags": ["complexity", "master-theorem", "amortized", "cache", "phase1"],
  "passing_score": 70,

  "function": {
    "name": "worldline_analyzer",
    "prototype": "pub mod worldline_analyzer",
    "return_type": "module",
    "parameters": []
  },

  "driver": {
    "reference": "// Module complet - voir solution de r√©f√©rence",

    "edge_cases": [
      {
        "name": "identify_linear",
        "test": "identify_worldline with times ‚àù n",
        "expected": "WorldLine::Gamma",
        "is_trap": false
      },
      {
        "name": "identify_quadratic",
        "test": "identify_worldline with times ‚àù n¬≤",
        "expected": "WorldLine::Epsilon",
        "is_trap": false
      },
      {
        "name": "master_case_2",
        "test": "master_case(2.0, 2.0, 1.0)",
        "expected": 2,
        "is_trap": false
      },
      {
        "name": "master_case_1",
        "test": "master_case(7.0, 2.0, 2.0)",
        "expected": 1,
        "is_trap": false
      },
      {
        "name": "amortized_array",
        "test": "reading_steiner_array(1000).1 < 3.0",
        "expected": true,
        "is_trap": true,
        "trap_explanation": "Co√ªt amorti doit √™tre < 3 (O(1) amorti)"
      },
      {
        "name": "amortized_counter",
        "test": "reading_steiner_counter(1024).1 < 2.0",
        "expected": true,
        "is_trap": true,
        "trap_explanation": "En moyenne ~2 flips par incr√©mentation"
      },
      {
        "name": "cache_row_better",
        "test": "alpha_pattern hits > omega_pattern hits",
        "expected": true,
        "is_trap": true,
        "trap_explanation": "Row-major doit √™tre plus cache-friendly"
      },
      {
        "name": "empty_sizes",
        "test": "identify_worldline(&[], &[])",
        "expected": "WorldLine::Alpha",
        "is_trap": true,
        "trap_explanation": "Cas d√©g√©n√©r√© doit retourner O(1)"
      },
      {
        "name": "invalid_master",
        "test": "master_case(0.0, 1.0, 0.0)",
        "expected": "handled gracefully",
        "is_trap": true,
        "trap_explanation": "a=0 ou b=1 invalide le th√©or√®me"
      }
    ],

    "fuzzing": {
      "enabled": true,
      "iterations": 500,
      "generators": [
        {
          "type": "array_float",
          "param_index": 0,
          "params": {
            "min_len": 3,
            "max_len": 10,
            "min_val": 1.0,
            "max_val": 10.0
          }
        }
      ]
    }
  },

  "norm": {
    "allowed_functions": ["std::time", "ln", "log", "pow", "VecDeque", "HashMap"],
    "forbidden_functions": [],
    "check_security": true,
    "check_memory": true,
    "blocking": true
  }
}
```

### 4.10 Solutions Mutantes

```rust
/* Mutant A (Boundary) : Mauvaise comparaison pour l'identification */
pub fn identify_worldline_mutant_a(sizes: &[usize], times: &[Duration]) -> WorldLine {
    if sizes.len() < 2 {  // ERREUR: devrait √™tre <= 1
        return WorldLine::Alpha;
    }
    // ... reste identique
    WorldLine::Gamma
}
// Pourquoi c'est faux: √âchoue avec exactement 2 √©l√©ments
// Ce qui √©tait pens√©: "< 2 signifie moins de 2 √©l√©ments"

/* Mutant B (Math) : Mauvais calcul de log_b(a) */
pub fn critical_exponent_mutant(a: f64, b: f64) -> f64 {
    a.ln() * b.ln()  // ERREUR: multiplication au lieu de division
}
// Pourquoi c'est faux: log_b(a) = ln(a)/ln(b), pas ln(a)*ln(b)
// Ce qui √©tait pens√©: Confusion avec les propri√©t√©s des logarithmes

/* Mutant C (Logic) : Master Theorem Case invers√© */
pub fn master_case_mutant(a: f64, b: f64, k: f64) -> u8 {
    let log_b_a = a.ln() / b.ln();
    if k < log_b_a {
        3  // ERREUR: devrait √™tre 1
    } else if k > log_b_a {
        1  // ERREUR: devrait √™tre 3
    } else {
        2
    }
}
// Pourquoi c'est faux: Cases 1 et 3 invers√©s
// Ce qui √©tait pens√©: Confusion sur quel terme domine

/* Mutant D (Overflow) : Division par z√©ro potentielle */
pub fn reading_steiner_array_mutant(operations: usize) -> (usize, f64) {
    let total_cost = 0;  // ERREUR: initialis√© √† 0 sans accumulation
    let amortized = total_cost as f64 / operations as f64;
    (total_cost, amortized)
}
// Pourquoi c'est faux: total_cost n'est jamais incr√©ment√©
// Ce qui √©tait pens√©: Oubli de compter les op√©rations

/* Mutant E (Cache) : Hits et misses invers√©s */
pub fn simulate_timeline_mutant(
    access_pattern: &[usize],
    cache_lines: usize,
    block_size: usize,
) -> CacheTimeline {
    let mut cache: VecDeque<usize> = VecDeque::new();
    let mut hits = 0;
    let mut misses = 0;

    for &addr in access_pattern {
        let block = addr / block_size;
        if cache.contains(&block) {
            misses += 1;  // ERREUR: devrait √™tre hits
        } else {
            hits += 1;    // ERREUR: devrait √™tre misses
            if cache.len() >= cache_lines {
                cache.pop_back();
            }
            cache.push_front(block);
        }
    }

    CacheTimeline {
        hits,
        misses,
        hit_ratio: hits as f64 / (hits + misses) as f64,
    }
}
// Pourquoi c'est faux: Hits et misses sont invers√©s
// Ce qui √©tait pens√©: Confusion entre "trouv√©" et "pas trouv√©"
```

---

## üß† SECTION 5 : COMPRENDRE

### 5.1 Ce que cet exercice enseigne

1. **Analyse empirique de complexit√©** : Mesurer les temps d'ex√©cution et en d√©duire la classe de complexit√©
2. **Master Theorem** : R√©soudre automatiquement les r√©currences divide-and-conquer
3. **Analyse amortie** : Comprendre le co√ªt moyen sur une s√©quence d'op√©rations
4. **Comportement cache** : Mod√©liser comment la hi√©rarchie m√©moire affecte les performances
5. **Raisonnement formel** : G√©n√©rer des preuves de complexit√©

### 5.2 LDA ‚Äî Traduction litt√©rale

```
FONCTION identify_worldline QUI RETOURNE UNE WORLDLINE ET PREND EN PARAM√àTRES sizes QUI EST UN TABLEAU DE TAILLES ET times QUI EST UN TABLEAU DE DUR√âES
D√âBUT FONCTION
    SI LA LONGUEUR DE sizes EST INF√âRIEURE √Ä 2 OU LA LONGUEUR DE times EST INF√âRIEURE √Ä 2 ALORS
        RETOURNER WorldLine::Alpha
    FIN SI

    D√âCLARER ratios COMME TABLEAU DE FLOTTANTS VIDE

    POUR i ALLANT DE 1 √Ä LA LONGUEUR DE sizes MOINS 1 FAIRE
        D√âCLARER size_ratio COMME L'√âL√âMENT √Ä LA POSITION i DANS sizes DIVIS√â PAR L'√âL√âMENT √Ä LA POSITION i MOINS 1
        D√âCLARER time_ratio COMME LA DUR√âE √Ä LA POSITION i DIVIS√âE PAR LA DUR√âE √Ä LA POSITION i MOINS 1
        AJOUTER time_ratio DIVIS√â PAR size_ratio √Ä ratios
    FIN POUR

    D√âCLARER avg_ratio COMME LA MOYENNE DE ratios

    SI avg_ratio EST INF√âRIEUR √Ä 0.2 ALORS
        RETOURNER WorldLine::Beta
    SINON SI avg_ratio EST INF√âRIEUR √Ä 1.3 ALORS
        RETOURNER WorldLine::Gamma
    SINON SI avg_ratio EST INF√âRIEUR √Ä 2.5 ALORS
        RETOURNER WorldLine::Epsilon
    SINON
        RETOURNER WorldLine::Omega
    FIN SI
FIN FONCTION
```

### 5.2.2 Logic Flow

```
ALGORITHME : Master Theorem Solver
---
1. CALCULER log_b(a) = ln(a) / ln(b)

2. COMPARER k avec log_b(a) :
   |
   |-- SI k < log_b(a) :
   |     RETOURNER "Case 1: Œò(n^{log_b(a)})"
   |     (La r√©cursion domine)
   |
   |-- SI k = log_b(a) :
   |     RETOURNER "Case 2: Œò(n^k ¬∑ log^{p+1}(n))"
   |     (√âquilibre entre r√©cursion et travail)
   |
   |-- SI k > log_b(a) :
   |     RETOURNER "Case 3: Œò(n^k)"
   |     (Le travail domine)

3. V√âRIFIER la condition de r√©gularit√© pour Case 3
```

### 5.2.3 Repr√©sentation Algorithmique (Logique de Garde)

```
FONCTION : simulate_timeline (LRU Cache)
---
INIT cache = file vide, hits = 0, misses = 0

POUR CHAQUE adresse DANS access_pattern :
   |
   |-- CALCULER block = adresse / block_size
   |
   |-- V√âRIFIER si block EST DANS cache :
   |     |
   |     |-- SI OUI (HIT) :
   |     |     INCR√âMENTER hits
   |     |     D√âPLACER block EN T√äTE (LRU update)
   |     |
   |     |-- SI NON (MISS) :
   |           INCR√âMENTER misses
   |           SI cache EST PLEIN :
   |               √âVINCER l'√©l√©ment en queue (LRU)
   |           AJOUTER block EN T√äTE

RETOURNER { hits, misses, hit_ratio }
```

### 5.2.3.1 Diagramme Mermaid

```mermaid
graph TD
    A[T(n) = a¬∑T(n/b) + f(n)] --> B{Calculer log_b(a)}
    B --> C{Comparer k vs log_b(a)}

    C -->|k < log_b(a)| D[Case 1]
    C -->|k = log_b(a)| E[Case 2]
    C -->|k > log_b(a)| F[Case 3]

    D --> G[Œò(n^log_b(a))]
    E --> H[Œò(n^k ¬∑ log^(p+1) n)]
    F --> I{R√©gularit√© ?}

    I -->|Oui| J[Œò(f(n))]
    I -->|Non| K[Master Theorem ne s'applique pas]

    style D fill:#ff9999
    style E fill:#99ff99
    style F fill:#9999ff
```

### 5.3 Visualisation ASCII

**Master Theorem ‚Äî Les trois cases :**

```
                    R√©currence: T(n) = a¬∑T(n/b) + f(n)

    Arbre de r√©cursion:

    Niveau 0:        [ f(n) ]                           Co√ªt: f(n)
                    /   |   \
    Niveau 1:    [f(n/b)][f(n/b)]...[f(n/b)]  (a n≈ìuds)   Co√ªt: a¬∑f(n/b)
                 /|\      /|\        /|\
    Niveau 2:  [...]    [...]      [...]   (a¬≤ n≈ìuds)    Co√ªt: a¬≤¬∑f(n/b¬≤)
                ...
    Niveau k:  [T(1)][T(1)]...[T(1)] (a^k n≈ìuds)         Co√ªt: a^k¬∑O(1)

    o√π k = log_b(n) (profondeur de l'arbre)

    Co√ªt total = Œ£ (de i=0 √† log_b(n)) a^i ¬∑ f(n/b^i)

    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    CASE 1: f(n) est "l√©g√®re" (k < log_b(a))
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    Les feuilles dominent!

         ‚óã                     Peu de travail en haut
        /|\
       ‚óã ‚óã ‚óã                   Un peu plus
      /|\/|\/|\
     ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè                 BOOM! Tout le travail est ici

    ‚Üí T(n) = Œò(n^log_b(a))

    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    CASE 2: f(n) est "√©quilibr√©e" (k = log_b(a))
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    Chaque niveau contribue √©galement!

         ‚óè                     1√ó travail
        /|\
       ‚óè ‚óè ‚óè                   1√ó travail
      /|\/|\/|\
     ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè ‚óè          1√ó travail

    ‚Üí T(n) = Œò(n^k ¬∑ log n)  (log n niveaux)

    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    CASE 3: f(n) est "lourde" (k > log_b(a))
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    La racine domine!

         ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè             Tout le travail est ici!
        /|\
       ‚óã ‚óã ‚óã                   Moins
      /|\/|\/|\
     ¬∑ ¬∑ ¬∑ ¬∑ ¬∑ ¬∑ ¬∑            Presque rien

    ‚Üí T(n) = Œò(f(n))
```

**Analyse Amortie ‚Äî Tableau dynamique :**

```
    Op√©ration #:  1   2   3   4   5   6   7   8   9  ...

    Capacit√©:     1   2   2   4   4   4   4   8   8  ...

    Co√ªt r√©el:    1   2   1   3   1   1   1   5   1  ...
                  ‚îÇ   ‚îÇ       ‚îÇ               ‚îÇ
                  ‚îÇ   ‚îî‚îÄ copie 1 √©l√©ment     ‚îî‚îÄ copie 4 √©l√©ments
                  ‚îÇ         + insert              + insert
                  ‚îî‚îÄ copie 0 + insert

    Cumul co√ªt:   1   3   4   7   8   9  10  15  16  ...

    Co√ªt amorti = Cumul / # op√©rations
                = 16 / 9 ‚âà 1.78

    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Pour n op√©rations:                                     ‚îÇ
    ‚îÇ  Co√ªt total ‚â§ n + n/2 + n/4 + n/8 + ... ‚â§ 2n           ‚îÇ
    ‚îÇ  Co√ªt amorti ‚â§ 2n/n = 2 = O(1)                         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Simulation Cache ‚Äî Row-major vs Column-major :**

```
    Matrice 4√ó4 en m√©moire (row-major storage):

    Logique:               En RAM (lin√©aire):
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ 0  ‚îÇ 1  ‚îÇ 2  ‚îÇ 3 ‚îÇ   [0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ 4  ‚îÇ 5  ‚îÇ 6  ‚îÇ 7 ‚îÇ      Block 0     Block 1     Block 2       Block 3
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 8  ‚îÇ 9  ‚îÇ 10 ‚îÇ 11‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ 12 ‚îÇ 13 ‚îÇ 14 ‚îÇ 15‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    Acc√®s ROW-MAJOR (Alpha pattern):        Acc√®s COLUMN-MAJOR (Omega pattern):
    0 ‚Üí 1 ‚Üí 2 ‚Üí 3 ‚Üí 4 ‚Üí 5 ‚Üí ...            0 ‚Üí 4 ‚Üí 8 ‚Üí 12 ‚Üí 1 ‚Üí 5 ‚Üí 9 ‚Üí ...

    Cache (4 blocs, block_size=4):          Cache (4 blocs, block_size=4):

    Acc√®s 0: MISS, charge Block 0           Acc√®s 0: MISS, charge Block 0
    Acc√®s 1: HIT  (dans Block 0)            Acc√®s 4: MISS, charge Block 1
    Acc√®s 2: HIT  (dans Block 0)            Acc√®s 8: MISS, charge Block 2
    Acc√®s 3: HIT  (dans Block 0)            Acc√®s 12: MISS, charge Block 3
    Acc√®s 4: MISS, charge Block 1           Acc√®s 1: MISS! Block 0 √©vinc√©!
    ...                                     ...

    R√©sultat: 4 MISS, 12 HIT               R√©sultat: 16 MISS, 0 HIT
    Hit ratio: 75%                          Hit ratio: 0%
```

### 5.4 Les pi√®ges en d√©tail

| Pi√®ge | Description | Solution |
|-------|-------------|----------|
| **Division par z√©ro** | `ln(1) = 0` dans log_b(a) quand b=1 | V√©rifier b > 1 avant calcul |
| **Overflow de temps** | Duration::as_nanos() overflow sur 32 bits | Utiliser u128 ou as_secs_f64 |
| **Case 3 sans r√©gularit√©** | Master Theorem ne s'applique pas toujours | V√©rifier a¬∑f(n/b) ‚â§ c¬∑f(n) |
| **Bruit de mesure** | Variations de temps d'ex√©cution | Faire plusieurs runs, prendre m√©diane |
| **Cache froid** | Premier run plus lent | Warmup avant mesure |

### 5.5 Cours Complet

#### 5.5.1 Analyse de Complexit√© Empirique

La mesure empirique de complexit√© consiste √†:
1. Ex√©cuter l'algorithme pour diff√©rentes tailles n
2. Mesurer le temps d'ex√©cution T(n)
3. Calculer le ratio T(2n)/T(n)

Ce ratio r√©v√®le la complexit√©:
- O(1): ratio ‚âà 1
- O(log n): ratio ‚âà 1 + Œµ (d√©croissant)
- O(n): ratio ‚âà 2
- O(n log n): ratio ‚âà 2 + Œµ (croissant lentement)
- O(n¬≤): ratio ‚âà 4
- O(2^n): ratio explose

#### 5.5.2 Le Master Theorem

Pour T(n) = a¬∑T(n/b) + f(n):

**Intuition:** On compare le "poids" des feuilles (a^(log_b n) = n^(log_b a)) au travail f(n).

**Case 1:** Les feuilles dominent
- Condition: f(n) = O(n^c) avec c < log_b(a)
- R√©sultat: T(n) = Œò(n^(log_b a))

**Case 2:** √âquilibre √† tous les niveaux
- Condition: f(n) = Œò(n^(log_b a) ¬∑ log^k n)
- R√©sultat: T(n) = Œò(n^(log_b a) ¬∑ log^(k+1) n)

**Case 3:** La racine domine
- Condition: f(n) = Œ©(n^c) avec c > log_b(a) ET r√©gularit√©
- R√©sultat: T(n) = Œò(f(n))

#### 5.5.3 Analyse Amortie

Trois m√©thodes:
1. **Agr√©gat:** Co√ªt total / nombre d'op√©rations
2. **Comptable (Banker's):** Cr√©dits pour op√©rations futures
3. **Potentiel:** Œ¶(√©tat) ‚Üí co√ªt amorti = co√ªt r√©el + ŒîŒ¶

Exemples classiques:
- Vector::push_back: O(1) amorti (g√©om√©trique)
- Compteur binaire: O(1) amorti par incr√©mentation
- Union-Find: O(Œ±(n)) amorti avec path compression

#### 5.5.4 Hi√©rarchie Cache

```
Registres:   1 cycle     (~100 bytes)
L1 Cache:    3-4 cycles  (~32 KB)
L2 Cache:    10-12 cycles (~256 KB)
L3 Cache:    30-40 cycles (~8 MB)
RAM:         100+ cycles  (GB)
SSD:         10,000+ cycles
HDD:         10,000,000+ cycles
```

**Localit√© spatiale:** Acc√©der √† des adresses proches
**Localit√© temporelle:** R√©acc√©der aux m√™mes donn√©es

### 5.6 Normes avec explications

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚ùå HORS NORME                                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ let ratio = a.ln() * b.ln();  // Mauvais calcul de log         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚úÖ CONFORME                                                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ let ratio = a.ln() / b.ln();  // Correct: log_b(a)             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üìñ POURQUOI ?                                                   ‚îÇ
‚îÇ log_b(a) = log(a) / log(b) par changement de base              ‚îÇ
‚îÇ Multiplier donne un r√©sultat sans signification math√©matique   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.7 Simulation avec trace d'ex√©cution

**Trace: master_case(7.0, 2.0, 2.0) ‚Äî Strassen**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âtape ‚îÇ Instruction                              ‚îÇ Valeur     ‚îÇ Explication         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   1   ‚îÇ Calculer ln(7)                           ‚îÇ 1.9459     ‚îÇ Logarithme naturel  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   2   ‚îÇ Calculer ln(2)                           ‚îÇ 0.6931     ‚îÇ ln(2)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   3   ‚îÇ log_b(a) = ln(7)/ln(2)                   ‚îÇ 2.807      ‚îÇ log‚ÇÇ(7)             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   4   ‚îÇ Comparer k=2.0 avec log_b(a)=2.807       ‚îÇ 2.0 < 2.807‚îÇ k est plus petit    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   5   ‚îÇ Case 1 s'applique                        ‚îÇ return 1   ‚îÇ Feuilles dominent   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   6   ‚îÇ Complexit√© = Œò(n^2.807)                  ‚îÇ r√©sultat   ‚îÇ Strassen             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.8 Mn√©motechniques

#### üéÆ MEME : "El Psy Kongroo" ‚Äî Steins;Gate et les World Lines

Comme Okabe dans Steins;Gate qui doit identifier sur quelle "World Line" il se trouve en mesurant la divergence, tu dois identifier la complexit√© de ton algorithme en mesurant les temps d'ex√©cution.

- **World Line Alpha (O(1)):** Le paradis ‚Äî temps constant
- **World Line Beta (O(log n)):** Presque parfait
- **World Line Gamma (O(n)):** Acceptable
- **World Line Omega (O(2^n)):** La destruction ‚Äî √©viter √† tout prix!

```rust
// El Psy Kongroo - La phrase de Okabe
// Comme chercher le Steins Gate (l'optimum), on cherche la vraie complexit√©
let worldline = identify_worldline(&sizes, &times);
match worldline {
    WorldLine::Alpha => println!("Perfect! O(1)"),
    WorldLine::Omega => println!("The organization is watching... O(2^n)!"),
    _ => println!("Continue searching for Steins Gate..."),
}
```

#### üî¨ MEME : "Reading Steiner" ‚Äî La m√©moire cumulative

Dans Steins;Gate, le "Reading Steiner" est la capacit√© d'Okabe √† retenir les souvenirs √† travers les sauts temporels. C'est exactement l'analyse amortie: on "retient" le co√ªt cumul√© pour calculer le co√ªt moyen.

```rust
// Reading Steiner pour le tableau dynamique
// On accumule les souvenirs (co√ªts) √† travers le temps
let (total_memories, avg_per_leap) = reading_steiner_array(1000);
// M√™me si certains sauts co√ªtent cher (r√©allocation),
// en moyenne c'est O(1) par saut!
```

### 5.9 Applications pratiques

| Application | Technique utilis√©e |
|-------------|-------------------|
| Profiling CPU | Benchmarking empirique |
| Choix d'algorithme | Master Theorem pour comparer |
| Database indexing | Analyse cache pour B-trees |
| Vector::push_back | Analyse amortie O(1) |
| Compilateur JIT | Estimation de co√ªt d'inlining |

---

## ‚ö†Ô∏è SECTION 6 : PI√àGES ‚Äî R√âCAPITULATIF

| # | Pi√®ge | Impact | Pr√©vention |
|---|-------|--------|------------|
| 1 | Division par z√©ro (b=1) | Crash/NaN | V√©rifier b > 1 |
| 2 | Overflow nanosecondes | Mauvaise mesure | Utiliser u128 |
| 3 | Cache froid | Biais de mesure | Warmup runs |
| 4 | Master Theorem sans r√©gularit√© | R√©sultat faux | V√©rifier condition |
| 5 | LRU invers√© (FIFO) | Mauvais hit ratio | Impl√©menter vrai LRU |

---

## üìù SECTION 7 : QCM

### Question 1
Pour la r√©currence T(n) = 4¬∑T(n/2) + n, quel case du Master Theorem s'applique?

- A) Case 1 car log‚ÇÇ(4) = 2 > 1
- B) Case 2 car log‚ÇÇ(4) = 2 = k
- C) Case 3 car n domine 4¬∑T(n/2)
- D) Le Master Theorem ne s'applique pas
- E) Case 1 car k=1 < log‚ÇÇ(4)=2

<details>
<summary>R√©ponse</summary>
**E)** log‚ÇÇ(4) = 2, et f(n) = n = n¬π, donc k=1 < 2 = log_b(a). Case 1 s'applique, T(n) = Œò(n¬≤).
</details>

### Question 2
Quel est le co√ªt amorti de `push_back` sur un vector qui double de capacit√©?

- A) O(n) car parfois on copie tout
- B) O(log n) car on double
- C) O(1) car la moyenne est constante
- D) O(n¬≤) car on fait n push de O(n) chacun
- E) Impossible √† d√©terminer

<details>
<summary>R√©ponse</summary>
**C)** Sur n op√©rations, le co√ªt total est ‚â§ 2n (somme g√©om√©trique), donc O(2n/n) = O(1) amorti.
</details>

### Question 3
Pourquoi l'acc√®s column-major √† une matrice est-il lent?

- A) Les colonnes sont plus longues
- B) On saute d'un bloc cache √† l'autre
- C) Le CPU pr√©f√®re les lignes
- D) C'est une illusion, les deux sont identiques
- E) La m√©moire est organis√©e en colonnes

<details>
<summary>R√©ponse</summary>
**B)** En row-major storage, les √©l√©ments d'une colonne ne sont pas contigus en m√©moire. Chaque acc√®s charge un nouveau bloc cache, causant des cache misses syst√©matiques.
</details>

### Question 4
Quelle est la complexit√© de Strassen (multiplication matricielle)?

- A) O(n¬≤)
- B) O(n¬≥)
- C) O(n^2.807)
- D) O(n¬≤ log n)
- E) O(n^2.376)

<details>
<summary>R√©ponse</summary>
**C)** Strassen: T(n) = 7¬∑T(n/2) + O(n¬≤). log‚ÇÇ(7) ‚âà 2.807, donc Case 1: Œò(n^2.807).
</details>

### Question 5
Dans l'analyse amortie par potentiel, le co√ªt amorti est:

- A) co√ªt_r√©el + Œ¶(avant)
- B) co√ªt_r√©el - Œ¶(apr√®s)
- C) co√ªt_r√©el + ŒîŒ¶
- D) Œ¶(apr√®s) - Œ¶(avant)
- E) max(co√ªt_r√©el, Œ¶)

<details>
<summary>R√©ponse</summary>
**C)** Co√ªt amorti = co√ªt r√©el + Œ¶(apr√®s) - Œ¶(avant) = co√ªt r√©el + ŒîŒ¶.
</details>

---

## üìä SECTION 8 : R√âCAPITULATIF

| √âl√©ment | Valeur |
|---------|--------|
| **Exercice** | 1.1.8 ‚Äî worldline_analyzer |
| **Difficult√©** | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ (6/10) |
| **XP Base** | 150 |
| **XP Bonus** | √ó3 (450 XP) |
| **Temps estim√©** | 60 min |
| **Concepts cl√©s** | Master Theorem, Amortized Analysis, Cache Simulation |
| **Langage** | Rust Edition 2024 / C17 |
| **R√©f√©rence culture** | Steins;Gate (World Lines, Divergence Meter) |

---

## üì¶ SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "1.1.8-worldline-analyzer",
    "generated_at": "2026-01-11 10:00:00",

    "metadata": {
      "exercise_id": "1.1.8",
      "exercise_name": "worldline_analyzer",
      "module": "1.1",
      "module_name": "Arrays & Sorting",
      "concept": "h",
      "concept_name": "Complexity Analysis & Recurrences",
      "type": "complet",
      "tier": 3,
      "tier_info": "Synth√®se",
      "phase": 1,
      "difficulty": 6,
      "difficulty_stars": "‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ",
      "language": "rust",
      "duration_minutes": 60,
      "xp_base": 150,
      "xp_bonus_multiplier": 3,
      "bonus_tier": "AVANC√â",
      "bonus_icon": "üî•",
      "complexity_time": "Variable",
      "complexity_space": "Variable",
      "prerequisites": ["recursion", "big-o-basics"],
      "domains": ["Tri", "MD", "CPU", "Mem"],
      "domains_bonus": ["Calcul"],
      "tags": ["complexity", "master-theorem", "amortized", "cache"],
      "meme_reference": "Steins;Gate - El Psy Kongroo"
    },

    "files": {
      "spec.json": "/* Section 4.9 */",
      "references/ref_solution.rs": "/* Section 4.3 */",
      "references/ref_solution_bonus.rs": "/* Section 4.6 */",
      "alternatives/alt_regression.rs": "/* Section 4.4 */",
      "mutants/mutant_a_boundary.rs": "/* Section 4.10 */",
      "mutants/mutant_b_math.rs": "/* Section 4.10 */",
      "mutants/mutant_c_logic.rs": "/* Section 4.10 */",
      "mutants/mutant_d_overflow.rs": "/* Section 4.10 */",
      "mutants/mutant_e_cache.rs": "/* Section 4.10 */",
      "tests/main.rs": "/* Section 4.2 */"
    },

    "validation": {
      "expected_pass": [
        "references/ref_solution.rs",
        "references/ref_solution_bonus.rs",
        "alternatives/alt_regression.rs"
      ],
      "expected_fail": [
        "mutants/mutant_a_boundary.rs",
        "mutants/mutant_b_math.rs",
        "mutants/mutant_c_logic.rs",
        "mutants/mutant_d_overflow.rs",
        "mutants/mutant_e_cache.rs"
      ]
    }
  }
}
```

---

*Exercice g√©n√©r√© par HACKBRAIN v5.5.2 ‚Äî "El Psy Kongroo"*
*L'excellence p√©dagogique ne se n√©gocie pas ‚Äî pas de raccourcis*

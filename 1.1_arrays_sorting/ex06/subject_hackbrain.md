<thinking>
## Analyse du Concept
- Concept : Coordinate Compression (compression de coordonnÃ©es)
- Phase demandÃ©e : 1
- AdaptÃ© ? OUI â€” Technique intermÃ©diaire-avancÃ©e pour Phase 1. Transforme des valeurs sparses en indices denses.

## Combo Base + Bonus
- Exercice de base : ImplÃ©menter Compressor 1D/2D + applications (count_smaller, LIS, RangeFrequency)
- Bonus : Segment Tree avec compression pour requÃªtes dynamiques
- Palier bonus : ğŸ”¥ AvancÃ©
- Progression logique ? OUI â€” Base = compression + requÃªtes statiques, Bonus = structures dynamiques

## PrÃ©requis & DifficultÃ©
- PrÃ©requis rÃ©els : Sorting, HashMap, Binary Search, prefix sums
- DifficultÃ© estimÃ©e : 6/10
- CohÃ©rent avec phase ? OUI â€” Proche du max Phase 1

## Aspect Fun/Culture
- Contexte choisi : Ant-Man / Marvel â€” Pym Particles
- MEME mnÃ©motechnique : "I shrink therefore I am" / "What is this, a coordinate for ants?"
- Pourquoi c'est fun : Analogie parfaite entre compression (shrinking) et Pym Particles. Les milliards deviennent des petits indices, comme Scott Lang qui devient microscopique.

## ScÃ©narios d'Ã‰chec (5 mutants)
1. Mutant A (Boundary) : Off-by-one dans binary_search pour compress
2. Mutant B (Safety) : Ne gÃ¨re pas la valeur non trouvÃ©e dans decompress
3. Mutant C (Order) : Oublie de dÃ©dupliquer les valeurs triÃ©es
4. Mutant D (Logic) : Mauvais sens de tri pour count_smaller_to_right
5. Mutant E (Return) : LIS retourne la longueur du tableau dp au lieu du max

## Verdict
VALIDE â€” Analogie Ant-Man excellente, exercice technique couvrant compression + applications avancÃ©es
Note crÃ©ativitÃ© : 96/100
</thinking>

---

# Exercice 1.1.6 : pym_particles

**Module :**
1.1 â€” Arrays & Sorting

**Concept :**
l â€” Coordinate Compression

**DifficultÃ© :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜†â˜† (6/10)

**Type :**
complet

**Tiers :**
3 â€” SynthÃ¨se (compression 1D + 2D + applications Fenwick/DP)

**Langages :**
Rust Edition 2024 / C17

**PrÃ©requis :**
- Binary Search
- HashMap / Sorting
- Prefix Sums (ex05)

**Domaines :**
Struct, Tri, DP

**DurÃ©e estimÃ©e :**
75 min

**XP Base :**
180

**ComplexitÃ© :**
T2 O(n log n) construction Ã— S2 O(n) stockage

---

## ğŸ“ SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichiers Ã  rendre :**
- **Rust :** `src/lib.rs`, `Cargo.toml`
- **C :** `pym_particles.c`, `pym_particles.h`

**Fonctions autorisÃ©es :**
- Rust : std (Vec, HashMap, BTreeMap, collections)
- C : malloc, free, qsort, bsearch, memset

**Fonctions interdites :**
- BibliothÃ¨ques externes de compression

---

### 1.2 Consigne

#### 1.2.1 Version Culture Pop

**ğŸœ ANT-MAN â€” "What is this, a coordinate for ants?"**

Scott Lang a un problÃ¨me. Les coordonnÃ©es du Quantum Realm sont astronomiques â€” des valeurs en milliards. Mais son Ã©quipement ne peut stocker que quelques milliers d'indices.

**La solution de Hank Pym :** Les **Pym Particles** de compression !

Au lieu de manipuler directement les coordonnÃ©es gÃ©antes, on les **shrink** vers de petits indices (0, 1, 2, ...) tout en gardant l'ordre relatif. Quand on a besoin de la vraie valeur, on **grow** back !

```
CoordonnÃ©es Quantum :  [1_000_000_000, 42, 999_999_999]
                              â†“ SHRINK (Pym Particles) â†“
Indices compressÃ©s :   [2, 0, 1]

    42 â†’ 0        (le plus petit)
    999_999_999 â†’ 1
    1_000_000_000 â†’ 2    (le plus grand)
```

**Pourquoi Ã§a marche ?**
On ne se soucie que de l'**ordre relatif**, pas des valeurs absolues. Si tu as 10^9 mais seulement 1000 valeurs uniques, tu peux tout mapper sur [0, 999].

**Ta mission :**

CrÃ©er le **Pym Particle Compressor** â€” un systÃ¨me de compression de coordonnÃ©es pour naviguer dans le Quantum Realm.

---

#### 1.2.2 Version AcadÃ©mique

**Coordinate Compression :**

Technique qui remplace un ensemble de valeurs larges et sparses par des indices consÃ©cutifs [0, k-1] oÃ¹ k est le nombre de valeurs uniques.

**PropriÃ©tÃ©s prÃ©servÃ©es :**
- L'ordre relatif est maintenu
- Ã‰galitÃ© prÃ©servÃ©e (mÃªmes valeurs â†’ mÃªme index)
- Bijection rÃ©versible (decompress possible)

**Algorithme :**
1. Collecter toutes les valeurs
2. Trier et dÃ©dupliquer â†’ `sorted_unique`
3. CrÃ©er mapping valeur â†’ index (HashMap ou binary search)
4. Pour compresser : lookup dans le mapping

**Applications :**
- Structures de donnÃ©es sur coordonnÃ©es (Fenwick Tree, Segment Tree)
- LIS en O(n log n) avec DP
- RequÃªtes de plage avec valeurs arbitraires

---

### 1.3 Prototypes

#### Rust

```rust
pub mod pym_particles {
    use std::collections::HashMap;
    use std::hash::Hash;

    /// 1D Coordinate Compressor â€” "The Pym Suit"
    pub struct PymCompressor<T: Ord + Clone + Hash> {
        sorted_unique: Vec<T>,
        value_to_index: HashMap<T, usize>,
    }

    impl<T: Ord + Clone + Hash> PymCompressor<T> {
        /// Construire le compresseur depuis un ensemble de coordonnÃ©es
        pub fn new(coordinates: &[T]) -> Self;

        /// Shrink une coordonnÃ©e vers son index compressÃ©
        pub fn shrink(&self, value: &T) -> Option<usize>;

        /// Grow un index vers sa coordonnÃ©e originale
        pub fn grow(&self, index: usize) -> Option<&T>;

        /// Nombre de coordonnÃ©es uniques
        pub fn size(&self) -> usize;

        /// Shrink un tableau entier
        pub fn shrink_all(&self, values: &[T]) -> Vec<usize>;

        /// Lower bound: plus petit index >= value
        pub fn lower_bound(&self, value: &T) -> usize;

        /// Upper bound: plus petit index > value
        pub fn upper_bound(&self, value: &T) -> usize;
    }

    /// 2D Compressor â€” "Quantum Realm Navigator"
    pub struct QuantumNavigator {
        x_pym: PymCompressor<i64>,
        y_pym: PymCompressor<i64>,
    }

    impl QuantumNavigator {
        pub fn new(points: &[(i64, i64)]) -> Self;
        pub fn shrink_point(&self, point: (i64, i64)) -> (usize, usize);
        pub fn grow_point(&self, compressed: (usize, usize)) -> (i64, i64);
        pub fn grid_size(&self) -> (usize, usize);
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // APPLICATIONS â€” "Using the Pym Suit"
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    /// Count smaller elements to the right
    /// "How many smaller ants are behind me?"
    /// Uses compression + Fenwick Tree
    pub fn count_smaller_behind(arr: &[i32]) -> Vec<i32>;

    /// Longest Increasing Subsequence
    /// "The longest chain of growing ants"
    /// Uses compression + patience sort / DP with binary search
    pub fn longest_growth_chain(arr: &[i64]) -> usize;

    /// Distinct elements in range queries
    /// "How many unique ant species in this sector?"
    /// Uses compression + offline processing
    pub fn unique_species_in_sectors(
        arr: &[i32],
        queries: &[(usize, usize)],
    ) -> Vec<usize>;

    /// Range frequency query structure
    /// "How many times does ant #X appear in sector?"
    pub struct AntCensus {
        // Positions de chaque valeur compressÃ©e
        positions: Vec<Vec<usize>>,
        compressor: PymCompressor<i32>,
    }

    impl AntCensus {
        pub fn new(arr: &[i32]) -> Self;
        pub fn count_ant(&self, left: usize, right: usize, value: i32) -> usize;
    }

    /// Count points in rectangles
    /// "How many ants in each Quantum zone?"
    pub fn ants_in_zones(
        ant_positions: &[(i64, i64)],
        zones: &[(i64, i64, i64, i64)],  // (x1, y1, x2, y2)
    ) -> Vec<i64>;
}
```

#### C

```c
#ifndef PYM_PARTICLES_H
#define PYM_PARTICLES_H

#include <stddef.h>
#include <stdint.h>

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// STRUCTURES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// 1D Compressor
typedef struct s_pym_compressor {
    int64_t *sorted_unique;
    size_t   unique_count;
} t_pym_compressor;

// 2D Compressor
typedef struct s_quantum_navigator {
    t_pym_compressor *x_pym;
    t_pym_compressor *y_pym;
} t_quantum_navigator;

// Range Frequency
typedef struct s_ant_census {
    size_t **positions;      // positions[value_idx] = array of positions
    size_t  *pos_counts;     // count per value
    t_pym_compressor *comp;
} t_ant_census;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONSTRUCTEURS & DESTRUCTEURS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

t_pym_compressor   *pym_compressor_new(const int64_t *coords, size_t n);
void                pym_compressor_free(t_pym_compressor *comp);

t_quantum_navigator *quantum_navigator_new(const int64_t *xs, const int64_t *ys, size_t n);
void                 quantum_navigator_free(t_quantum_navigator *nav);

t_ant_census       *ant_census_new(const int *arr, size_t n);
void                ant_census_free(t_ant_census *census);

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// OPÃ‰RATIONS â€” "Pym Particle Manipulation"
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// 1D Compression
ssize_t pym_shrink(const t_pym_compressor *comp, int64_t value);
int64_t pym_grow(const t_pym_compressor *comp, size_t index);
size_t  pym_size(const t_pym_compressor *comp);
size_t *pym_shrink_all(const t_pym_compressor *comp, const int64_t *values, size_t n);
size_t  pym_lower_bound(const t_pym_compressor *comp, int64_t value);
size_t  pym_upper_bound(const t_pym_compressor *comp, int64_t value);

// 2D Compression
void    quantum_shrink_point(const t_quantum_navigator *nav, int64_t x, int64_t y,
                            size_t *out_x, size_t *out_y);
void    quantum_grow_point(const t_quantum_navigator *nav, size_t cx, size_t cy,
                          int64_t *out_x, int64_t *out_y);

// Applications
int    *count_smaller_behind(const int *arr, size_t n);
size_t  longest_growth_chain(const int64_t *arr, size_t n);
size_t *unique_species_in_sectors(const int *arr, size_t n,
                                  const size_t *lefts, const size_t *rights,
                                  size_t q);
size_t  ant_census_count(const t_ant_census *census, size_t left, size_t right, int value);
int64_t *ants_in_zones(const int64_t *xs, const int64_t *ys, size_t n_points,
                       const int64_t *zones, size_t n_zones);

#endif
```

---

## ğŸ’¡ SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 Faits Fascinants

**ğŸŒŒ L'origine compÃ©titive :**
La coordinate compression est une technique FONDAMENTALE en programmation compÃ©titive. Sans elle, impossible de rÃ©soudre des problÃ¨mes avec coordonnÃ©es jusqu'Ã  10^18 en temps/mÃ©moire raisonnable.

**ğŸ“Š Usage en data science :**
Le "label encoding" en machine learning EST de la coordinate compression ! `["chat", "chien", "oiseau"]` â†’ `[0, 1, 2]`.

**ğŸ® Dans les jeux :**
Les moteurs de jeu utilisent la compression de coordonnÃ©es pour les chunks (Minecraft), les sectors (Elite Dangerous), ou les zones de spawn.

### 2.2 PropriÃ©tÃ© ClÃ©

```
            INVARIANT FONDAMENTAL

La compression prÃ©serve l'ORDRE RELATIF :

Si a < b dans l'original
â†’ compress(a) < compress(b) dans le compressÃ©

C'est TOUT ce dont la plupart des algorithmes ont besoin !
```

### 2.5 Dans la Vraie Vie

| MÃ©tier | Utilisation |
|--------|-------------|
| **ML Engineer** | Label encoding, categorical features |
| **Game Developer** | Chunk coordinates, spatial hashing |
| **Competitive Programmer** | Segment trees, Fenwick trees on large ranges |
| **Database Engineer** | Dictionary encoding, columnar compression |
| **GIS Specialist** | Tile coordinates, quadtree keys |

---

## ğŸ–¥ï¸ SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ ls
pym_particles.rs  main.rs  Cargo.toml

$ cargo build --release

$ cargo test
running 10 tests
test test_basic_compression ... ok
test test_large_values ... ok
test test_2d_compression ... ok
test test_count_smaller ... ok
test test_lis ... ok
test test_range_frequency ... ok
test test_unique_in_range ... ok
test test_bounds ... ok
test test_edge_empty ... ok
test test_edge_duplicates ... ok

test result: ok. 10 passed; 0 failed
```

---

### 3.1 ğŸ”¥ BONUS AVANCÃ‰ (OPTIONNEL)

**DifficultÃ© Bonus :**
â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜† (8/10)

**RÃ©compense :**
XP Ã—3

**Time Complexity attendue :**
O(n log n) pour toutes les opÃ©rations dynamiques

**Space Complexity attendue :**
O(n)

**Domaines Bonus :**
`DP, Struct`

#### 3.1.1 Consigne Bonus

**ğŸœ ANT-MAN â€” "Quantum Realm Dynamics"**

Janet Van Dyne a besoin de tracker les mouvements dans le Quantum Realm en TEMPS RÃ‰EL. Les coordonnÃ©es changent constamment !

**Ta mission bonus :**

1. **`DynamicPymCompressor`** â€” Supporte l'ajout de nouvelles valeurs en O(log n)

2. **`MergeSort + Compression`** â€” Compte les inversions avec compression

3. **`2D Range Queries Dynamiques`** â€” Segment Tree 2D avec compression paresseuse

**Contraintes :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1 â‰¤ n â‰¤ 10âµ                            â”‚
â”‚  -10Â¹â¸ â‰¤ valeurs â‰¤ 10Â¹â¸                 â”‚
â”‚  Temps : O(log n) par opÃ©ration         â”‚
â”‚  Support des mises Ã  jour dynamiques    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.1.2 Prototype Bonus

```rust
/// Dynamic Compressor avec insertion
pub struct DynamicPymCompressor<T: Ord + Clone + Hash> {
    tree: BTreeMap<T, usize>,  // Balanced BST
    reverse: Vec<T>,
}

impl<T: Ord + Clone + Hash> DynamicPymCompressor<T> {
    pub fn new() -> Self;
    pub fn insert(&mut self, value: T) -> usize;
    pub fn shrink(&self, value: &T) -> Option<usize>;
    pub fn grow(&self, index: usize) -> Option<&T>;
    pub fn size(&self) -> usize;
}

/// Count inversions avec compression
pub fn count_inversions(arr: &[i64]) -> i64;

/// 2D Segment Tree avec lazy compression
pub struct QuantumGrid {
    // Implementation avec compression diffÃ©rÃ©e
}

impl QuantumGrid {
    pub fn new(points: &[(i64, i64, i64)]) -> Self;  // (x, y, value)
    pub fn update(&mut self, x: i64, y: i64, delta: i64);
    pub fn query(&self, x1: i64, y1: i64, x2: i64, y2: i64) -> i64;
}
```

#### 3.1.3 Ce qui change par rapport Ã  l'exercice de base

| Aspect | Base | Bonus |
|--------|------|-------|
| Construction | O(n log n) statique | O(log n) par insertion |
| Nouvelles valeurs | Reconstruction | Insertion dynamique |
| Inversions | Non supportÃ© | O(n log n) merge sort |
| 2D queries | Statique | Dynamique avec updates |

---

## âœ…âŒ SECTION 4 : ZONE CORRECTION (POUR LE TESTEUR)

### 4.1 Moulinette

| Test | Input | Expected Output | Points |
|------|-------|-----------------|--------|
| compress_basic | `[100, 200, 50, 200, 100]` | size=3, shrink(50)=0 | 3 |
| compress_large | `[10^9, 1, 5Ã—10^8]` | `[2, 0, 1]` | 3 |
| compress_negative | `[-5, 0, 5, -10]` | size=4, order preserved | 3 |
| decompress_valid | shrink then grow | original value | 2 |
| 2d_compress | 3 points | correct (x,y) pairs | 4 |
| smaller_basic | `[5, 2, 6, 1]` | `[2, 1, 1, 0]` | 5 |
| smaller_duplicates | `[2, 2, 2]` | `[0, 0, 0]` | 3 |
| lis_basic | `[10,9,2,5,3,7,101,18]` | `4` | 5 |
| lis_all_same | `[7, 7, 7]` | `1` | 2 |
| lis_increasing | `[1, 2, 3, 4]` | `4` | 2 |
| unique_range | `[1,1,2,1,3]`, queries | `[3, 2, 3]` | 4 |
| frequency_basic | census queries | correct counts | 4 |
| bounds_lower | lower_bound tests | correct indices | 3 |
| bounds_upper | upper_bound tests | correct indices | 3 |
| edge_empty | `[]` | handle gracefully | 2 |
| edge_single | `[42]` | size=1, shrink(42)=0 | 2 |

### 4.2 main.rs de test

```rust
use pym_particles::*;

fn main() {
    println!("=== PYM PARTICLES TESTS ===\n");

    // Test 1: Basic Compression
    let coords = vec![100i64, 200, 50, 200, 100];
    let pym = PymCompressor::new(&coords);

    assert_eq!(pym.size(), 3);
    assert_eq!(pym.shrink(&50), Some(0));
    assert_eq!(pym.shrink(&100), Some(1));
    assert_eq!(pym.shrink(&200), Some(2));
    assert_eq!(pym.grow(1), Some(&100));
    println!("[OK] Basic 1D Compression");

    // Test 2: Large Values
    let large = vec![1_000_000_000i64, 1, 500_000_000];
    let pym = PymCompressor::new(&large);
    assert_eq!(pym.shrink_all(&large), vec![2, 0, 1]);
    println!("[OK] Large Values");

    // Test 3: 2D Compression
    let points = vec![(1000i64, 2000i64), (500, 3000), (1000, 1000)];
    let nav = QuantumNavigator::new(&points);

    assert_eq!(nav.shrink_point((500, 1000)), (0, 0));
    assert_eq!(nav.shrink_point((1000, 3000)), (1, 2));
    println!("[OK] 2D Compression");

    // Test 4: Count Smaller to Right
    let arr = vec![5, 2, 6, 1];
    assert_eq!(count_smaller_behind(&arr), vec![2, 1, 1, 0]);

    let arr = vec![2, 0, 1];
    assert_eq!(count_smaller_behind(&arr), vec![2, 0, 0]);
    println!("[OK] Count Smaller Behind");

    // Test 5: LIS
    let arr = vec![10i64, 9, 2, 5, 3, 7, 101, 18];
    assert_eq!(longest_growth_chain(&arr), 4);

    let arr = vec![0i64, 1, 0, 3, 2, 3];
    assert_eq!(longest_growth_chain(&arr), 4);
    println!("[OK] Longest Growth Chain (LIS)");

    // Test 6: Unique in Range
    let arr = vec![1, 1, 2, 1, 3];
    let queries = vec![(0, 4), (1, 3), (2, 4)];
    assert_eq!(unique_species_in_sectors(&arr, &queries), vec![3, 2, 3]);
    println!("[OK] Unique Species in Sectors");

    // Test 7: Range Frequency
    let arr = vec![12, 33, 4, 56, 22, 2, 34, 33, 22, 12, 34, 56];
    let census = AntCensus::new(&arr);
    assert_eq!(census.count_ant(1, 2, 4), 1);
    assert_eq!(census.count_ant(0, 11, 33), 2);
    println!("[OK] Ant Census");

    // Test 8: Bounds
    let coords = vec![10i64, 20, 30, 40, 50];
    let pym = PymCompressor::new(&coords);
    assert_eq!(pym.lower_bound(&25), 2);  // 30 is first >= 25
    assert_eq!(pym.upper_bound(&30), 3);  // 40 is first > 30
    println!("[OK] Lower/Upper Bounds");

    println!("\n=== ALL TESTS PASSED ===");
    println!("I am Ant-Man. And I just compressed your coordinates!");
}
```

### 4.3 Solution de rÃ©fÃ©rence (Rust)

```rust
pub mod pym_particles {
    use std::collections::HashMap;
    use std::hash::Hash;

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // PYM COMPRESSOR â€” 1D Coordinate Compression
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    pub struct PymCompressor<T: Ord + Clone + Hash> {
        sorted_unique: Vec<T>,
        value_to_index: HashMap<T, usize>,
    }

    impl<T: Ord + Clone + Hash> PymCompressor<T> {
        pub fn new(coordinates: &[T]) -> Self {
            let mut sorted_unique: Vec<T> = coordinates.to_vec();
            sorted_unique.sort();
            sorted_unique.dedup();

            let value_to_index: HashMap<T, usize> = sorted_unique
                .iter()
                .enumerate()
                .map(|(i, v)| (v.clone(), i))
                .collect();

            PymCompressor { sorted_unique, value_to_index }
        }

        pub fn shrink(&self, value: &T) -> Option<usize> {
            self.value_to_index.get(value).copied()
        }

        pub fn grow(&self, index: usize) -> Option<&T> {
            self.sorted_unique.get(index)
        }

        pub fn size(&self) -> usize {
            self.sorted_unique.len()
        }

        pub fn shrink_all(&self, values: &[T]) -> Vec<usize> {
            values.iter()
                .filter_map(|v| self.shrink(v))
                .collect()
        }

        pub fn lower_bound(&self, value: &T) -> usize {
            self.sorted_unique.partition_point(|x| x < value)
        }

        pub fn upper_bound(&self, value: &T) -> usize {
            self.sorted_unique.partition_point(|x| x <= value)
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // QUANTUM NAVIGATOR â€” 2D Compression
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    pub struct QuantumNavigator {
        x_pym: PymCompressor<i64>,
        y_pym: PymCompressor<i64>,
    }

    impl QuantumNavigator {
        pub fn new(points: &[(i64, i64)]) -> Self {
            let xs: Vec<i64> = points.iter().map(|p| p.0).collect();
            let ys: Vec<i64> = points.iter().map(|p| p.1).collect();

            QuantumNavigator {
                x_pym: PymCompressor::new(&xs),
                y_pym: PymCompressor::new(&ys),
            }
        }

        pub fn shrink_point(&self, point: (i64, i64)) -> (usize, usize) {
            (
                self.x_pym.shrink(&point.0).unwrap_or(0),
                self.y_pym.shrink(&point.1).unwrap_or(0),
            )
        }

        pub fn grow_point(&self, compressed: (usize, usize)) -> (i64, i64) {
            (
                *self.x_pym.grow(compressed.0).unwrap_or(&0),
                *self.y_pym.grow(compressed.1).unwrap_or(&0),
            )
        }

        pub fn grid_size(&self) -> (usize, usize) {
            (self.x_pym.size(), self.y_pym.size())
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // FENWICK TREE â€” Helper for count_smaller
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    struct Fenwick {
        tree: Vec<i32>,
    }

    impl Fenwick {
        fn new(n: usize) -> Self {
            Fenwick { tree: vec![0; n + 1] }
        }

        fn update(&mut self, mut i: usize, delta: i32) {
            i += 1;
            while i < self.tree.len() {
                self.tree[i] += delta;
                i += i & i.wrapping_neg();
            }
        }

        fn prefix_sum(&self, mut i: usize) -> i32 {
            let mut sum = 0;
            i += 1;
            while i > 0 {
                sum += self.tree[i];
                i -= i & i.wrapping_neg();
            }
            sum
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // COUNT SMALLER BEHIND
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    pub fn count_smaller_behind(arr: &[i32]) -> Vec<i32> {
        if arr.is_empty() {
            return vec![];
        }

        // Compress coordinates
        let arr_i64: Vec<i64> = arr.iter().map(|&x| x as i64).collect();
        let comp = PymCompressor::new(&arr_i64);

        let n = arr.len();
        let mut fenwick = Fenwick::new(comp.size());
        let mut result = vec![0i32; n];

        // Process from right to left
        for i in (0..n).rev() {
            let compressed = comp.shrink(&(arr[i] as i64)).unwrap();

            // Count elements smaller than current
            if compressed > 0 {
                result[i] = fenwick.prefix_sum(compressed - 1);
            }

            // Add current element
            fenwick.update(compressed, 1);
        }

        result
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // LIS WITH COMPRESSION
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    pub fn longest_growth_chain(arr: &[i64]) -> usize {
        if arr.is_empty() {
            return 0;
        }

        // Use patience sort approach (no compression needed, but binary search)
        let mut tails: Vec<i64> = vec![];

        for &x in arr {
            let pos = tails.partition_point(|&t| t < x);
            if pos == tails.len() {
                tails.push(x);
            } else {
                tails[pos] = x;
            }
        }

        tails.len()
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // UNIQUE SPECIES IN SECTORS â€” Offline Mo's Algorithm style
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    pub fn unique_species_in_sectors(
        arr: &[i32],
        queries: &[(usize, usize)],
    ) -> Vec<usize> {
        if arr.is_empty() || queries.is_empty() {
            return vec![0; queries.len()];
        }

        let n = arr.len();
        let q = queries.len();

        // Compress values
        let arr_i64: Vec<i64> = arr.iter().map(|&x| x as i64).collect();
        let comp = PymCompressor::new(&arr_i64);
        let compressed: Vec<usize> = arr.iter()
            .map(|&x| comp.shrink(&(x as i64)).unwrap())
            .collect();

        // Sort queries by right endpoint
        let mut sorted_queries: Vec<(usize, usize, usize)> = queries
            .iter()
            .enumerate()
            .map(|(i, &(l, r))| (l, r, i))
            .collect();
        sorted_queries.sort_by_key(|q| q.1);

        // Process with last occurrence tracking
        let mut last_occurrence = vec![n; comp.size()];  // Beyond array
        let mut fenwick = Fenwick::new(n);
        let mut results = vec![0usize; q];
        let mut current_right = 0;

        for (left, right, query_idx) in sorted_queries {
            // Extend to include all elements up to right
            while current_right <= right && current_right < n {
                let val = compressed[current_right];
                // Remove previous occurrence contribution
                if last_occurrence[val] < n {
                    fenwick.update(last_occurrence[val], -1);
                }
                // Add new occurrence
                fenwick.update(current_right, 1);
                last_occurrence[val] = current_right;
                current_right += 1;
            }

            // Query distinct count in [left, right]
            let total = fenwick.prefix_sum(right);
            let before = if left > 0 { fenwick.prefix_sum(left - 1) } else { 0 };
            results[query_idx] = (total - before) as usize;
        }

        results
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // ANT CENSUS â€” Range Frequency
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    pub struct AntCensus {
        positions: Vec<Vec<usize>>,
        compressor: PymCompressor<i64>,
    }

    impl AntCensus {
        pub fn new(arr: &[i32]) -> Self {
            let arr_i64: Vec<i64> = arr.iter().map(|&x| x as i64).collect();
            let compressor = PymCompressor::new(&arr_i64);

            let mut positions = vec![vec![]; compressor.size()];
            for (i, &val) in arr.iter().enumerate() {
                if let Some(compressed) = compressor.shrink(&(val as i64)) {
                    positions[compressed].push(i);
                }
            }

            AntCensus { positions, compressor }
        }

        pub fn count_ant(&self, left: usize, right: usize, value: i32) -> usize {
            if let Some(compressed) = self.compressor.shrink(&(value as i64)) {
                let pos = &self.positions[compressed];

                // Binary search for count in [left, right]
                let start = pos.partition_point(|&p| p < left);
                let end = pos.partition_point(|&p| p <= right);

                end - start
            } else {
                0
            }
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // ANTS IN ZONES â€” 2D Range Count
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    pub fn ants_in_zones(
        ant_positions: &[(i64, i64)],
        zones: &[(i64, i64, i64, i64)],
    ) -> Vec<i64> {
        if ant_positions.is_empty() || zones.is_empty() {
            return vec![0; zones.len()];
        }

        // Simple O(n*q) approach for base implementation
        zones.iter()
            .map(|&(x1, y1, x2, y2)| {
                ant_positions.iter()
                    .filter(|&&(x, y)| x >= x1 && x <= x2 && y >= y1 && y <= y2)
                    .count() as i64
            })
            .collect()
    }
}
```

### 4.5 Solutions refusÃ©es (avec explications)

```rust
// âŒ REFUSÃ‰: Pas de dÃ©duplication
impl<T: Ord + Clone + Hash> PymCompressor<T> {
    pub fn new_bad(coordinates: &[T]) -> Self {
        let mut sorted: Vec<T> = coordinates.to_vec();
        sorted.sort();
        // BUG: Pas de dedup() !
        // RÃ©sultat: indices incorrects pour les doublons
    }
}

// âŒ REFUSÃ‰: shrink sans HashMap (O(n) au lieu de O(1))
pub fn shrink_bad(&self, value: &T) -> Option<usize> {
    // BUG: Linear search au lieu de HashMap lookup
    self.sorted_unique.iter().position(|x| x == value)
}
// Pourquoi c'est faux: O(n) par lookup au lieu de O(1)

// âŒ REFUSÃ‰: count_smaller de gauche Ã  droite
pub fn count_smaller_behind_bad(arr: &[i32]) -> Vec<i32> {
    // BUG: Processe de gauche Ã  droite
    // Compte les Ã©lÃ©ments Ã  GAUCHE, pas Ã  DROITE
}

// âŒ REFUSÃ‰: LIS retourne mauvaise valeur
pub fn longest_growth_chain_bad(arr: &[i64]) -> usize {
    let mut tails: Vec<i64> = vec![];
    for &x in arr {
        let pos = tails.partition_point(|&t| t < x);
        if pos == tails.len() {
            tails.push(x);
        } else {
            tails[pos] = x;
        }
    }
    // BUG: Retourne la derniÃ¨re valeur au lieu de la longueur
    tails.last().copied().unwrap_or(0) as usize
}
```

### 4.9 spec.json (ENGINE v22.1)

```json
{
  "name": "pym_particles",
  "language": "rust",
  "version": "edition_2024",
  "type": "code",
  "tier": 3,
  "tier_info": "SynthÃ¨se (compression 1D + 2D + applications Fenwick/DP)",
  "tags": ["arrays", "coordinate_compression", "fenwick", "lis", "phase1"],
  "passing_score": 70,

  "function": {
    "name": "pym_particles",
    "module": true,
    "components": [
      {
        "name": "PymCompressor",
        "type": "struct",
        "generic": "T: Ord + Clone + Hash",
        "methods": ["new", "shrink", "grow", "size", "shrink_all", "lower_bound", "upper_bound"]
      },
      {
        "name": "QuantumNavigator",
        "type": "struct",
        "methods": ["new", "shrink_point", "grow_point", "grid_size"]
      },
      {
        "name": "AntCensus",
        "type": "struct",
        "methods": ["new", "count_ant"]
      }
    ],
    "standalone_functions": [
      "count_smaller_behind",
      "longest_growth_chain",
      "unique_species_in_sectors",
      "ants_in_zones"
    ]
  },

  "driver": {
    "reference_file": "solutions/ref_pym_particles.rs",

    "edge_cases": [
      {
        "name": "compress_basic",
        "construct": ["PymCompressor", [100, 200, 50, 200, 100]],
        "tests": [
          {"call": ["size"], "expected": 3},
          {"call": ["shrink", 50], "expected": {"Some": 0}},
          {"call": ["shrink", 100], "expected": {"Some": 1}},
          {"call": ["shrink", 200], "expected": {"Some": 2}}
        ]
      },
      {
        "name": "compress_large",
        "construct": ["PymCompressor", [1000000000, 1, 500000000]],
        "call": ["shrink_all", [1000000000, 1, 500000000]],
        "expected": [2, 0, 1]
      },
      {
        "name": "smaller_basic",
        "function": "count_smaller_behind",
        "args": [[5, 2, 6, 1]],
        "expected": [2, 1, 1, 0]
      },
      {
        "name": "smaller_duplicates",
        "function": "count_smaller_behind",
        "args": [[2, 2, 2]],
        "expected": [0, 0, 0]
      },
      {
        "name": "lis_basic",
        "function": "longest_growth_chain",
        "args": [[10, 9, 2, 5, 3, 7, 101, 18]],
        "expected": 4
      },
      {
        "name": "lis_all_same",
        "function": "longest_growth_chain",
        "args": [[7, 7, 7]],
        "expected": 1
      },
      {
        "name": "unique_range",
        "function": "unique_species_in_sectors",
        "args": [[1, 1, 2, 1, 3], [[0, 4], [1, 3], [2, 4]]],
        "expected": [3, 2, 3]
      },
      {
        "name": "census_basic",
        "construct": ["AntCensus", [12, 33, 4, 56, 22, 2, 34, 33, 22, 12, 34, 56]],
        "tests": [
          {"call": ["count_ant", 1, 2, 4], "expected": 1},
          {"call": ["count_ant", 0, 11, 33], "expected": 2}
        ]
      },
      {
        "name": "bounds_test",
        "construct": ["PymCompressor", [10, 20, 30, 40, 50]],
        "tests": [
          {"call": ["lower_bound", 25], "expected": 2},
          {"call": ["upper_bound", 30], "expected": 3}
        ]
      },
      {
        "name": "empty_array",
        "function": "count_smaller_behind",
        "args": [[]],
        "expected": [],
        "is_trap": true,
        "trap_explanation": "Tableau vide - doit retourner vecteur vide"
      }
    ],

    "fuzzing": {
      "enabled": true,
      "iterations": 500,
      "generators": [
        {
          "type": "array_int",
          "param_index": 0,
          "params": {
            "min_len": 1,
            "max_len": 1000,
            "min_val": -1000000000,
            "max_val": 1000000000
          }
        }
      ]
    }
  },

  "norm": {
    "allowed_functions": ["malloc", "free", "qsort", "bsearch", "memset"],
    "forbidden_functions": [],
    "check_memory": true,
    "blocking": true
  },

  "bonus": {
    "tier": "ADVANCED",
    "icon": "ğŸ”¥",
    "xp_multiplier": 3,
    "functions": [
      "DynamicPymCompressor",
      "count_inversions",
      "QuantumGrid"
    ]
  }
}
```

### 4.10 Solutions Mutantes

```rust
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT A (Boundary) : Off-by-one dans binary search
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

impl<T: Ord + Clone + Hash> PymCompressor<T> {
    pub fn lower_bound_bad(&self, value: &T) -> usize {
        // BUG: <= au lieu de <
        self.sorted_unique.partition_point(|x| x <= value)
    }
}
// Pourquoi c'est faux : Retourne l'index APRÃˆS la valeur, pas celui de la valeur
// Ce qui Ã©tait pensÃ© : Confusion entre lower_bound et upper_bound

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT B (Safety) : Pas de gestion du None dans shrink
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

impl<T: Ord + Clone + Hash> PymCompressor<T> {
    pub fn shrink_bad(&self, value: &T) -> usize {
        // BUG: unwrap() au lieu de Option
        *self.value_to_index.get(value).unwrap()
    }
}
// Pourquoi c'est faux : Panic si la valeur n'existe pas
// Ce qui Ã©tait pensÃ© : "Toutes les valeurs seront prÃ©sentes"

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT C (Order) : Pas de dÃ©duplication
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

impl<T: Ord + Clone + Hash> PymCompressor<T> {
    pub fn new_bad(coordinates: &[T]) -> Self {
        let mut sorted_unique: Vec<T> = coordinates.to_vec();
        sorted_unique.sort();
        // BUG: Pas de dedup()

        let value_to_index: HashMap<T, usize> = sorted_unique
            .iter()
            .enumerate()
            .map(|(i, v)| (v.clone(), i))
            .collect();
        // HashMap Ã©crase les doublons, mais sorted_unique est incorrect

        PymCompressor { sorted_unique, value_to_index }
    }
}
// Pourquoi c'est faux : sorted_unique contient des doublons, grow() retourne des valeurs incorrectes
// Ce qui Ã©tait pensÃ© : "Le HashMap gÃ¨re les doublons"

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT D (Logic) : count_smaller dans le mauvais sens
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub fn count_smaller_behind_bad(arr: &[i32]) -> Vec<i32> {
    let arr_i64: Vec<i64> = arr.iter().map(|&x| x as i64).collect();
    let comp = PymCompressor::new(&arr_i64);

    let n = arr.len();
    let mut fenwick = Fenwick::new(comp.size());
    let mut result = vec![0i32; n];

    // BUG: Process from left to right (counts smaller to LEFT)
    for i in 0..n {
        let compressed = comp.shrink(&(arr[i] as i64)).unwrap();
        if compressed > 0 {
            result[i] = fenwick.prefix_sum(compressed - 1);
        }
        fenwick.update(compressed, 1);
    }

    result
}
// Pourquoi c'est faux : Compte les Ã©lÃ©ments Ã  gauche, pas Ã  droite
// Ce qui Ã©tait pensÃ© : "L'ordre d'itÃ©ration n'importe pas"

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MUTANT E (Return) : LIS retourne le dernier Ã©lÃ©ment
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub fn longest_growth_chain_bad(arr: &[i64]) -> usize {
    if arr.is_empty() {
        return 0;
    }

    let mut tails: Vec<i64> = vec![];

    for &x in arr {
        let pos = tails.partition_point(|&t| t < x);
        if pos == tails.len() {
            tails.push(x);
        } else {
            tails[pos] = x;
        }
    }

    // BUG: Retourne la derniÃ¨re valeur au lieu de la longueur
    *tails.last().unwrap() as usize
}
// Pourquoi c'est faux : Retourne une valeur du tableau, pas la longueur LIS
// Ce qui Ã©tait pensÃ© : "tails contient la LIS donc le dernier = longueur"
```

---

## ğŸ§  SECTION 5 : COMPRENDRE (DOCUMENT DE COURS COMPLET)

### 5.1 Ce que cet exercice enseigne

| Concept | Description | Pourquoi c'est important |
|---------|-------------|-------------------------|
| **Coordinate Compression** | Mapper valeurs sparses â†’ indices denses | Fondamental en competitive programming |
| **PrÃ©servation d'ordre** | L'ordre relatif suffit pour beaucoup d'algos | Insight clÃ© pour optimisation |
| **Fenwick + Compression** | Combiner structures avancÃ©es | Pattern puissant |
| **LIS O(n log n)** | Patience sort avec binary search | Algorithme classique optimisÃ© |
| **Range Queries** | RequÃªtes sur intervalles | OmniprÃ©sent en algorithmique |

### 5.2 LDA â€” Traduction LittÃ©rale

**PymCompressor::new**
```
FONCTION new QUI RETOURNE UN PymCompressor ET PREND EN PARAMÃˆTRE coordinates QUI EST UN SLICE
DÃ‰BUT FONCTION
    DÃ‰CLARER sorted_unique COMME VECTEUR COPIE DE coordinates
    TRIER sorted_unique EN ORDRE CROISSANT
    SUPPRIMER LES DOUBLONS CONSÃ‰CUTIFS DE sorted_unique

    DÃ‰CLARER value_to_index COMME HASHMAP VIDE
    POUR CHAQUE Ã©lÃ©ment v Ã€ LA POSITION i DANS sorted_unique FAIRE
        INSÃ‰RER (v, i) DANS value_to_index
    FIN POUR

    RETOURNER PymCompressor AVEC sorted_unique ET value_to_index
FIN FONCTION
```

**shrink**
```
FONCTION shrink QUI RETOURNE UN OPTION<INDEX> ET PREND EN PARAMÃˆTRE value
DÃ‰BUT FONCTION
    RETOURNER LE RÃ‰SULTAT DE LA RECHERCHE DE value DANS value_to_index
FIN FONCTION
```

### 5.2.2 Logic Flow (Structured English)

```
ALGORITHME : Coordinate Compression
---
1. CONSTRUCTION (une seule fois) :
   a. COPIER toutes les valeurs
   b. TRIER par ordre croissant
   c. DÃ‰DUPLIQUER (supprimer les doublons consÃ©cutifs)
   d. CRÃ‰ER HashMap : valeur â†’ index

2. SHRINK (compression) :
   a. CHERCHER la valeur dans HashMap
   b. RETOURNER l'index (ou None si absent)

3. GROW (dÃ©compression) :
   a. ACCÃ‰DER Ã  sorted_unique[index]
   b. RETOURNER la valeur originale

4. COMPLEXITÃ‰ :
   - Construction : O(n log n)
   - Shrink : O(1) avec HashMap
   - Grow : O(1) accÃ¨s tableau
```

### 5.2.3 ReprÃ©sentation Algorithmique (Logique de Garde)

```
FONCTION : count_smaller_behind(arr)
---
INIT result = tableau de 0

1. COMPRESSER toutes les valeurs :
   |
   |-- CRÃ‰ER PymCompressor avec arr

2. CRÃ‰ER Fenwick Tree de taille compressed_size

3. ITÃ‰RER DE DROITE Ã€ GAUCHE (i = n-1 down to 0) :
   |
   |-- compressed = shrink(arr[i])
   |
   |-- SI compressed > 0 :
   |     result[i] = fenwick.prefix_sum(compressed - 1)
   |
   |-- fenwick.update(compressed, +1)

4. RETOURNER result
```

### 5.3 Visualisation ASCII

**Coordinate Compression:**
```
Valeurs originales (sparses) :

    [1_000_000_000]  [42]  [999_999_999]  [42]  [500_000_000]
           â†“          â†“          â†“          â†“          â†“

Ã‰tape 1 - Tri + DÃ©dup :
    sorted = [42, 500_000_000, 999_999_999, 1_000_000_000]

Ã‰tape 2 - Mapping :
    42 â†’ 0
    500_000_000 â†’ 1
    999_999_999 â†’ 2
    1_000_000_000 â†’ 3

RÃ©sultat compressÃ© :
    [3]  [0]  [2]  [0]  [1]
```

**Count Smaller Behind avec Fenwick:**
```
arr = [5, 2, 6, 1]

Ã‰tape 1: Compression
    sorted = [1, 2, 5, 6]
    mapping: 1â†’0, 2â†’1, 5â†’2, 6â†’3

Ã‰tape 2: Traitement droite â†’ gauche

    i=3, val=1, compressed=0
    fenwick = [0,0,0,0]
    smaller = 0 (pas d'Ã©lÃ©ment Ã  droite)
    fenwick[0] += 1 â†’ [1,0,0,0]
    result[3] = 0

    i=2, val=6, compressed=3
    fenwick = [1,0,0,0]
    smaller = prefix(2) = 1  (le "1" est Ã  droite et plus petit)
    fenwick[3] += 1 â†’ [1,0,0,1]
    result[2] = 1

    i=1, val=2, compressed=1
    fenwick = [1,0,0,1]
    smaller = prefix(0) = 1  (le "1" est plus petit)
    fenwick[1] += 1 â†’ [1,1,0,1]
    result[1] = 1

    i=0, val=5, compressed=2
    fenwick = [1,1,0,1]
    smaller = prefix(1) = 2  ("1" et "2" sont plus petits)
    fenwick[2] += 1 â†’ [1,1,1,1]
    result[0] = 2

RÃ©sultat: [2, 1, 1, 0] âœ“
```

### 5.4 Les piÃ¨ges en dÃ©tail

| PiÃ¨ge | Description | Solution |
|-------|-------------|----------|
| **Oublier dedup()** | Doublons crÃ©ent des indices incorrects | Toujours sort PUIS dedup |
| **Direction count_smaller** | Gauche vs droite | ItÃ©rer de droite Ã  gauche |
| **lower vs upper bound** | Confusion sur l'inclusivitÃ© | `<` = lower, `<=` = upper |
| **LIS longueur vs valeur** | Retourner len() pas last() | C'est la LONGUEUR du tableau tails |
| **Valeur non trouvÃ©e** | Panic sur unwrap() | Utiliser Option ou vÃ©rifier |

### 5.5 Cours Complet

#### 5.5.1 Pourquoi la Coordinate Compression ?

Imagine que tu dois crÃ©er un Segment Tree pour des valeurs allant de -10^18 Ã  10^18. C'est impossible en mÃ©moire !

Mais si tu as seulement 1000 valeurs uniques, tu peux les mapper sur [0, 999] et crÃ©er un arbre de taille 1000.

**Le principe clÃ© :**
La plupart des algorithmes ne se soucient que de l'**ordre relatif** des valeurs, pas de leurs valeurs absolues.

#### 5.5.2 Algorithme de Compression

```rust
fn compress(values: &[i64]) -> (Vec<usize>, Vec<i64>) {
    // 1. Copier et trier
    let mut sorted = values.to_vec();
    sorted.sort();

    // 2. DÃ©dupliquer
    sorted.dedup();

    // 3. CrÃ©er le mapping inversÃ©
    let map: HashMap<i64, usize> = sorted.iter()
        .enumerate()
        .map(|(i, &v)| (v, i))
        .collect();

    // 4. Compresser le tableau original
    let compressed = values.iter()
        .map(|v| map[v])
        .collect();

    (compressed, sorted)  // sorted sert Ã  dÃ©compresser
}
```

#### 5.5.3 Count Smaller to Right

Ce problÃ¨me classique devient O(n log n) avec compression + Fenwick :

1. **Compresser** toutes les valeurs vers [0, k-1]
2. **Initialiser** un Fenwick Tree de taille k
3. **ItÃ©rer de droite Ã  gauche** :
   - Pour chaque Ã©lÃ©ment, query le nombre d'Ã©lÃ©ments plus petits dÃ©jÃ  vus
   - Ajouter l'Ã©lÃ©ment courant au Fenwick Tree

Pourquoi de droite Ã  gauche ? Parce qu'on veut compter les Ã©lÃ©ments **Ã  droite**, qui sont donc traitÃ©s **avant** dans notre itÃ©ration inversÃ©e.

#### 5.5.4 LIS (Longest Increasing Subsequence)

L'approche "patience sort" donne O(n log n) :

```rust
fn lis(arr: &[i64]) -> usize {
    let mut tails = vec![];

    for &x in arr {
        // Trouver oÃ¹ insÃ©rer x
        let pos = tails.partition_point(|&t| t < x);

        if pos == tails.len() {
            tails.push(x);  // Nouveau plus grand
        } else {
            tails[pos] = x;  // Remplacer
        }
    }

    tails.len()  // La longueur de tails = longueur LIS
}
```

**Intuition :** `tails[i]` contient le plus petit Ã©lÃ©ment de fin possible pour une sous-sÃ©quence croissante de longueur `i+1`.

### 5.6 Normes avec explications pÃ©dagogiques

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ HORS NORME (fonctionne mais inefficace)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ // Linear search pour chaque compression                        â”‚
â”‚ sorted.iter().position(|x| x == value)  // O(n)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… CONFORME                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ // HashMap lookup O(1)                                          â”‚
â”‚ value_to_index.get(value)                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“– POURQUOI ?                                                   â”‚
â”‚ â€¢ 10^5 compressions Ã— O(n) search = O(nÂ²) â†’ timeout             â”‚
â”‚ â€¢ HashMap lookup = O(1) amorti                                   â”‚
â”‚ â€¢ Le surcoÃ»t mÃ©moire est nÃ©gligeable vs le gain en temps        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.7 Simulation avec trace d'exÃ©cution

**count_smaller_behind([5, 2, 6, 1])**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰tape â”‚ Instruction                              â”‚ Fenwick     â”‚ result                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   1   â”‚ Compression: 1â†’0, 2â†’1, 5â†’2, 6â†’3         â”‚             â”‚                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   2   â”‚ i=3, val=1, comp=0                       â”‚ [0,0,0,0]   â”‚ [?,?,?,0]                â”‚
â”‚       â”‚ query(comp-1) = query(-1) = 0            â”‚             â”‚                           â”‚
â”‚       â”‚ update(0, +1)                            â”‚ [1,0,0,0]   â”‚                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   3   â”‚ i=2, val=6, comp=3                       â”‚ [1,0,0,0]   â”‚ [?,?,1,0]                â”‚
â”‚       â”‚ query(2) = 1 (le "1" Ã  droite)           â”‚             â”‚                           â”‚
â”‚       â”‚ update(3, +1)                            â”‚ [1,0,0,1]   â”‚                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   4   â”‚ i=1, val=2, comp=1                       â”‚ [1,0,0,1]   â”‚ [?,1,1,0]                â”‚
â”‚       â”‚ query(0) = 1                             â”‚             â”‚                           â”‚
â”‚       â”‚ update(1, +1)                            â”‚ [1,1,0,1]   â”‚                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   5   â”‚ i=0, val=5, comp=2                       â”‚ [1,1,0,1]   â”‚ [2,1,1,0]                â”‚
â”‚       â”‚ query(1) = 2 ("1" et "2")                â”‚             â”‚                           â”‚
â”‚       â”‚ update(2, +1)                            â”‚ [1,1,1,1]   â”‚                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.8 MnÃ©motechniques

#### ğŸœ MEME : "What is this, a coordinate for ants?" â€” Coordinate Compression

Comme Scott Lang qui rÃ©trÃ©cit avec les Pym Particles, tes coordonnÃ©es gÃ©antes deviennent minuscules.

```rust
// Avant: CoordonnÃ©es GÃ‰ANTES
let giant = [1_000_000_000, 42, 999_999_999];

// AprÃ¨s: CoordonnÃ©es pour fourmis ğŸœ
let ant_sized = [2, 0, 1];
```

**"I shrink, therefore I fit in memory!"**

#### ğŸ¦¸ MEME : "Avengers, Assemble!" â€” Sorted + Dedup

Comme les Avengers qui se rassemblent et Ã©liminent les doublons (il n'y a qu'un seul Iron Man), la compression trie et dÃ©duplique.

```rust
// Les hÃ©ros arrivent dans le dÃ©sordre avec des doublons
let heroes = ["Thor", "Iron Man", "Thor", "Hulk"];

// AprÃ¨s assemblage
let unique_heroes = ["Hulk", "Iron Man", "Thor"];
//                      0         1         2
```

#### ğŸ’¥ MEME : "Thanos Ã©tait un problÃ¨me O(nÂ²)" â€” Optimisation

Thanos voulait rÃ©duire la population de moitiÃ© avec une solution O(n) (le snap).

La coordinate compression, c'est pareil : transformer un problÃ¨me O(nÂ²) en O(n log n).

### 5.9 Applications pratiques

| Domaine | Application |
|---------|-------------|
| **ML** | Label encoding des features catÃ©gorielles |
| **Databases** | Dictionary encoding pour compression colonnes |
| **Gaming** | Chunk coordinates, spatial indexing |
| **Competitive** | Fenwick/Segment trees sur grands ranges |
| **GIS** | Tile coordinates, Z-order curves |

---

## âš ï¸ SECTION 6 : PIÃˆGES â€” RÃ‰CAPITULATIF

| # | PiÃ¨ge | Impact | DÃ©tection |
|---|-------|--------|-----------|
| 1 | Pas de dedup() | Indices incorrects pour doublons | Test avec valeurs rÃ©pÃ©tÃ©es |
| 2 | shrink retourne usize au lieu de Option | Panic sur valeur inconnue | Test avec valeur absente |
| 3 | count_smaller gaucheâ†’droite | Compte Ã  gauche pas Ã  droite | Test [5,2,6,1] |
| 4 | LIS retourne tails.last() | Retourne valeur pas longueur | Test sÃ©quences variÃ©es |
| 5 | Confusion lower/upper bound | Off-by-one | Tests exhaustifs sur bounds |

---

## ğŸ“ SECTION 7 : QCM

### Q1. Compression de [100, 50, 100, 200]
Quelle est la taille aprÃ¨s compression ?

A) 2
B) 3
C) 4
D) 5

**RÃ©ponse : B**

Valeurs uniques triÃ©es : [50, 100, 200] â†’ 3 Ã©lÃ©ments

---

### Q2. shrink(75) sur [50, 100, 200]
Que retourne shrink(75) ?

A) 0
B) 1
C) None / erreur
D) 2

**RÃ©ponse : C**

75 n'existe pas dans les valeurs compressÃ©es

---

### Q3. count_smaller_behind direction
Pourquoi itÃ¨re-t-on de droite Ã  gauche ?

A) C'est plus rapide
B) Pour compter les Ã©lÃ©ments Ã  droite
C) Pour Ã©viter les doublons
D) Par convention

**RÃ©ponse : B**

On veut compter les Ã©lÃ©ments Ã  DROITE, donc on les traite AVANT (en itÃ©rant depuis la droite)

---

### Q4. LIS de [3, 1, 2, 1, 4]
Quelle est la longueur de la LIS ?

A) 2
B) 3
C) 4
D) 5

**RÃ©ponse : B**

LIS = [1, 2, 4] â†’ longueur 3

---

### Q5. lower_bound vs upper_bound
Pour sorted = [10, 20, 30], que retourne lower_bound(20) ?

A) 0
B) 1
C) 2
D) 3

**RÃ©ponse : B**

lower_bound(20) = premier index â‰¥ 20 = index de 20 = 1

---

## ğŸ“Š SECTION 8 : RÃ‰CAPITULATIF

| Ã‰lÃ©ment | Valeur |
|---------|--------|
| **Exercice** | 1.1.6 - pym_particles |
| **DifficultÃ©** | 6/10 (â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜†â˜†) |
| **Structures** | 3 (PymCompressor, QuantumNavigator, AntCensus) |
| **Fonctions** | 4 applications + bounds |
| **ComplexitÃ© Construction** | O(n log n) |
| **ComplexitÃ© Query** | O(1) shrink/grow, O(log n) bounds |
| **Bonus** | ğŸ”¥ AvancÃ© (Ã—3 XP) |
| **Points totaux** | 100 base + 50 bonus |

---

## ğŸ“¦ SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "1.1.6-pym_particles",
    "generated_at": "2026-01-11T10:45:00Z",

    "metadata": {
      "exercise_id": "1.1.6",
      "exercise_name": "pym_particles",
      "module": "1.1",
      "module_name": "Arrays & Sorting",
      "concept": "l",
      "concept_name": "Coordinate Compression",
      "type": "code",
      "tier": 3,
      "tier_info": "SynthÃ¨se (compression 1D + 2D + Fenwick + DP)",
      "phase": 1,
      "difficulty": 6,
      "difficulty_stars": "â˜…â˜…â˜…â˜…â˜…â˜…â˜†â˜†â˜†â˜†",
      "language": "rust",
      "language_version": "edition_2024",
      "language_alt": "c17",
      "duration_minutes": 75,
      "xp_base": 180,
      "xp_bonus_multiplier": 3,
      "bonus_tier": "ADVANCED",
      "bonus_icon": "ğŸ”¥",
      "complexity_time": "T2 O(n log n)",
      "complexity_space": "S2 O(n)",
      "prerequisites": ["binary_search", "hashmap", "prefix_sums"],
      "domains": ["Struct", "Tri", "DP"],
      "domains_bonus": ["DP", "Struct"],
      "tags": ["coordinate_compression", "fenwick", "lis", "range_query"],
      "meme_reference": "Ant-Man - What is this, a coordinate for ants?"
    },

    "files": {
      "spec.json": "/* Section 4.9 */",
      "references/ref_pym_particles.rs": "/* Section 4.3 */",
      "references/ref_pym_particles.c": "/* C implementation */",
      "references/ref_bonus.rs": "/* Section 4.6 */",
      "mutants/mutant_a_boundary.rs": "/* Section 4.10 */",
      "mutants/mutant_b_safety.rs": "/* Section 4.10 */",
      "mutants/mutant_c_order.rs": "/* Section 4.10 */",
      "mutants/mutant_d_logic.rs": "/* Section 4.10 */",
      "mutants/mutant_e_return.rs": "/* Section 4.10 */",
      "tests/main.rs": "/* Section 4.2 */"
    },

    "validation": {
      "expected_pass": [
        "references/ref_pym_particles.rs",
        "references/ref_bonus.rs"
      ],
      "expected_fail": [
        "mutants/mutant_a_boundary.rs",
        "mutants/mutant_b_safety.rs",
        "mutants/mutant_c_order.rs",
        "mutants/mutant_d_logic.rs",
        "mutants/mutant_e_return.rs"
      ]
    },

    "commands": {
      "validate_spec": "hackbrain-engine validate spec.json",
      "test_reference": "hackbrain-engine test -s spec.json -f references/ref_pym_particles.rs",
      "test_mutants": "hackbrain-mutation-tester -r references/ref_pym_particles.rs -s spec.json --validate"
    }
  }
}
```

---

*HACKBRAIN v5.5.2 â€” "What is this, a coordinate for ants?"*
*L'excellence pÃ©dagogique ne se nÃ©gocie pas*

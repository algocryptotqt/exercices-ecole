<thinking>
## Analyse du Concept
- Concept : Consistent Hashing avec noeuds virtuels
- Phase demandee : Avancee (systemes distribues)
- Adapte ? OUI - Le hachage consistant est fondamental pour le partitionnement de donnees dans les systemes distribues

## Combo Base + Bonus
- Exercice de base : Implementer un anneau de hachage consistant avec noeuds virtuels et replication
- Bonus : Jump Consistent Hash (Google) + Bounded Load balancing
- Palier bonus : AVANCE (Jump Hash) puis EXPERT (Bounded Load)
- Progression logique ? OUI - Base = ring classique, Bonus = optimisations industrielles

## Prerequis & Difficulte
- Prerequis reels : Hash functions, BTreeMap, iterators, systemes distribues basics
- Difficulte estimee : 7/10 (base), 8/10 (bonus Jump Hash), 9/10 (bonus Bounded Load)
- Coherent avec module 5.4 ? OUI

## Aspect Fun/Culture
- Contexte choisi : "The Lord of the Rings" - L'anneau qui distribue le pouvoir
- MEME mnemonique : "One Ring to hash them all" - l'anneau de hachage qui distribue equitablement
- Pourquoi c'est fun : L'anneau de Sauron distribue le mal, notre anneau distribue les donnees

## Scenarios d'Echec (6 mutants concrets)
1. Mutant A (Boundary) : Oubli du wrap-around a la fin de l'anneau
2. Mutant B (Safety) : Replicas sur le meme noeud physique (pas de deduplication)
3. Mutant C (Resource) : Pas de prise en compte du poids dans le nombre de vnodes
4. Mutant D (Logic) : Migration excessive lors d'ajout de noeud (recalcul total)
5. Mutant E (Return) : Retourne le vnode au lieu du noeud physique
6. Mutant F (Concurrency) : Race condition sur l'anneau partage

## Verdict
VALIDE - L'exercice couvre les concepts critiques de partitionnement distribue
</thinking>

---

# Exercice 5.4.1-a : elastic_ring

**Module :**
5.4.1 — Distributed Systems - Data Partitioning

**Concept :**
a — Consistent Hashing avec noeuds virtuels et replication

**Difficulte :**
7/10

**Type :**
complet

**Tiers :**
2 — Integration systeme

**Langage :**
Rust Edition 2024

**Prerequis :**
- Fonctions de hachage (SHA-256, xxHash)
- BTreeMap et operations sur arbres
- Iterators et closures Rust
- Notions de base des systemes distribues
- Statistiques (ecart-type, coefficient de variation)

**Domaines :**
DS (Distributed Systems), Hash, Algo

**Duree estimee :**
90 min

**XP Base :**
300

**Complexite :**
T[5] O(log n) lookup / O(v * log n) add-remove X S[3] O(n * v) pour l'anneau

---

## SECTION 1 : PROTOTYPE & CONSIGNE

### 1.1 Obligations

**Fichiers a rendre :**
- Rust : `src/lib.rs`, `Cargo.toml`

**Fonctions autorisees :**
- Rust : `std::collections::{BTreeMap, HashMap, HashSet}`, `sha2`, `std::hash`

**Fonctions interdites :**
- Crates externes de consistent hashing (`hashring`, `ketama`, etc.)
- `rand` pour la selection des replicas

### 1.2 Consigne

**L'ANNEAU DE SAURON DISTRIBUE — One Ring to Hash Them All**

*"Un Anneau pour les gouverner tous, Un Anneau pour les trouver, Un Anneau pour les amener tous et dans les tenebres les lier..."*

Dans la Terre du Milieu des systemes distribues, l'Anneau de Hachage Consistant est la solution ultime pour distribuer equitablement les donnees entre les serveurs. Contrairement a l'anneau de Sauron, celui-ci apporte l'equilibre plutot que le chaos !

**Le probleme du partitionnement naif :**
```
server = hash(key) % num_servers
```
Quand un serveur tombe ou qu'on en ajoute un, TOUTES les cles sont redistribuees. Catastrophe !

**La solution : L'Anneau de Hachage Consistant**

Imagine un anneau (cercle) de 0 a 2^64-1. Chaque serveur est place a plusieurs positions (noeuds virtuels). Pour trouver ou va une cle, on la hash et on avance sur l'anneau jusqu'au premier serveur rencontre.

**Ta mission :**

Implementer `ConsistentHashRing` qui :

1. **Gere les noeuds physiques** : Ajouter/retirer des serveurs
2. **Utilise des noeuds virtuels** : Chaque serveur physique a N positions sur l'anneau
3. **Supporte le poids** : Un serveur avec weight=3 a 3x plus de vnodes
4. **Replique les donnees** : Retourne le noeud primaire + K-1 replicas
5. **Minimise la redistribution** : Ajouter 1 noeud sur N ne migre que ~1/N des cles
6. **Calcule les statistiques** : Distribution des cles par noeud

**Entree :**
- Configuration : nombre de vnodes, facteur de replication
- Noeuds physiques avec id, adresse, poids
- Cles a localiser

**Sortie :**
- `add_node` : Set des cles a migrer vers ce noeud
- `remove_node` : Set des cles a redistribuer
- `lookup` : Noeud primaire + replicas + position sur l'anneau

**Contraintes :**
- L'anneau utilise SHA-256 tronque a u64 pour le hash
- Les replicas doivent etre sur des noeuds PHYSIQUES differents
- La redistribution doit etre minimale (~1/N des cles)
- Le poids multiplie le nombre de vnodes

### 1.3 Prototype

**Rust :**
```rust
use std::collections::{BTreeMap, HashMap, HashSet};

/// Configuration du ring de hachage consistant
#[derive(Debug, Clone)]
pub struct ConsistentHashConfig {
    /// Nombre de noeuds virtuels par noeud physique (par unite de poids)
    pub virtual_nodes: usize,
    /// Facteur de replication (nombre de copies incluant le primaire)
    pub replication_factor: usize,
}

impl Default for ConsistentHashConfig {
    fn default() -> Self {
        Self {
            virtual_nodes: 150,
            replication_factor: 3,
        }
    }
}

/// Identifiant d'un noeud physique
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct PhysicalNode {
    pub id: String,
    pub address: String,
    pub weight: u32,
}

/// Anneau de hachage consistant
pub struct ConsistentHashRing {
    config: ConsistentHashConfig,
    // L'anneau : position -> (node_id, vnode_index)
    ring: BTreeMap<u64, (String, usize)>,
    // Map node_id -> PhysicalNode
    nodes: HashMap<String, PhysicalNode>,
}

/// Resultat d'un lookup indiquant les noeuds responsables
#[derive(Debug, Clone)]
pub struct LookupResult {
    /// Noeud primaire responsable
    pub primary: PhysicalNode,
    /// Noeuds de replication (backup), excluant le primaire
    pub replicas: Vec<PhysicalNode>,
    /// Position sur l'anneau (hash de la cle)
    pub ring_position: u64,
}

/// Statistiques de distribution
#[derive(Debug, Clone)]
pub struct DistributionStats {
    /// Nombre de cles par noeud physique
    pub keys_per_node: HashMap<String, usize>,
    /// Ecart-type de la distribution
    pub standard_deviation: f64,
    /// Coefficient de variation (ecart-type / moyenne)
    pub coefficient_of_variation: f64,
}

impl ConsistentHashRing {
    /// Cree un nouvel anneau avec la configuration donnee
    pub fn new(config: ConsistentHashConfig) -> Self;

    /// Ajoute un noeud physique au ring
    /// Retourne les positions (hash) des cles qui devraient migrer vers ce noeud
    pub fn add_node(&mut self, node: PhysicalNode) -> HashSet<u64>;

    /// Retire un noeud du ring
    /// Retourne les positions (hash) des cles qui doivent etre redistribuees
    pub fn remove_node(&mut self, node_id: &str) -> HashSet<u64>;

    /// Trouve les noeuds responsables d'une cle
    pub fn lookup(&self, key: &str) -> Option<LookupResult>;

    /// Trouve les noeuds responsables d'un hash deja calcule
    pub fn lookup_hash(&self, hash: u64) -> Option<LookupResult>;

    /// Retourne tous les noeuds physiques
    pub fn nodes(&self) -> Vec<&PhysicalNode>;

    /// Nombre de noeuds physiques
    pub fn node_count(&self) -> usize;

    /// Nombre total de noeuds virtuels sur l'anneau
    pub fn vnode_count(&self) -> usize;

    /// Calcule les statistiques de distribution pour un ensemble de cles
    pub fn distribution_stats(&self, keys: &[String]) -> DistributionStats;

    /// Simule l'impact de l'ajout d'un noeud
    /// Retourne le pourcentage de cles qui seraient migrees
    pub fn simulate_add(&self, node: &PhysicalNode, sample_keys: &[String]) -> f64;

    /// Simule l'impact du retrait d'un noeud
    pub fn simulate_remove(&self, node_id: &str, sample_keys: &[String]) -> f64;

    /// Retourne une representation de l'anneau pour debug
    /// Vec de (position, node_id, vnode_index)
    pub fn ring_debug(&self) -> Vec<(u64, String, usize)>;
}

/// Fonction de hachage pour les cles (SHA-256 tronque a u64)
pub fn hash_key(key: &str) -> u64;

/// Fonction de hachage pour les noeuds virtuels
pub fn hash_vnode(node_id: &str, vnode_index: usize) -> u64;
```

### 1.2.2 Enonce Academique

Le **hachage consistant** (consistent hashing) est une technique de partitionnement de donnees qui minimise le nombre de remappages necessaires lors de l'ajout ou du retrait de noeuds.

**Principe :**
1. On represente l'espace de hachage comme un anneau [0, 2^64)
2. Chaque serveur est place a plusieurs positions (noeuds virtuels)
3. Une cle est assignee au premier serveur rencontre en parcourant l'anneau dans le sens horaire

**Proprietes requises :**
- **Equilibre** : Les cles sont distribuees uniformement
- **Monotonie** : L'ajout d'un noeud ne cause que des migrations vers ce noeud
- **Spread** : Une cle n'est jamais assignee a trop de serveurs
- **Load** : Chaque serveur ne recoit pas trop plus que sa part

**Noeuds virtuels :**
Pour ameliorer l'equilibre, chaque serveur physique est represente par plusieurs noeuds virtuels sur l'anneau. Le nombre de vnodes peut etre pondere selon la capacite du serveur.

---

## SECTION 2 : LE SAVIEZ-VOUS ?

### 2.1 Histoire du Consistent Hashing

Le hachage consistant a ete invente par David Karger et al. au MIT en 1997 pour resoudre le probleme du cache web distribue. L'article original "Consistent Hashing and Random Trees" est devenu une pierre angulaire des systemes distribues.

**Fun fact :** Amazon Dynamo (2007) a popularise cette technique. Sans elle, pas d'Amazon Prime, pas de Netflix, pas de Discord !

### 2.2 L'evolution des implementations

| Annee | Systeme | Innovation |
|-------|---------|------------|
| 1997 | MIT | Concept original |
| 2007 | Dynamo | Noeuds virtuels + replication |
| 2012 | Cassandra | Vnodes configurable par noeud |
| 2014 | Google | Jump Consistent Hash (O(1) memoire) |
| 2020 | Meta | Bounded Load consistent hashing |

### 2.3 DANS LA VRAIE VIE

| Metier | Utilisation | Cas concret |
|--------|-------------|-------------|
| **Backend Engineer** | Sharding DB | Repartition des utilisateurs sur les shards |
| **DevOps/SRE** | Load Balancing | HAProxy, Nginx pour sticky sessions |
| **Data Engineer** | Cache distribue | Redis Cluster, Memcached |
| **Game Developer** | Matchmaking | Repartition des joueurs sur les serveurs |
| **Cloud Architect** | Object Storage | S3, GCS pour localiser les blobs |

### 2.4 Formule magique

Pour N noeuds avec V vnodes chacun :
- **Redistribution attendue** lors d'un ajout : `~K/N` (K = nombre de cles)
- **Variance de la distribution** : diminue en `O(1/V)`
- **Memoire utilisee** : `O(N * V)` pour l'anneau

---

## SECTION 3 : EXEMPLE D'UTILISATION

### 3.0 Session bash

```bash
$ ls
Cargo.toml  src/

$ cat Cargo.toml
[package]
name = "elastic_ring"
version = "0.1.0"
edition = "2024"

[dependencies]
sha2 = "0.10"

$ cargo test
   Compiling elastic_ring v0.1.0
    Finished test [unoptimized + debuginfo]
     Running unittests src/lib.rs

running 15 tests
test tests::test_basic_lookup ... ok
test tests::test_consistent_lookup ... ok
test tests::test_minimal_redistribution ... ok
test tests::test_replication_different_nodes ... ok
test tests::test_weight_distribution ... ok
test tests::test_empty_ring ... ok
test tests::test_single_node ... ok
test tests::test_add_remove_node ... ok
test tests::test_vnode_count ... ok
test tests::test_distribution_stats ... ok
test tests::test_simulate_add ... ok
test tests::test_wrap_around ... ok
test tests::test_hash_determinism ... ok
test tests::test_replicas_skip_same_physical ... ok
test tests::test_ring_debug ... ok

test result: ok. 15 passed; 0 failed

$ cargo run --example demo
=== Consistent Hash Ring Demo ===

Adding nodes...
  Added node1 (weight=1): 150 vnodes
  Added node2 (weight=1): 150 vnodes
  Added node3 (weight=2): 300 vnodes (double weight!)

Ring stats:
  Physical nodes: 3
  Virtual nodes: 600

Looking up keys...
  "user:1234" -> primary: node3, replicas: [node1, node2]
  "user:5678" -> primary: node1, replicas: [node2, node3]
  "session:abc" -> primary: node2, replicas: [node3, node1]

Distribution test (10000 keys):
  node1: 2456 keys (24.56%)
  node2: 2512 keys (25.12%)
  node3: 5032 keys (50.32%)  <- Double weight = double keys!
  Standard deviation: 1.23%
  Coefficient of variation: 0.049

Adding node4...
  Migration percentage: 9.8% (expected ~10% = 1/10 nodes equivalent)

Removing node2...
  Keys to redistribute: 2512
  New distribution maintained balance
```

### 3.1 BONUS AVANCE : Jump Consistent Hash (OPTIONNEL)

**Difficulte Bonus :**
8/10

**Recompense :**
XP x3

**Time Complexity attendue :**
O(log n)

**Space Complexity attendue :**
O(1) — PAS D'ANNEAU EN MEMOIRE !

**Domaines Bonus :**
`Algo, Math`

#### 3.1.1 Consigne Bonus

**L'ANNEAU INVISIBLE — Jump Hash de Google**

*"Le meilleur anneau est celui qui n'existe pas..."*

Google a invente Jump Consistent Hash en 2014 : meme proprietes que le consistent hash classique, mais en O(1) memoire ! Pas besoin de stocker l'anneau.

**Ta mission :**

Implementer `jump_consistent_hash(key: u64, num_buckets: i32) -> i32` qui :
- Retourne un bucket dans [0, num_buckets)
- Est consistant (meme cle = meme bucket tant que num_buckets ne diminue pas)
- Ne redistribue que ~1/n des cles quand on passe de n a n+1 buckets
- N'utilise AUCUNE structure de donnees

**L'algorithme magique (14 lignes de code !) :**
```
b = -1, j = 0
while j < num_buckets:
    b = j
    key = key * 2862933555777941757 + 1
    j = (b + 1) * (2^31 / ((key >> 33) + 1))
return b
```

**Contraintes :**
- O(1) memoire (pas d'allocation)
- O(log n) temps
- Deterministe

#### 3.1.2 Prototype Bonus

```rust
/// Jump Consistent Hash - O(log n) time, O(1) space
/// Google's algorithm from 2014 paper
pub fn jump_consistent_hash(key: u64, num_buckets: i32) -> i32;

/// Wrapper pour utiliser avec des cles string
pub fn jump_hash_key(key: &str, num_buckets: i32) -> i32;
```

### 3.2 BONUS EXPERT : Bounded Load (OPTIONNEL)

**Difficulte Bonus :**
9/10

**Recompense :**
XP x4

**Ta mission :**

Implementer le Bounded Load Consistent Hashing (Mirrokni et al., 2018) :
- Chaque noeud a une capacite maximale
- Si le noeud primaire est "plein", on passe au suivant
- Garantit que la charge max d'un noeud est (1 + epsilon) * moyenne

```rust
impl ConsistentHashRing {
    /// Lookup avec bounded load
    /// Retourne le premier noeud non surcharge
    pub fn lookup_bounded(
        &self,
        key: &str,
        loads: &HashMap<String, usize>,
        capacity: usize,
    ) -> Option<LookupResult>;
}
```

---

## SECTION 4 : ZONE CORRECTION (POUR LE TESTEUR)

### 4.1 Moulinette

| Test | Input | Expected | Points | Trap |
|------|-------|----------|--------|------|
| `test_new` | `ConsistentHashRing::new(default)` | `node_count() == 0` | 2 | |
| `test_add_single` | `add_node(node1)` | `node_count() == 1` | 3 | |
| `test_vnode_count` | `add_node(weight=1, vnodes=100)` | `vnode_count() == 100` | 3 | |
| `test_vnode_weight` | `add_node(weight=3, vnodes=100)` | `vnode_count() == 300` | 5 | |
| `test_lookup_single` | `lookup("key")` avec 1 noeud | `primary == node1` | 5 | |
| `test_lookup_empty` | `lookup("key")` sans noeud | `None` | 5 | |
| `test_consistent` | 2x `lookup("same_key")` | `primary identique` | 8 | |
| `test_wrap_around` | Key hash pres de u64::MAX | Trouve le premier noeud | 8 | |
| `test_replicas_unique` | `lookup` avec RF=3, 5 noeuds | 3 noeuds physiques differents | 10 | |
| `test_replicas_skip_vnode` | Vnodes consecutifs du meme noeud | Skip au prochain physique | 10 | |
| `test_min_redistribution` | `add_node` sur 10 noeuds | Migration < 15% | 12 | |
| `test_weight_ratio` | nodes weight 1 et 3 | ratio ~3:1 | 10 | |
| `test_distribution_cv` | 10000 cles, 5 noeuds | CV < 0.10 | 8 | |
| `test_remove_node` | `remove_node` | Cles redistribuees | 8 | |
| `test_hash_determinism` | `hash_key` 2x meme input | Output identique | 3 | |
| **TOTAL** | | | **100** | |

### 4.2 Tests de reference

```rust
#[cfg(test)]
mod tests {
    use super::*;

    fn make_node(id: &str, weight: u32) -> PhysicalNode {
        PhysicalNode {
            id: id.to_string(),
            address: format!("10.0.0.{}:8080", id.chars().last().unwrap()),
            weight,
        }
    }

    #[test]
    fn test_basic_lookup() {
        let mut ring = ConsistentHashRing::new(ConsistentHashConfig::default());
        ring.add_node(make_node("node1", 1));
        ring.add_node(make_node("node2", 1));

        let result = ring.lookup("my_key").unwrap();
        assert!(!result.primary.id.is_empty());
    }

    #[test]
    fn test_consistent_lookup() {
        let config = ConsistentHashConfig {
            virtual_nodes: 100,
            replication_factor: 3,
        };
        let mut ring = ConsistentHashRing::new(config);

        for i in 0..5 {
            ring.add_node(make_node(&format!("node{}", i), 1));
        }

        // La meme cle doit toujours aller au meme noeud
        let key = "consistent_key";
        let result1 = ring.lookup(key).unwrap();
        let result2 = ring.lookup(key).unwrap();
        assert_eq!(result1.primary.id, result2.primary.id);
        assert_eq!(result1.ring_position, result2.ring_position);
    }

    #[test]
    fn test_minimal_redistribution() {
        let config = ConsistentHashConfig {
            virtual_nodes: 150,
            replication_factor: 1,
        };
        let mut ring = ConsistentHashRing::new(config);

        for i in 0..10 {
            ring.add_node(make_node(&format!("node{}", i), 1));
        }

        // Generer 10000 cles de test
        let keys: Vec<String> = (0..10000).map(|i| format!("key_{}", i)).collect();

        // Simuler l'ajout d'un noeud
        let new_node = make_node("node_new", 1);
        let migration_percent = ring.simulate_add(&new_node, &keys);

        // Avec 11 noeuds, on s'attend a ~9% de migration (1/11)
        assert!(
            migration_percent < 0.15,
            "Trop de redistribution: {}%",
            migration_percent * 100.0
        );
        assert!(
            migration_percent > 0.05,
            "Trop peu de redistribution: {}%",
            migration_percent * 100.0
        );
    }

    #[test]
    fn test_replication_different_nodes() {
        let config = ConsistentHashConfig {
            virtual_nodes: 100,
            replication_factor: 3,
        };
        let mut ring = ConsistentHashRing::new(config);

        for i in 0..5 {
            ring.add_node(make_node(&format!("node{}", i), 1));
        }

        let result = ring.lookup("test_key").unwrap();
        let all_nodes: HashSet<_> = std::iter::once(&result.primary)
            .chain(result.replicas.iter())
            .map(|n| &n.id)
            .collect();

        // Tous les noeuds de replication doivent etre differents
        assert_eq!(all_nodes.len(), 3);
    }

    #[test]
    fn test_weight_distribution() {
        let config = ConsistentHashConfig {
            virtual_nodes: 100,
            replication_factor: 1,
        };
        let mut ring = ConsistentHashRing::new(config);

        ring.add_node(make_node("light", 1));
        ring.add_node(make_node("heavy", 3)); // 3x plus de poids

        let keys: Vec<String> = (0..10000).map(|i| format!("key_{}", i)).collect();
        let stats = ring.distribution_stats(&keys);

        let light_count = *stats.keys_per_node.get("light").unwrap_or(&0);
        let heavy_count = *stats.keys_per_node.get("heavy").unwrap_or(&0);

        // Le noeud lourd devrait avoir ~3x plus de cles
        let ratio = heavy_count as f64 / light_count as f64;
        assert!(
            ratio > 2.0 && ratio < 4.0,
            "Ratio inattendu: {}",
            ratio
        );
    }

    #[test]
    fn test_wrap_around() {
        let config = ConsistentHashConfig {
            virtual_nodes: 10,
            replication_factor: 1,
        };
        let mut ring = ConsistentHashRing::new(config);
        ring.add_node(make_node("node1", 1));

        // Meme si le hash est tres eleve, on doit wrap-around
        // et trouver le premier noeud de l'anneau
        let result = ring.lookup_hash(u64::MAX - 1);
        assert!(result.is_some());
    }

    #[test]
    fn test_empty_ring() {
        let ring = ConsistentHashRing::new(ConsistentHashConfig::default());
        assert!(ring.lookup("any_key").is_none());
        assert_eq!(ring.node_count(), 0);
        assert_eq!(ring.vnode_count(), 0);
    }
}
```

### 4.3 Solution de reference

```rust
use sha2::{Sha256, Digest};
use std::collections::{BTreeMap, HashMap, HashSet};

#[derive(Debug, Clone)]
pub struct ConsistentHashConfig {
    pub virtual_nodes: usize,
    pub replication_factor: usize,
}

impl Default for ConsistentHashConfig {
    fn default() -> Self {
        Self {
            virtual_nodes: 150,
            replication_factor: 3,
        }
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct PhysicalNode {
    pub id: String,
    pub address: String,
    pub weight: u32,
}

pub struct ConsistentHashRing {
    config: ConsistentHashConfig,
    ring: BTreeMap<u64, (String, usize)>,
    nodes: HashMap<String, PhysicalNode>,
}

#[derive(Debug, Clone)]
pub struct LookupResult {
    pub primary: PhysicalNode,
    pub replicas: Vec<PhysicalNode>,
    pub ring_position: u64,
}

#[derive(Debug, Clone)]
pub struct DistributionStats {
    pub keys_per_node: HashMap<String, usize>,
    pub standard_deviation: f64,
    pub coefficient_of_variation: f64,
}

pub fn hash_key(key: &str) -> u64 {
    let mut hasher = Sha256::new();
    hasher.update(key.as_bytes());
    let result = hasher.finalize();
    u64::from_be_bytes(result[0..8].try_into().unwrap())
}

pub fn hash_vnode(node_id: &str, vnode_index: usize) -> u64 {
    let combined = format!("{}#{}", node_id, vnode_index);
    hash_key(&combined)
}

impl ConsistentHashRing {
    pub fn new(config: ConsistentHashConfig) -> Self {
        Self {
            config,
            ring: BTreeMap::new(),
            nodes: HashMap::new(),
        }
    }

    pub fn add_node(&mut self, node: PhysicalNode) -> HashSet<u64> {
        let mut migrated = HashSet::new();
        let total_vnodes = self.config.virtual_nodes * node.weight as usize;

        // Ajouter les vnodes sur l'anneau
        for i in 0..total_vnodes {
            let pos = hash_vnode(&node.id, i);

            // Trouver quelles cles migreront vers ce nouveau vnode
            // Ce sont les cles entre le predecesseur et cette position
            if let Some((&pred_pos, _)) = self.ring.range(..pos).next_back() {
                // Les cles dans ]pred_pos, pos] migreront
                migrated.insert(pos);
            } else if !self.ring.is_empty() {
                // Wrap-around: cles apres le dernier noeud
                migrated.insert(pos);
            }

            self.ring.insert(pos, (node.id.clone(), i));
        }

        self.nodes.insert(node.id.clone(), node);
        migrated
    }

    pub fn remove_node(&mut self, node_id: &str) -> HashSet<u64> {
        let mut redistributed = HashSet::new();

        if let Some(node) = self.nodes.remove(node_id) {
            let total_vnodes = self.config.virtual_nodes * node.weight as usize;

            for i in 0..total_vnodes {
                let pos = hash_vnode(node_id, i);
                if self.ring.remove(&pos).is_some() {
                    redistributed.insert(pos);
                }
            }
        }

        redistributed
    }

    pub fn lookup(&self, key: &str) -> Option<LookupResult> {
        self.lookup_hash(hash_key(key))
    }

    pub fn lookup_hash(&self, hash: u64) -> Option<LookupResult> {
        if self.ring.is_empty() {
            return None;
        }

        // Trouver le premier noeud >= hash (ou wrap-around)
        let mut iter = self.ring.range(hash..).chain(self.ring.iter());

        let mut seen_physical: HashSet<String> = HashSet::new();
        let mut primary: Option<PhysicalNode> = None;
        let mut replicas: Vec<PhysicalNode> = Vec::new();

        for (_pos, (node_id, _vnode_idx)) in iter {
            if seen_physical.contains(node_id) {
                continue;
            }

            let node = self.nodes.get(node_id)?.clone();
            seen_physical.insert(node_id.clone());

            if primary.is_none() {
                primary = Some(node);
            } else {
                replicas.push(node);
            }

            // On a assez de noeuds pour la replication
            if seen_physical.len() >= self.config.replication_factor {
                break;
            }

            // On a parcouru tous les noeuds physiques disponibles
            if seen_physical.len() >= self.nodes.len() {
                break;
            }
        }

        primary.map(|p| LookupResult {
            primary: p,
            replicas,
            ring_position: hash,
        })
    }

    pub fn nodes(&self) -> Vec<&PhysicalNode> {
        self.nodes.values().collect()
    }

    pub fn node_count(&self) -> usize {
        self.nodes.len()
    }

    pub fn vnode_count(&self) -> usize {
        self.ring.len()
    }

    pub fn distribution_stats(&self, keys: &[String]) -> DistributionStats {
        let mut keys_per_node: HashMap<String, usize> = HashMap::new();

        for key in keys {
            if let Some(result) = self.lookup(key) {
                *keys_per_node.entry(result.primary.id).or_insert(0) += 1;
            }
        }

        // Calculer moyenne et ecart-type
        let values: Vec<f64> = keys_per_node.values().map(|&v| v as f64).collect();
        let n = values.len() as f64;

        if n == 0.0 {
            return DistributionStats {
                keys_per_node,
                standard_deviation: 0.0,
                coefficient_of_variation: 0.0,
            };
        }

        let mean = values.iter().sum::<f64>() / n;
        let variance = values.iter().map(|v| (v - mean).powi(2)).sum::<f64>() / n;
        let std_dev = variance.sqrt();
        let cv = if mean > 0.0 { std_dev / mean } else { 0.0 };

        DistributionStats {
            keys_per_node,
            standard_deviation: std_dev,
            coefficient_of_variation: cv,
        }
    }

    pub fn simulate_add(&self, node: &PhysicalNode, sample_keys: &[String]) -> f64 {
        // Creer une copie temporaire du ring
        let mut temp_ring = ConsistentHashRing::new(self.config.clone());
        for n in self.nodes.values() {
            temp_ring.add_node(n.clone());
        }

        // Calculer les assignations avant
        let before: HashMap<String, String> = sample_keys
            .iter()
            .filter_map(|k| {
                temp_ring.lookup(k).map(|r| (k.clone(), r.primary.id))
            })
            .collect();

        // Ajouter le nouveau noeud
        temp_ring.add_node(node.clone());

        // Calculer les assignations apres
        let mut migrated = 0;
        for key in sample_keys {
            if let Some(result) = temp_ring.lookup(key) {
                if let Some(old_node) = before.get(key) {
                    if *old_node != result.primary.id {
                        migrated += 1;
                    }
                }
            }
        }

        migrated as f64 / sample_keys.len() as f64
    }

    pub fn simulate_remove(&self, node_id: &str, sample_keys: &[String]) -> f64 {
        let mut temp_ring = ConsistentHashRing::new(self.config.clone());
        for n in self.nodes.values() {
            temp_ring.add_node(n.clone());
        }

        let before: HashMap<String, String> = sample_keys
            .iter()
            .filter_map(|k| {
                temp_ring.lookup(k).map(|r| (k.clone(), r.primary.id))
            })
            .collect();

        temp_ring.remove_node(node_id);

        let mut migrated = 0;
        for key in sample_keys {
            if let Some(result) = temp_ring.lookup(key) {
                if let Some(old_node) = before.get(key) {
                    if *old_node != result.primary.id {
                        migrated += 1;
                    }
                }
            }
        }

        migrated as f64 / sample_keys.len() as f64
    }

    pub fn ring_debug(&self) -> Vec<(u64, String, usize)> {
        self.ring
            .iter()
            .map(|(&pos, (node_id, vnode_idx))| (pos, node_id.clone(), *vnode_idx))
            .collect()
    }
}
```

### 4.4 Solutions alternatives acceptees

```rust
// Alternative 1: Utilisation de xxHash au lieu de SHA-256
// Valide car plus rapide et suffisamment uniforme

// Alternative 2: Stockage des positions dans un Vec trie au lieu de BTreeMap
// Valide si binary_search est utilise correctement

// Alternative 3: Utilisation de FNV-1a pour les vnodes
// Valide car deterministe et bon spread
```

### 4.5 Solutions refusees (avec explications)

```rust
// REFUSE: Utilisation de rand pour placer les vnodes
use rand::Rng;
fn hash_vnode(node_id: &str, idx: usize) -> u64 {
    rand::thread_rng().gen()  // NON-DETERMINISTE !
}
// Raison: Le hachage doit etre deterministe

// REFUSE: Replicas qui incluent des vnodes du meme noeud physique
fn get_replicas(&self, start: u64) -> Vec<String> {
    self.ring.range(start..).take(3).map(|v| v.1.clone()).collect()
    // Peut retourner 3 vnodes du MEME noeud physique !
}
// Raison: Les replicas doivent etre sur des noeuds physiques differents

// REFUSE: Recalcul total lors d'add_node
fn add_node(&mut self, node: PhysicalNode) {
    self.ring.clear();  // TOUT EFFACER
    for n in &self.nodes {
        // Reconstruire tout...
    }
}
// Raison: Viole le principe de redistribution minimale
```

### 4.6 Solution bonus de reference (Jump Consistent Hash)

```rust
/// Jump Consistent Hash - Google's algorithm (2014)
/// O(log n) time, O(1) space
pub fn jump_consistent_hash(mut key: u64, num_buckets: i32) -> i32 {
    let mut b: i64 = -1;
    let mut j: i64 = 0;

    while j < num_buckets as i64 {
        b = j;
        key = key.wrapping_mul(2862933555777941757).wrapping_add(1);
        j = ((b + 1) as f64 * (((1i64 << 31) as f64) / (((key >> 33) + 1) as f64))) as i64;
    }

    b as i32
}

pub fn jump_hash_key(key: &str, num_buckets: i32) -> i32 {
    jump_consistent_hash(hash_key(key), num_buckets)
}

#[test]
fn test_jump_hash_consistency() {
    // Quand on passe de n a n+1 buckets, seule 1/(n+1) des cles migrent
    let keys: Vec<u64> = (0..10000).map(|i| hash_key(&format!("key{}", i))).collect();

    let before: Vec<i32> = keys.iter().map(|&k| jump_consistent_hash(k, 10)).collect();
    let after: Vec<i32> = keys.iter().map(|&k| jump_consistent_hash(k, 11)).collect();

    let migrated = before.iter().zip(after.iter()).filter(|(a, b)| a != b).count();
    let ratio = migrated as f64 / keys.len() as f64;

    // Devrait etre ~1/11 = 9%
    assert!(ratio > 0.07 && ratio < 0.12, "Migration ratio: {}", ratio);
}
```

### 4.9 spec.json

```json
{
  "name": "elastic_ring",
  "language": "rust",
  "type": "code",
  "tier": 2,
  "tier_info": "Integration systeme distribue",
  "tags": ["consistent-hashing", "distributed-systems", "partitioning", "replication"],
  "passing_score": 70,

  "function": {
    "name": "ConsistentHashRing",
    "prototype": "pub struct ConsistentHashRing",
    "return_type": "struct",
    "parameters": []
  },

  "driver": {
    "reference": "/* Section 4.3 */",

    "edge_cases": [
      {
        "name": "empty_ring_lookup",
        "args": ["\"any_key\""],
        "expected": "None",
        "is_trap": true,
        "trap_explanation": "Lookup sur ring vide doit retourner None"
      },
      {
        "name": "single_node_replication",
        "args": ["\"key\""],
        "expected": "1 replica (le meme noeud)",
        "is_trap": true,
        "trap_explanation": "Avec 1 seul noeud, impossible d'avoir des replicas differents"
      },
      {
        "name": "wrap_around",
        "args": ["hash_near_max"],
        "expected": "Premier noeud de l'anneau",
        "is_trap": true,
        "trap_explanation": "Hash eleve doit wrap au debut de l'anneau"
      },
      {
        "name": "consecutive_vnodes_same_physical",
        "args": ["\"key\""],
        "expected": "Skip au prochain noeud physique",
        "is_trap": true,
        "trap_explanation": "Ne pas compter plusieurs vnodes du meme noeud physique"
      },
      {
        "name": "weight_zero",
        "args": ["node with weight=0"],
        "expected": "0 vnodes ajoutes",
        "is_trap": true,
        "trap_explanation": "Poids 0 = pas de presence sur l'anneau"
      }
    ],

    "fuzzing": {
      "enabled": true,
      "iterations": 5000,
      "generators": [
        {
          "type": "string",
          "param_index": 0,
          "params": {
            "min_length": 1,
            "max_length": 100
          }
        }
      ]
    }
  },

  "norm": {
    "allowed_functions": ["BTreeMap", "HashMap", "HashSet", "sha2"],
    "forbidden_functions": ["hashring", "ketama", "rand"],
    "check_security": true,
    "check_memory": true,
    "blocking": true
  }
}
```

### 4.10 Solutions Mutantes (minimum 6)

```rust
/* Mutant A (Boundary) : Oubli du wrap-around */
fn lookup_hash_mutant_a(&self, hash: u64) -> Option<LookupResult> {
    // BUG: Ne cherche que apres le hash, pas de wrap-around
    let (pos, (node_id, _)) = self.ring.range(hash..).next()?;
    // Si hash > tous les vnodes, retourne None au lieu de wrapper
    Some(LookupResult {
        primary: self.nodes.get(node_id)?.clone(),
        replicas: vec![],
        ring_position: *pos,
    })
}
// Pourquoi c'est faux : Les cles avec hash eleve ne trouvent jamais de noeud
// Ce qui etait pense : "range(hash..) suffit" — NON, il faut chainer avec le debut !

/* Mutant B (Safety) : Replicas sur le meme noeud physique */
fn lookup_hash_mutant_b(&self, hash: u64) -> Option<LookupResult> {
    let mut iter = self.ring.range(hash..).chain(self.ring.iter());
    let mut results: Vec<PhysicalNode> = Vec::new();

    // BUG: Prend les N premiers vnodes sans verifier les noeuds physiques
    for (_pos, (node_id, _)) in iter.take(self.config.replication_factor) {
        results.push(self.nodes.get(node_id)?.clone());
    }

    Some(LookupResult {
        primary: results.remove(0),
        replicas: results,
        ring_position: hash,
    })
}
// Pourquoi c'est faux : Peut avoir 3 replicas sur le meme serveur physique
// Ce qui etait pense : "3 vnodes = 3 replicas" — NON, il faut des noeuds PHYSIQUES differents !

/* Mutant C (Resource) : Poids ignore */
fn add_node_mutant_c(&mut self, node: PhysicalNode) -> HashSet<u64> {
    // BUG: Ignore le poids, utilise toujours virtual_nodes fixe
    for i in 0..self.config.virtual_nodes {  // Devrait etre * node.weight
        let pos = hash_vnode(&node.id, i);
        self.ring.insert(pos, (node.id.clone(), i));
    }
    self.nodes.insert(node.id.clone(), node);
    HashSet::new()
}
// Pourquoi c'est faux : Un noeud avec weight=3 a le meme impact qu'un weight=1
// Ce qui etait pense : "Le poids c'est juste informatif" — NON, il multiplie les vnodes !

/* Mutant D (Logic) : Migration excessive */
fn add_node_mutant_d(&mut self, node: PhysicalNode) -> HashSet<u64> {
    // BUG: Recalcule toutes les positions au lieu d'ajouter incrementalement
    self.ring.clear();  // CATASTROPHE !

    self.nodes.insert(node.id.clone(), node);

    // Reconstruire tout l'anneau
    for n in self.nodes.values() {
        for i in 0..(self.config.virtual_nodes * n.weight as usize) {
            let pos = hash_vnode(&n.id, i);
            self.ring.insert(pos, (n.id.clone(), i));
        }
    }

    // Retourne un set vide car on ne sait pas ce qui a migre
    HashSet::new()
}
// Pourquoi c'est faux : ~100% des cles sont "migrees" au lieu de ~1/N
// Ce qui etait pense : "Plus simple de tout reconstruire" — NON, ca viole le principe fondamental !

/* Mutant E (Return) : Retourne vnode au lieu de noeud physique */
fn lookup_hash_mutant_e(&self, hash: u64) -> Option<LookupResult> {
    let mut iter = self.ring.range(hash..).chain(self.ring.iter());
    let (pos, (node_id, vnode_idx)) = iter.next()?;

    // BUG: Cree un "faux" noeud avec l'index du vnode
    Some(LookupResult {
        primary: PhysicalNode {
            id: format!("{}#{}", node_id, vnode_idx),  // FAUX ID !
            address: "".to_string(),
            weight: 1,
        },
        replicas: vec![],
        ring_position: *pos,
    })
}
// Pourquoi c'est faux : Le client recoit un ID de vnode, pas le noeud physique reel
// Ce qui etait pense : "L'index du vnode est utile" — NON, le client veut le noeud physique !

/* Mutant F (Concurrency) : Pas de deduplication dans la boucle replica */
fn lookup_hash_mutant_f(&self, hash: u64) -> Option<LookupResult> {
    let mut iter = self.ring.range(hash..).chain(self.ring.iter());
    let mut seen = HashSet::new();
    let mut primary = None;
    let mut replicas = Vec::new();

    for (_pos, (node_id, _)) in iter {
        // BUG: Verifie seen mais n'ajoute pas avant le check
        if primary.is_none() {
            primary = Some(self.nodes.get(node_id)?.clone());
            // Oubli: seen.insert(node_id.clone());
        } else if !seen.contains(node_id) {
            replicas.push(self.nodes.get(node_id)?.clone());
            // seen.insert manquant ici aussi
        }

        if replicas.len() + 1 >= self.config.replication_factor {
            break;
        }
    }

    primary.map(|p| LookupResult {
        primary: p,
        replicas,
        ring_position: hash,
    })
}
// Pourquoi c'est faux : Le set 'seen' reste vide, peut avoir des doublons
// Ce qui etait pense : "Le check suffit" — NON, il faut AUSSI ajouter au set !
```

---

## SECTION 5 : COMPRENDRE (DOCUMENT DE COURS COMPLET)

### 5.1 Ce que cet exercice enseigne

1. **Partitionnement distribue** : Comment repartir des donnees sur plusieurs serveurs
2. **Hachage consistant** : Minimiser la redistribution lors de changements de topologie
3. **Noeuds virtuels** : Ameliorer l'equilibre avec des positions multiples
4. **Replication** : Garantir la disponibilite avec des copies sur differents noeuds
5. **Trade-offs systeme** : Equilibre entre memoire (vnodes) et distribution

### 5.2 LDA — Traduction Litterale en Francais (MAJUSCULES)

```
STRUCTURE ConsistentHashRing QUI CONTIENT :
    - config QUI EST LA CONFIGURATION (vnodes, replication_factor)
    - ring QUI EST UN ARBRE ORDONNE DE (position -> (node_id, vnode_index))
    - nodes QUI EST UNE TABLE DE (node_id -> PhysicalNode)
FIN STRUCTURE

FONCTION lookup QUI PREND key ET RETOURNE UN RESULTAT OPTIONNEL
DEBUT FONCTION
    SI ring EST VIDE ALORS
        RETOURNER RIEN
    FIN SI

    CALCULER hash = hash_key(key)

    CREER iterateur = CONCATENER (ring depuis hash) ET (ring depuis debut)

    CREER ensemble seen_physical VIDE
    CREER primary = RIEN
    CREER replicas = LISTE VIDE

    POUR CHAQUE (position, node_id, vnode_index) DANS iterateur
        SI node_id EST DEJA DANS seen_physical ALORS
            CONTINUER AU SUIVANT
        FIN SI

        AJOUTER node_id A seen_physical
        RECUPERER physical_node DEPUIS nodes[node_id]

        SI primary EST RIEN ALORS
            AFFECTER physical_node A primary
        SINON
            AJOUTER physical_node A replicas
        FIN SI

        SI TAILLE(seen_physical) >= replication_factor ALORS
            SORTIR DE LA BOUCLE
        FIN SI
    FIN POUR

    RETOURNER LookupResult(primary, replicas, hash)
FIN FONCTION

FONCTION add_node QUI PREND node ET RETOURNE LES POSITIONS MIGREES
DEBUT FONCTION
    CALCULER total_vnodes = virtual_nodes * node.weight

    POUR i DE 0 A total_vnodes - 1
        CALCULER position = hash_vnode(node.id, i)
        INSERER (position, node.id, i) DANS ring
    FIN POUR

    INSERER node DANS nodes

    RETOURNER ensemble des positions affectees
FIN FONCTION
```

### 5.2.2 Logic Flow (Structured English)

```
ALGORITHM: Consistent Hash Lookup
---
1. IF ring is empty:
   a. RETURN None

2. COMPUTE hash of key:
   a. hash = SHA256(key)[0..8] as u64

3. FIND nodes on ring:

   a. CREATE iterator starting at hash position
   b. CHAIN with iterator from ring start (wrap-around)

   c. FOR each (position, node_id) in iterator:
      |
      |-- IF node_id already seen:
      |     SKIP to next
      |
      |-- ADD node_id to seen set
      |
      |-- IF no primary yet:
      |     SET as primary
      |-- ELSE:
      |     ADD to replicas list
      |
      |-- IF enough replicas:
      |     BREAK

4. RETURN LookupResult(primary, replicas, hash)
```

### 5.2.3 Logique de Garde (Fail Fast)

```
FONCTION : lookup (key)
---
INIT result = None

1. VERIFIER si ring est vide :
   |
   |-- RETOURNER None immediatement

2. CALCULER hash de la cle :
   |
   |-- hash = hash_key(key)

3. CREER iterateur avec wrap-around :
   |
   |-- iter = ring.range(hash..).chain(ring.iter())

4. COLLECTER noeuds uniques :
   |
   |-- TANT QUE pas assez de replicas ET pas fini l'anneau
   |     |
   |     |-- SKIP si meme noeud physique deja vu
   |     |
   |     |-- AJOUTER au resultat

5. RETOURNER resultat avec primary + replicas
```

### 5.3 Visualisation ASCII

```
L'Anneau de Hachage Consistant :

Position:    0        1/4       1/2       3/4       MAX
             |---------|---------|---------|---------|
             v         v         v         v         v

Ring:    [N1#0]    [N2#0]    [N1#1]    [N3#0]    [N2#1]
             \         \         \         \         \
              node1     node2     node1     node3     node2

Lookup("user:1234"):
1. hash("user:1234") = 0.35 (entre N2#0 et N1#1)
2. Premier vnode >= 0.35 : N1#1 (node1)
3. Suivant vnode different : N3#0 (node3)
4. Suivant vnode different : N2#1 (node2)

Resultat: primary=node1, replicas=[node3, node2]

        0.35
          |
          v
    [N2#0]----[N1#1]----[N3#0]----[N2#1]
               ^         ^         ^
               |         |         |
            primary   replica1  replica2


Ajout d'un nouveau noeud (N4) :

Avant:   [N1]----[N2]--------[N3]----[N1]----[N2]
              ^                   ^
              |_____segment_______|
              migre vers N4

Apres:   [N1]----[N4]----[N2]----[N3]----[N1]----[N2]

Seules les cles dans le segment [N1, N4] migrent !
~1/N des cles (si N noeuds au total)
```

### 5.4 Les pieges en detail

| Piege | Description | Solution |
|-------|-------------|----------|
| **Wrap-around oublie** | Hash eleve ne trouve pas de noeud | Chainer avec le debut de l'anneau |
| **Replicas meme noeud** | Plusieurs vnodes = 1 seul noeud physique | Tracker les noeuds physiques vus |
| **Poids ignore** | weight=3 traite comme weight=1 | Multiplier vnodes par weight |
| **Migration excessive** | Reconstruire tout l'anneau | Ajouter incrementalement |
| **Hash non-deterministe** | rand() pour les positions | Utiliser hash(node_id + index) |
| **RF > nodes** | Demander 3 replicas avec 2 noeuds | Limiter au nombre de noeuds dispo |

### 5.5 Cours Complet

#### Qu'est-ce que le Hachage Consistant ?

Le **hachage consistant** (consistent hashing) est une technique qui permet de distribuer des donnees sur un ensemble de serveurs de maniere a minimiser les perturbations lors de l'ajout ou du retrait de serveurs.

**Le probleme du modulo naif :**
```
server = hash(key) % N
```

Quand N change (ajout/retrait de serveur), TOUTES les cles sont potentiellement reassignees. Pour un cache distribue, cela signifie un "cache miss" massif !

**La solution de l'anneau :**

1. Representer l'espace de hash comme un cercle [0, 2^64)
2. Placer chaque serveur a une position hash(server_id)
3. Une cle va au premier serveur rencontre dans le sens horaire

```
Avantage : Quand un serveur est ajoute/retire,
seules les cles "entre" lui et son predecesseur sont affectees.
```

#### Noeuds Virtuels (Vnodes)

Avec un seul point par serveur, la distribution peut etre tres inegale. Solution : chaque serveur a plusieurs "noeuds virtuels" sur l'anneau.

```
Sans vnodes (3 serveurs) :     Avec vnodes (3 serveurs, 4 vnodes chacun) :

     A                              A1  B1  A2  C1
     |                              |   |   |   |
 ----+----                     -----+---+---+---+-----
     |                              |   |   |   |
     B---C                          B2  C2  A3  B3...

Distribution tres inegale      Distribution beaucoup plus uniforme
```

**Formule pour le nombre optimal de vnodes :**
- Trop peu : mauvais equilibre
- Trop : memoire excessive
- Recommandation : 100-200 vnodes par noeud physique

#### Replication

Pour la haute disponibilite, chaque cle est stockee sur plusieurs noeuds :

```
RF (Replication Factor) = 3

key "user:1234" -> hash = 42

Ring: ... [N1@40] [N2@45] [N3@50] [N1@55] ...
              ^       ^       ^
              |       |       |
           primary replica1 replica2

MAIS : N1 et N1@55 sont le MEME noeud physique !
On doit SKIP les vnodes du meme noeud physique.
```

#### Complexite des operations

| Operation | Temps | Espace |
|-----------|-------|--------|
| Lookup | O(log V + R) | O(1) |
| Add node | O(V * log V) | O(V) |
| Remove node | O(V * log V) | O(V) |
| Stats | O(K * log V) | O(N) |

Ou V = nombre total de vnodes, R = replication factor, K = nombre de cles, N = noeuds physiques.

### 5.6 Normes avec explications pedagogiques

```
+------------------------------------------------------------------+
| HORS NORME (compile, mais interdit)                              |
+------------------------------------------------------------------+
| // Utiliser rand pour placer les vnodes                          |
| let pos = rand::random::<u64>();                                 |
+------------------------------------------------------------------+
| CONFORME                                                         |
+------------------------------------------------------------------+
| // Hash deterministe                                             |
| let pos = hash_vnode(&node.id, vnode_index);                     |
+------------------------------------------------------------------+
| POURQUOI ?                                                       |
|                                                                  |
| Le hachage DOIT etre deterministe :                              |
| - Meme node_id + index = meme position, toujours                 |
| - Permet de reconstruire l'anneau apres redemarrage              |
| - Garantit que tous les noeuds ont la meme vue de l'anneau       |
+------------------------------------------------------------------+
```

### 5.7 Simulation avec trace d'execution

**Scenario : lookup("user:42") avec 3 noeuds, RF=2**

```
Configuration:
  vnodes_per_node = 4
  replication_factor = 2
  nodes = [A, B, C]

Ring apres construction:
  Position | Node | VNode Index
  ---------|------|------------
  0x1000   | A    | 0
  0x2500   | B    | 0
  0x3200   | A    | 1
  0x4800   | C    | 0
  0x5100   | B    | 1
  0x6300   | C    | 1
  0x7800   | A    | 2
  0x8500   | B    | 2
  ...

+-------+------------------------------------------+------------+------------------------+
| Etape | Instruction                              | Etat       | Explication            |
+-------+------------------------------------------+------------+------------------------+
|   1   | hash = hash_key("user:42")               | 0x2800     | Position sur l'anneau  |
+-------+------------------------------------------+------------+------------------------+
|   2   | iter = ring.range(0x2800..)              | ->A@0x3200 | Premier vnode >= hash  |
+-------+------------------------------------------+------------+------------------------+
|   3   | Check: A in seen? No                     | seen={A}   | Premier noeud physique |
|       | primary = A                              | primary=A  |                        |
+-------+------------------------------------------+------------+------------------------+
|   4   | Next: C@0x4800                           | ->C@0x4800 | Prochain vnode         |
+-------+------------------------------------------+------------+------------------------+
|   5   | Check: C in seen? No                     | seen={A,C} | Noeud different        |
|       | replicas.push(C)                         | replicas=1 |                        |
+-------+------------------------------------------+------------+------------------------+
|   6   | len(seen)=2 >= RF=2                      | BREAK      | Assez de replicas      |
+-------+------------------------------------------+------------+------------------------+
|   7   | RETURN LookupResult                      |            |                        |
|       | primary=A, replicas=[C], pos=0x2800      |            |                        |
+-------+------------------------------------------+------------+------------------------+
```

### 5.8 Mnemoniques (MEME obligatoire)

#### MEME : "One Ring to Hash Them All"

*"Trois Anneaux pour les rois des serveurs sous le ciel,*
*Sept pour les shards dans leurs salles de pierre,*
*Neuf pour les replicas voues au mortel,*
*Un pour le Ring Hash sur son trone solitaire..."*

L'Anneau de Hachage Consistant, comme l'Anneau Unique, a le pouvoir de :
- **Unir** : Tous les serveurs partagent la meme vision du ring
- **Distribuer** : Le "pouvoir" (les donnees) est reparti equitablement
- **Persister** : L'anneau survit a la chute d'un noeud

```rust
fn one_ring_to_hash(key: &str) -> &PhysicalNode {
    // "In the Land of Distributed Systems where the Shadows lie"
    let hash = hash_key(key);
    find_next_node_clockwise(hash)
}
```

#### MEME : "Wrap-around is Coming"

Quand le hash est tres eleve et qu'il n'y a pas de noeud apres...

```
Hash: 0xFFFFFFFF...
Ring: [N1@0x1000] [N2@0x5000] [N3@0x8000]
                                    |
                              Rien apres !

Solution: Wrap-around au debut !

      0xFFFF...  ->  0x0000  ->  0x1000 (N1)
           |          |           |
           +----------+-----------+
              "Winter came, we wrapped"
```

### 5.9 Applications pratiques

| Application | Utilisation du Consistent Hashing |
|-------------|-----------------------------------|
| **Amazon DynamoDB** | Partitionnement des items par partition key |
| **Apache Cassandra** | Token ring pour la distribution des donnees |
| **Redis Cluster** | 16384 hash slots distribues sur les noeuds |
| **Nginx** | Load balancing avec sticky sessions |
| **Discord** | Routage des messages vers les bons guilds |
| **Akamai CDN** | Distribution du contenu cache |

---

## SECTION 6 : PIEGES — RECAPITULATIF

| # | Piege | Impact | Comment l'eviter |
|---|-------|--------|------------------|
| 1 | Oubli du wrap-around | Cles avec hash eleve orphelines | `range(hash..).chain(iter())` |
| 2 | Replicas sur meme noeud physique | Pas de vraie replication | HashSet des node_ids physiques |
| 3 | Poids ignore | Distribution inegale | `vnodes * weight` |
| 4 | Migration excessive | Cache miss massif | Ajout incremental, pas de clear() |
| 5 | Hash non-deterministe | Anneaux inconsistants entre noeuds | SHA-256 ou hash deterministe |
| 6 | RF > nombre de noeuds | Panic ou replicas dupliques | `min(RF, node_count)` |

---

## SECTION 7 : QCM

### Question 1
**Quel est l'avantage principal du hachage consistant sur `hash % N` ?**

A) Plus rapide a calculer
B) Utilise moins de memoire
C) Minimise la redistribution lors de changements de topologie
D) Garantit un equilibrage parfait
E) Supporte plus de cles
F) Fonctionne sans reseau
G) C et D sont vrais
H) A et B sont vrais
I) Toutes les reponses
J) Aucune reponse

**Reponse : C**

### Question 2
**Pourquoi utilise-t-on des noeuds virtuels ?**

A) Pour economiser de la memoire
B) Pour accelerer les lookups
C) Pour ameliorer l'equilibre de la distribution
D) Pour supporter la replication
E) Pour eviter les collisions de hash
F) Pour permettre le wrap-around
G) C et D
H) A et B
I) C uniquement
J) Toutes sauf A

**Reponse : I**

### Question 3
**Lors de l'ajout d'un noeud sur N noeuds existants, quelle proportion de cles devrait migrer ?**

A) 0%
B) ~1/N
C) ~50%
D) ~100%
E) Depend du nombre de vnodes
F) ~1/(N+1)
G) B ou F selon le contexte
H) Impossible a predire
I) ~N%
J) ~log(N)%

**Reponse : F**

### Question 4
**Que se passe-t-il si le hash d'une cle est superieur a toutes les positions de l'anneau ?**

A) Erreur : cle non trouvee
B) La cle va au dernier noeud
C) La cle wrappe au premier noeud de l'anneau
D) La cle est rejetee
E) On recalcule le hash
F) C'est impossible avec SHA-256
G) La cle va a un noeud aleatoire
H) Depend de l'implementation
I) C, et c'est le comportement standard
J) B, car c'est le plus proche

**Reponse : I**

### Question 5
**Pour la replication avec RF=3, que faut-il garantir ?**

A) 3 vnodes consecutifs
B) 3 noeuds physiques differents
C) 3 copies sur le meme serveur
D) 3 hashs differents
E) 3 anneaux differents
F) B, en skippant les vnodes du meme noeud physique
G) A et C
H) Rien de special
I) Depend du client
J) 3 datacenters differents

**Reponse : F**

---

## SECTION 8 : RECAPITULATIF

| Element | Valeur |
|---------|--------|
| **Exercice** | 5.4.1-a — elastic_ring |
| **Concept principal** | Consistent Hashing |
| **Difficulte** | 7/10 |
| **Temps estime** | 90 min |
| **XP Base** | 300 |
| **Bonus Jump Hash** | AVANCE (x3 XP) |
| **Bonus Bounded Load** | EXPERT (x4 XP) |
| **Langage** | Rust 2024 |
| **Points cles** | Ring, Vnodes, Replication, Minimal redistribution |

---

## SECTION 9 : DEPLOYMENT PACK

```json
{
  "deploy": {
    "hackbrain_version": "5.5.2",
    "engine_version": "v22.1",
    "exercise_slug": "5.4.1-a-elastic-ring",
    "generated_at": "2025-01-16 10:00:00",

    "metadata": {
      "exercise_id": "5.4.1-a",
      "exercise_name": "elastic_ring",
      "module": "5.4.1",
      "module_name": "Distributed Systems - Data Partitioning",
      "concept": "a",
      "concept_name": "Consistent Hashing",
      "type": "complet",
      "tier": 2,
      "tier_info": "Integration systeme distribue",
      "phase": 2,
      "difficulty": 7,
      "difficulty_stars": "7/10",
      "language": "rust",
      "language_alt": null,
      "duration_minutes": 90,
      "xp_base": 300,
      "xp_bonus_multiplier": 3,
      "bonus_tier": "AVANCE",
      "bonus_icon": "",
      "complexity_time": "T5 O(log n)",
      "complexity_space": "S3 O(n * v)",
      "prerequisites": ["hash-functions", "btreemap", "distributed-basics"],
      "domains": ["DS", "Hash", "Algo"],
      "domains_bonus": ["Math"],
      "tags": ["consistent-hashing", "distributed-systems", "partitioning", "replication", "vnodes"],
      "meme_reference": "One Ring to Hash Them All"
    },

    "files": {
      "spec.json": "/* Section 4.9 */",
      "references/ref_solution.rs": "/* Section 4.3 */",
      "references/ref_solution_bonus.rs": "/* Section 4.6 */",
      "mutants/mutant_a_wrap_around.rs": "/* Section 4.10 */",
      "mutants/mutant_b_same_physical.rs": "/* Section 4.10 */",
      "mutants/mutant_c_weight_ignored.rs": "/* Section 4.10 */",
      "mutants/mutant_d_excessive_migration.rs": "/* Section 4.10 */",
      "mutants/mutant_e_vnode_id.rs": "/* Section 4.10 */",
      "mutants/mutant_f_dedup_missing.rs": "/* Section 4.10 */",
      "tests/test_ring.rs": "/* Section 4.2 */"
    },

    "validation": {
      "expected_pass": [
        "references/ref_solution.rs",
        "references/ref_solution_bonus.rs"
      ],
      "expected_fail": [
        "mutants/mutant_a_wrap_around.rs",
        "mutants/mutant_b_same_physical.rs",
        "mutants/mutant_c_weight_ignored.rs",
        "mutants/mutant_d_excessive_migration.rs",
        "mutants/mutant_e_vnode_id.rs",
        "mutants/mutant_f_dedup_missing.rs"
      ]
    }
  }
}
```

---

*HACKBRAIN v5.5.2 — "One Ring to Hash Them All, One Ring to Find Them, One Ring to Bring Them All, and in the Distributed System Bind Them"*
